{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 2** | **Siguiente 4** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../../../README.md) | [](./2.INTRODUCCION_A_PANDAS.ipynb)| [](./4.LIMPIEZA_Y_PREPARACION_DE_DATOS.ipynb)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. VISUALIZACIN EN PYTHON (MATPLOTLIB)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **B煤squeda y eliminaci贸n de datos duplicados por filas y columnas**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pandas, puedes utilizar funciones para buscar y eliminar datos duplicados tanto por filas como por columnas en un DataFrame. Aqu铆 tienes una explicaci贸n detallada con ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame original:\n",
      "  Nombre  Edad  Altura\n",
      "0   Juan    25     170\n",
      "1  Mar铆a    30     165\n",
      "2  Pedro    35     180\n",
      "3  Mar铆a    30     165\n",
      "\n",
      "Filas duplicadas:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "\n",
      "DataFrame sin filas duplicadas:\n",
      "  Nombre  Edad  Altura\n",
      "0   Juan    25     170\n",
      "1  Mar铆a    30     165\n",
      "2  Pedro    35     180\n",
      "\n",
      "Columnas duplicadas:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "\n",
      "DataFrame sin columnas duplicadas:\n",
      "  Nombre  Edad  Altura\n",
      "0   Juan    25     170\n",
      "1  Mar铆a    30     165\n",
      "2  Pedro    35     180\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creaci贸n del DataFrame\n",
    "data = {'Nombre': ['Juan', 'Mar铆a', 'Pedro', 'Mar铆a'],\n",
    "        'Edad': [25, 30, 35, 30],\n",
    "        'Altura': [170, 165, 180, 165]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame original:\")\n",
    "print(df)\n",
    "\n",
    "# B煤squeda de datos duplicados por filas\n",
    "duplicados_filas = df.duplicated()\n",
    "print(\"\\nFilas duplicadas:\")\n",
    "print(duplicados_filas)\n",
    "\n",
    "# Eliminaci贸n de datos duplicados por filas\n",
    "df_sin_duplicados_filas = df.drop_duplicates()\n",
    "print(\"\\nDataFrame sin filas duplicadas:\")\n",
    "print(df_sin_duplicados_filas)\n",
    "\n",
    "# B煤squeda de datos duplicados por columnas\n",
    "duplicados_columnas = df.duplicated(subset=['Nombre'])\n",
    "print(\"\\nColumnas duplicadas:\")\n",
    "print(duplicados_columnas)\n",
    "\n",
    "# Eliminaci贸n de datos duplicados por columnas\n",
    "df_sin_duplicados_columnas = df.drop_duplicates(subset=['Nombre'])\n",
    "print(\"\\nDataFrame sin columnas duplicadas:\")\n",
    "print(df_sin_duplicados_columnas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, creamos un DataFrame `df` con tres columnas: '`Nombre`', '`Edad`' y '`Altura`'. Algunas filas y columnas contienen datos duplicados. A continuaci贸n, aplicamos las siguientes operaciones:\n",
    "\n",
    "* **B煤squeda de datos duplicados por filas:** Utilizamos el m茅todo `duplicated()` sin especificar ninguna columna. Esto devuelve una serie de valores booleanos que indican si cada fila es duplicada o no.\n",
    "\n",
    "* **Eliminaci贸n de datos duplicados por filas:** Utilizamos el m茅todo `drop_duplicates()` sin especificar ninguna columna. Esto crea un nuevo DataFrame `df_sin_duplicados_filas` que excluye las filas duplicadas.\n",
    "\n",
    "* **B煤squeda de datos duplicados por columnas:** Utilizamos el m茅todo `duplicated()` especificando la columna '`Nombre`'. Esto devuelve una serie de valores booleanos que indican si cada valor en la columna '`Nombre`' es duplicado o no.\n",
    "\n",
    "* **Eliminaci贸n de datos duplicados por columnas:** Utilizamos el m茅todo `drop_duplicates()` especificando la columna '`Nombre`'. Esto crea un nuevo DataFrame `df_sin_duplicados_columnas` que excluye las filas con valores duplicados en la columna '`Nombre`'.\n",
    "\n",
    "En ambos casos, la funci贸n `drop_duplicates()` conserva la primera aparici贸n de una fila o columna duplicada y elimina las apariciones posteriores.\n",
    "\n",
    "Recuerda que tambi茅n puedes especificar m煤ltiples columnas en los m茅todos `duplicated()` y `drop_duplicates()` para buscar y eliminar duplicados basados en una combinaci贸n de columnas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transformaci贸n de Datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La transformaci贸n de datos es el proceso de modificar o manipular los datos existentes con el objetivo de obtener una representaci贸n m谩s 煤til, comprensible o adecuada para su an谩lisis o uso posterior. Esta etapa es esencial en el flujo de trabajo de an谩lisis de datos, ya que permite preparar y limpiar los datos antes de aplicar t茅cnicas de an谩lisis o modelado.\n",
    "\n",
    "La transformaci贸n de datos puede involucrar una variedad de operaciones, que incluyen:\n",
    "\n",
    "1. **Limpieza de datos:** Esto implica identificar y corregir errores, eliminar valores at铆picos o inconsistentes, tratar los valores perdidos o nulos, y estandarizar los formatos de datos para garantizar la coherencia y la integridad de los datos.\n",
    "\n",
    "2. **Normalizaci贸n:** Consiste en escalar los valores de las variables para que est茅n dentro de un rango espec铆fico, como 0 a 1, o estandarizarlos utilizando la media y desviaci贸n est谩ndar. Esto es especialmente 煤til cuando se trabaja con variables de diferentes escalas, ya que ayuda a evitar que ciertas variables dominen el an谩lisis debido a su escala.\n",
    "\n",
    "3. **Transformaci贸n de variables:** Implica aplicar funciones matem谩ticas o estad铆sticas a las variables para obtener nuevas representaciones o caracter铆sticas de los datos. Esto puede incluir transformaciones logar铆tmicas, exponenciales, ra铆ces cuadradas, entre otras.\n",
    "\n",
    "4. **Agregaci贸n de datos:** Consiste en combinar datos individuales en grupos m谩s grandes, como sumarizar datos por categor铆as o intervalos de tiempo, calcular estad铆sticas agregadas (como la media o la suma) o crear variables derivadas a partir de m煤ltiples variables existentes.\n",
    "\n",
    "5. **Codificaci贸n de variables categ贸ricas:** Si hay variables categ贸ricas en los datos, es posible que sea necesario codificarlas como variables num茅ricas para que los algoritmos de an谩lisis puedan procesarlas. Esto puede incluir t茅cnicas como la codificaci贸n `one-hot`, donde se crea una columna binaria para cada categor铆a, o la codificaci贸n ordinal, donde se asignan valores num茅ricos a las categor铆as en funci贸n de su orden o relevancia.\n",
    "\n",
    "Estas son solo algunas de las operaciones comunes de transformaci贸n de datos. El enfoque y las t茅cnicas espec铆ficas utilizadas pueden variar seg煤n el contexto del problema y los requisitos del an谩lisis. Es importante tener en cuenta que la transformaci贸n de datos debe realizarse de manera cuidadosa y bien documentada, para garantizar la calidad y la reproducibilidad de los resultados obtenidos.\n",
    "\n",
    "A continuaci贸n, se muestra un ejemplo de c贸digo Python que ilustra algunas transformaciones de datos utilizando la biblioteca pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A         B      Suma  Categor铆a_A  Categor铆a_B  Categor铆a_C\n",
      "0  0.00  2.302585  2.302585            1            0            0\n",
      "1  0.25  2.995732  3.245732            0            1            0\n",
      "2  0.50  3.401197  3.901197            1            0            0\n",
      "3  0.75  3.688879  4.438879            0            0            1\n",
      "4  1.00  3.912023  4.912023            0            1            0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': [10, 20, 30, 40, 50],\n",
    "        'Categor铆a': ['A', 'B', 'A', 'C', 'B']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Limpieza de datos: eliminar filas con valores nulos\n",
    "df = df.dropna()\n",
    "\n",
    "# Normalizaci贸n: escalar los valores de la columna A al rango [0, 1]\n",
    "df['A'] = (df['A'] - df['A'].min()) / (df['A'].max() - df['A'].min())\n",
    "\n",
    "# Transformaci贸n de variables: calcular el logaritmo de la columna B\n",
    "df['B'] = df['B'].apply(lambda x: math.log(x))\n",
    "\n",
    "# Agregaci贸n de datos: calcular la suma de las columnas A y B\n",
    "df['Suma'] = df['A'] + df['B']\n",
    "\n",
    "# Codificaci贸n de variables categ贸ricas: convertir una variable categ贸rica en una variable dummy\n",
    "df = pd.get_dummies(df, columns=['Categor铆a'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, aplicamos varias transformaciones de datos al DataFrame `df`:\n",
    "\n",
    "* **Limpieza de datos:** Utilizamos el m茅todo `dropna()` para eliminar las filas que contienen valores nulos.\n",
    "\n",
    "* **Normalizaci贸n:** Utilizamos la f贸rmula de escalamiento min-max para escalar los valores de la columna '`A`' al rango `[0, 1]`.\n",
    "\n",
    "* **Transformaci贸n de variables:** Aplicamos la funci贸n logaritmo a los valores de la columna '`B`' utilizando el m茅todo `apply()` y una funci贸n `lambda`.\n",
    "\n",
    "* **Agregaci贸n de datos:** Calculamos la suma de las columnas '`A`' y '`B`' y guardamos el resultado en una nueva columna '`Suma`'.\n",
    "\n",
    "* **Codificaci贸n de variables categ贸ricas:** Utilizamos el m茅todo `get_dummies()` para convertir una columna categ贸rica '`Categor铆a`' en variables dummy, creando columnas binarias correspondientes a cada categor铆a.\n",
    "\n",
    "Estas transformaciones son solo ejemplos y pueden variar seg煤n tus necesidades y los datos con los que est茅s trabajando. Recuerda que es importante entender tus datos y aplicar las transformaciones adecuadas para obtener resultados significativos en tu an谩lisis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocesamiento de datos con Python**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocesamiento de datos es una etapa fundamental en cualquier tarea de an谩lisis de datos y aprendizaje autom谩tico. Consiste en realizar una serie de transformaciones y manipulaciones en los datos brutos para prepararlos adecuadamente antes de aplicar algoritmos o modelos. El objetivo principal del preprocesamiento de datos es mejorar la calidad de los datos, eliminar ruidos y redundancias, y garantizar que los datos sean adecuados para su posterior an谩lisis.\n",
    "\n",
    "El preprocesamiento de datos implica diferentes t茅cnicas y pasos, que pueden variar seg煤n el tipo de datos y la naturaleza del problema. Algunas de las t茅cnicas comunes utilizadas en el preprocesamiento de datos son:\n",
    "\n",
    "1. **Limpieza de datos:** Esto implica eliminar o tratar los valores faltantes, corregir errores en los datos, eliminar valores at铆picos (outliers) y manejar valores duplicados.\n",
    "\n",
    "2. **Integraci贸n de datos:** En ocasiones, los datos pueden estar distribuidos en m煤ltiples fuentes o en diferentes formatos. La integraci贸n de datos implica combinar y fusionar los datos en una sola estructura coherente.\n",
    "\n",
    "3. **Transformaci贸n de datos:** Esto incluye la normalizaci贸n de variables num茅ricas para que est茅n en la misma escala, la estandarizaci贸n de datos para que tengan una media de cero y una desviaci贸n est谩ndar de uno, y la transformaci贸n de variables categ贸ricas en representaciones num茅ricas adecuadas.\n",
    "\n",
    "4. **Reducci贸n de dimensionalidad:** Cuando los datos tienen muchas variables o caracter铆sticas, puede ser 煤til reducir la dimensionalidad para simplificar el an谩lisis. Esto se puede lograr mediante t茅cnicas como An谩lisis de Componentes Principales (PCA) o selecci贸n de caracter铆sticas.\n",
    "\n",
    "5. **Discretizaci贸n de datos:** En algunos casos, puede ser necesario convertir variables continuas en variables discretas o categ贸ricas. Esto se puede hacer mediante la segmentaci贸n de rangos o el uso de algoritmos de agrupamiento.\n",
    "\n",
    "6. **Codificaci贸n de variables categ贸ricas:** Las variables categ贸ricas deben ser codificadas en representaciones num茅ricas para que puedan ser utilizadas por algoritmos de aprendizaje autom谩tico. Esto se puede hacer mediante t茅cnicas como la codificaci贸n one-hot (dummy encoding) o la codificaci贸n ordinal.\n",
    "\n",
    "7. **Manejo de desequilibrios de clases:** Si los datos est谩n desequilibrados, es decir, una clase est谩 sobre-representada en comparaci贸n con otras, se pueden aplicar t茅cnicas de muestreo para equilibrar las clases, como el submuestreo, el sobremuestreo o la generaci贸n sint茅tica de muestras.\n",
    "\n",
    "Estos son solo algunos ejemplos de las t茅cnicas de preprocesamiento de datos que se pueden utilizar. La elecci贸n de las t茅cnicas depender谩 del problema espec铆fico y los datos con los que se est谩 trabajando. Es importante tener en cuenta que el preprocesamiento de datos es un paso cr铆tico para garantizar la calidad y confiabilidad de los resultados en cualquier an谩lisis de datos o proyecto de aprendizaje autom谩tico."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Formato y normalizaci贸n de datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El formato y la normalizaci贸n de datos son procesos importantes en el preprocesamiento de datos que se realizan para garantizar que los datos est茅n en un estado adecuado para su an谩lisis o modelado. A continuaci贸n, se explica brevemente cada uno de estos conceptos:\n",
    "\n",
    "1. **Formato de datos:**\n",
    "\n",
    "El formato de datos se refiere a la estructura y presentaci贸n de los datos. A menudo, los datos pueden venir en diferentes formatos, como archivos CSV, Excel, JSON, bases de datos, entre otros. Durante el preprocesamiento, es com煤n convertir los datos a un formato m谩s conveniente o compatible con las herramientas y bibliotecas de an谩lisis de datos que se utilizar谩n. Por ejemplo, es posible que deba leer los datos de un archivo CSV y cargarlos en un DataFrame de Pandas para facilitar su manipulaci贸n y an谩lisis.\n",
    "\n",
    "2. **Normalizaci贸n de datos:**\n",
    "\n",
    "La normalizaci贸n de datos es un proceso para escalar los valores de los datos a un rango espec铆fico o estandarizarlos para que tengan una distribuci贸n com煤n. Esto es 煤til cuando las variables en los datos tienen diferentes rangos o unidades de medida. La normalizaci贸n permite comparar y analizar los datos de manera m谩s efectiva. Algunas t茅cnicas comunes de normalizaci贸n incluyen:\n",
    "\n",
    "* **Min-Max scaling:** Escala los valores al rango [0, 1] dividiendo cada valor por el valor m谩ximo y restando el valor m铆nimo.\n",
    "* **Z-score normalization:** Est谩ndariza los valores para que tengan una media de cero y una desviaci贸n est谩ndar de uno restando la media y dividiendo por la desviaci贸n est谩ndar.\n",
    "\n",
    "2. **Escalamiento decimal:**\n",
    "\n",
    " Mueve el punto decimal de los valores para ajustarlos a una escala espec铆fica, como escalar los valores entre -1 y 1.\n",
    "La normalizaci贸n de datos es especialmente importante cuando se utilizan algoritmos basados en distancias o que son sensibles a las escalas de las variables, como el an谩lisis de conglomerados o los algoritmos de aprendizaje autom谩tico basados en la distancia euclidiana.\n",
    "\n",
    "Es importante destacar que el formato y la normalizaci贸n de datos pueden variar seg煤n el tipo de datos y el problema espec铆fico. Algunas bibliotecas populares en Python para trabajar con el formato y la normalizaci贸n de datos son Pandas y Scikit-learn, que ofrecen diversas funciones y m茅todos para realizar estas tareas de manera eficiente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Formato y normalizaci贸n de datos](../img/Formato%20y%20normalizaci%C3%B3n%20de%20datos.jpg \"Formato y normalizaci贸n de datos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 2** | **Siguiente 4** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../../../README.md) | [](./2.INTRODUCCION_A_PANDAS.ipynb)| [](./4.LIMPIEZA_Y_PREPARACION_DE_DATOS.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
