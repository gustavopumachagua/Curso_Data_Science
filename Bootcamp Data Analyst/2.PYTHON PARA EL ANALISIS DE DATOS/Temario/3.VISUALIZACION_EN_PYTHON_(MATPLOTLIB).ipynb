{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 2** | **Siguiente 4** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../../README.md) | [⏪](./2.INTRODUCCION_A_PANDAS.ipynb)| [⏩](./4.LIMPIEZA_Y_PREPARACION_DE_DATOS.ipynb)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. VISUALIZACIÓN EN PYTHON (MATPLOTLIB)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Búsqueda y eliminación de datos duplicados por filas y columnas**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En pandas, puedes utilizar funciones para buscar y eliminar datos duplicados tanto por filas como por columnas en un DataFrame. Aquí tienes una explicación detallada con ejemplos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame original:\n",
      "  Nombre  Edad  Altura\n",
      "0   Juan    25     170\n",
      "1  María    30     165\n",
      "2  Pedro    35     180\n",
      "3  María    30     165\n",
      "\n",
      "Filas duplicadas:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "\n",
      "DataFrame sin filas duplicadas:\n",
      "  Nombre  Edad  Altura\n",
      "0   Juan    25     170\n",
      "1  María    30     165\n",
      "2  Pedro    35     180\n",
      "\n",
      "Columnas duplicadas:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3     True\n",
      "dtype: bool\n",
      "\n",
      "DataFrame sin columnas duplicadas:\n",
      "  Nombre  Edad  Altura\n",
      "0   Juan    25     170\n",
      "1  María    30     165\n",
      "2  Pedro    35     180\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creación del DataFrame\n",
    "data = {'Nombre': ['Juan', 'María', 'Pedro', 'María'],\n",
    "        'Edad': [25, 30, 35, 30],\n",
    "        'Altura': [170, 165, 180, 165]}\n",
    "df = pd.DataFrame(data)\n",
    "print(\"DataFrame original:\")\n",
    "print(df)\n",
    "\n",
    "# Búsqueda de datos duplicados por filas\n",
    "duplicados_filas = df.duplicated()\n",
    "print(\"\\nFilas duplicadas:\")\n",
    "print(duplicados_filas)\n",
    "\n",
    "# Eliminación de datos duplicados por filas\n",
    "df_sin_duplicados_filas = df.drop_duplicates()\n",
    "print(\"\\nDataFrame sin filas duplicadas:\")\n",
    "print(df_sin_duplicados_filas)\n",
    "\n",
    "# Búsqueda de datos duplicados por columnas\n",
    "duplicados_columnas = df.duplicated(subset=['Nombre'])\n",
    "print(\"\\nColumnas duplicadas:\")\n",
    "print(duplicados_columnas)\n",
    "\n",
    "# Eliminación de datos duplicados por columnas\n",
    "df_sin_duplicados_columnas = df.drop_duplicates(subset=['Nombre'])\n",
    "print(\"\\nDataFrame sin columnas duplicadas:\")\n",
    "print(df_sin_duplicados_columnas)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, creamos un DataFrame `df` con tres columnas: '`Nombre`', '`Edad`' y '`Altura`'. Algunas filas y columnas contienen datos duplicados. A continuación, aplicamos las siguientes operaciones:\n",
    "\n",
    "* **Búsqueda de datos duplicados por filas:** Utilizamos el método `duplicated()` sin especificar ninguna columna. Esto devuelve una serie de valores booleanos que indican si cada fila es duplicada o no.\n",
    "\n",
    "* **Eliminación de datos duplicados por filas:** Utilizamos el método `drop_duplicates()` sin especificar ninguna columna. Esto crea un nuevo DataFrame `df_sin_duplicados_filas` que excluye las filas duplicadas.\n",
    "\n",
    "* **Búsqueda de datos duplicados por columnas:** Utilizamos el método `duplicated()` especificando la columna '`Nombre`'. Esto devuelve una serie de valores booleanos que indican si cada valor en la columna '`Nombre`' es duplicado o no.\n",
    "\n",
    "* **Eliminación de datos duplicados por columnas:** Utilizamos el método `drop_duplicates()` especificando la columna '`Nombre`'. Esto crea un nuevo DataFrame `df_sin_duplicados_columnas` que excluye las filas con valores duplicados en la columna '`Nombre`'.\n",
    "\n",
    "En ambos casos, la función `drop_duplicates()` conserva la primera aparición de una fila o columna duplicada y elimina las apariciones posteriores.\n",
    "\n",
    "Recuerda que también puedes especificar múltiples columnas en los métodos `duplicated()` y `drop_duplicates()` para buscar y eliminar duplicados basados en una combinación de columnas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Transformación de Datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La transformación de datos es el proceso de modificar o manipular los datos existentes con el objetivo de obtener una representación más útil, comprensible o adecuada para su análisis o uso posterior. Esta etapa es esencial en el flujo de trabajo de análisis de datos, ya que permite preparar y limpiar los datos antes de aplicar técnicas de análisis o modelado.\n",
    "\n",
    "La transformación de datos puede involucrar una variedad de operaciones, que incluyen:\n",
    "\n",
    "1. **Limpieza de datos:** Esto implica identificar y corregir errores, eliminar valores atípicos o inconsistentes, tratar los valores perdidos o nulos, y estandarizar los formatos de datos para garantizar la coherencia y la integridad de los datos.\n",
    "\n",
    "2. **Normalización:** Consiste en escalar los valores de las variables para que estén dentro de un rango específico, como 0 a 1, o estandarizarlos utilizando la media y desviación estándar. Esto es especialmente útil cuando se trabaja con variables de diferentes escalas, ya que ayuda a evitar que ciertas variables dominen el análisis debido a su escala.\n",
    "\n",
    "3. **Transformación de variables:** Implica aplicar funciones matemáticas o estadísticas a las variables para obtener nuevas representaciones o características de los datos. Esto puede incluir transformaciones logarítmicas, exponenciales, raíces cuadradas, entre otras.\n",
    "\n",
    "4. **Agregación de datos:** Consiste en combinar datos individuales en grupos más grandes, como sumarizar datos por categorías o intervalos de tiempo, calcular estadísticas agregadas (como la media o la suma) o crear variables derivadas a partir de múltiples variables existentes.\n",
    "\n",
    "5. **Codificación de variables categóricas:** Si hay variables categóricas en los datos, es posible que sea necesario codificarlas como variables numéricas para que los algoritmos de análisis puedan procesarlas. Esto puede incluir técnicas como la codificación `one-hot`, donde se crea una columna binaria para cada categoría, o la codificación ordinal, donde se asignan valores numéricos a las categorías en función de su orden o relevancia.\n",
    "\n",
    "Estas son solo algunas de las operaciones comunes de transformación de datos. El enfoque y las técnicas específicas utilizadas pueden variar según el contexto del problema y los requisitos del análisis. Es importante tener en cuenta que la transformación de datos debe realizarse de manera cuidadosa y bien documentada, para garantizar la calidad y la reproducibilidad de los resultados obtenidos.\n",
    "\n",
    "A continuación, se muestra un ejemplo de código Python que ilustra algunas transformaciones de datos utilizando la biblioteca pandas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      A         B      Suma  Categoría_A  Categoría_B  Categoría_C\n",
      "0  0.00  2.302585  2.302585            1            0            0\n",
      "1  0.25  2.995732  3.245732            0            1            0\n",
      "2  0.50  3.401197  3.901197            1            0            0\n",
      "3  0.75  3.688879  4.438879            0            0            1\n",
      "4  1.00  3.912023  4.912023            0            1            0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = {'A': [1, 2, 3, 4, 5],\n",
    "        'B': [10, 20, 30, 40, 50],\n",
    "        'Categoría': ['A', 'B', 'A', 'C', 'B']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Limpieza de datos: eliminar filas con valores nulos\n",
    "df = df.dropna()\n",
    "\n",
    "# Normalización: escalar los valores de la columna A al rango [0, 1]\n",
    "df['A'] = (df['A'] - df['A'].min()) / (df['A'].max() - df['A'].min())\n",
    "\n",
    "# Transformación de variables: calcular el logaritmo de la columna B\n",
    "df['B'] = df['B'].apply(lambda x: math.log(x))\n",
    "\n",
    "# Agregación de datos: calcular la suma de las columnas A y B\n",
    "df['Suma'] = df['A'] + df['B']\n",
    "\n",
    "# Codificación de variables categóricas: convertir una variable categórica en una variable dummy\n",
    "df = pd.get_dummies(df, columns=['Categoría'])\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, aplicamos varias transformaciones de datos al DataFrame `df`:\n",
    "\n",
    "* **Limpieza de datos:** Utilizamos el método `dropna()` para eliminar las filas que contienen valores nulos.\n",
    "\n",
    "* **Normalización:** Utilizamos la fórmula de escalamiento min-max para escalar los valores de la columna '`A`' al rango `[0, 1]`.\n",
    "\n",
    "* **Transformación de variables:** Aplicamos la función logaritmo a los valores de la columna '`B`' utilizando el método `apply()` y una función `lambda`.\n",
    "\n",
    "* **Agregación de datos:** Calculamos la suma de las columnas '`A`' y '`B`' y guardamos el resultado en una nueva columna '`Suma`'.\n",
    "\n",
    "* **Codificación de variables categóricas:** Utilizamos el método `get_dummies()` para convertir una columna categórica '`Categoría`' en variables dummy, creando columnas binarias correspondientes a cada categoría.\n",
    "\n",
    "Estas transformaciones son solo ejemplos y pueden variar según tus necesidades y los datos con los que estés trabajando. Recuerda que es importante entender tus datos y aplicar las transformaciones adecuadas para obtener resultados significativos en tu análisis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocesamiento de datos con Python**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El preprocesamiento de datos es una etapa fundamental en cualquier tarea de análisis de datos y aprendizaje automático. Consiste en realizar una serie de transformaciones y manipulaciones en los datos brutos para prepararlos adecuadamente antes de aplicar algoritmos o modelos. El objetivo principal del preprocesamiento de datos es mejorar la calidad de los datos, eliminar ruidos y redundancias, y garantizar que los datos sean adecuados para su posterior análisis.\n",
    "\n",
    "El preprocesamiento de datos implica diferentes técnicas y pasos, que pueden variar según el tipo de datos y la naturaleza del problema. Algunas de las técnicas comunes utilizadas en el preprocesamiento de datos son:\n",
    "\n",
    "1. **Limpieza de datos:** Esto implica eliminar o tratar los valores faltantes, corregir errores en los datos, eliminar valores atípicos (outliers) y manejar valores duplicados.\n",
    "\n",
    "2. **Integración de datos:** En ocasiones, los datos pueden estar distribuidos en múltiples fuentes o en diferentes formatos. La integración de datos implica combinar y fusionar los datos en una sola estructura coherente.\n",
    "\n",
    "3. **Transformación de datos:** Esto incluye la normalización de variables numéricas para que estén en la misma escala, la estandarización de datos para que tengan una media de cero y una desviación estándar de uno, y la transformación de variables categóricas en representaciones numéricas adecuadas.\n",
    "\n",
    "4. **Reducción de dimensionalidad:** Cuando los datos tienen muchas variables o características, puede ser útil reducir la dimensionalidad para simplificar el análisis. Esto se puede lograr mediante técnicas como Análisis de Componentes Principales (PCA) o selección de características.\n",
    "\n",
    "5. **Discretización de datos:** En algunos casos, puede ser necesario convertir variables continuas en variables discretas o categóricas. Esto se puede hacer mediante la segmentación de rangos o el uso de algoritmos de agrupamiento.\n",
    "\n",
    "6. **Codificación de variables categóricas:** Las variables categóricas deben ser codificadas en representaciones numéricas para que puedan ser utilizadas por algoritmos de aprendizaje automático. Esto se puede hacer mediante técnicas como la codificación one-hot (dummy encoding) o la codificación ordinal.\n",
    "\n",
    "7. **Manejo de desequilibrios de clases:** Si los datos están desequilibrados, es decir, una clase está sobre-representada en comparación con otras, se pueden aplicar técnicas de muestreo para equilibrar las clases, como el submuestreo, el sobremuestreo o la generación sintética de muestras.\n",
    "\n",
    "Estos son solo algunos ejemplos de las técnicas de preprocesamiento de datos que se pueden utilizar. La elección de las técnicas dependerá del problema específico y los datos con los que se está trabajando. Es importante tener en cuenta que el preprocesamiento de datos es un paso crítico para garantizar la calidad y confiabilidad de los resultados en cualquier análisis de datos o proyecto de aprendizaje automático."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Formato y normalización de datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El formato y la normalización de datos son procesos importantes en el preprocesamiento de datos que se realizan para garantizar que los datos estén en un estado adecuado para su análisis o modelado. A continuación, se explica brevemente cada uno de estos conceptos:\n",
    "\n",
    "1. **Formato de datos:**\n",
    "\n",
    "El formato de datos se refiere a la estructura y presentación de los datos. A menudo, los datos pueden venir en diferentes formatos, como archivos CSV, Excel, JSON, bases de datos, entre otros. Durante el preprocesamiento, es común convertir los datos a un formato más conveniente o compatible con las herramientas y bibliotecas de análisis de datos que se utilizarán. Por ejemplo, es posible que deba leer los datos de un archivo CSV y cargarlos en un DataFrame de Pandas para facilitar su manipulación y análisis.\n",
    "\n",
    "2. **Normalización de datos:**\n",
    "\n",
    "La normalización de datos es un proceso para escalar los valores de los datos a un rango específico o estandarizarlos para que tengan una distribución común. Esto es útil cuando las variables en los datos tienen diferentes rangos o unidades de medida. La normalización permite comparar y analizar los datos de manera más efectiva. Algunas técnicas comunes de normalización incluyen:\n",
    "\n",
    "* **Min-Max scaling:** Escala los valores al rango [0, 1] dividiendo cada valor por el valor máximo y restando el valor mínimo.\n",
    "* **Z-score normalization:** Estándariza los valores para que tengan una media de cero y una desviación estándar de uno restando la media y dividiendo por la desviación estándar.\n",
    "\n",
    "2. **Escalamiento decimal:**\n",
    "\n",
    " Mueve el punto decimal de los valores para ajustarlos a una escala específica, como escalar los valores entre -1 y 1.\n",
    "La normalización de datos es especialmente importante cuando se utilizan algoritmos basados en distancias o que son sensibles a las escalas de las variables, como el análisis de conglomerados o los algoritmos de aprendizaje automático basados en la distancia euclidiana.\n",
    "\n",
    "Es importante destacar que el formato y la normalización de datos pueden variar según el tipo de datos y el problema específico. Algunas bibliotecas populares en Python para trabajar con el formato y la normalización de datos son Pandas y Scikit-learn, que ofrecen diversas funciones y métodos para realizar estas tareas de manera eficiente."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Formato y normalización de datos](../img/Formato%20y%20normalizaci%C3%B3n%20de%20datos.jpg \"Formato y normalización de datos\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 2** | **Siguiente 4** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../../README.md) | [⏪](./2.INTRODUCCION_A_PANDAS.ipynb)| [⏩](./4.LIMPIEZA_Y_PREPARACION_DE_DATOS.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
