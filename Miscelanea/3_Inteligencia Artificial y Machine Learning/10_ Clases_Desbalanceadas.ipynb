{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 9** | **Siguiente 11** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../README.md) | [⏪](./9_Tipos_de_Distancias.ipynb)| [⏩](./11_K-Vecinos.ipynb)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **10. Cómo crear Clasificadores de Machine Learning ante Clases Desbalanceadas asignando Pesos con Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introducción al problema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando trabajamos con conjuntos de datos en los que las clases están desbalanceadas, es decir, una clase tiene muchas más muestras que las otras, es importante tomar medidas para manejar este desbalance. Una forma de abordar esto es asignar pesos diferentes a las clases durante el entrenamiento de un clasificador. Esto permite que el modelo penalice más los errores en la clase minoritaria y, por lo tanto, tenga un mejor rendimiento en términos de precisión y recall.\n",
    "\n",
    "Aquí hay un ejemplo paso a paso de cómo crear clasificadores de Machine Learning ante clases desbalanceadas asignando pesos usando Python y la biblioteca Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador sin pesos:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       270\n",
      "           1       0.57      0.40      0.47        30\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.75      0.68      0.71       300\n",
      "weighted avg       0.90      0.91      0.90       300\n",
      "\n",
      "\n",
      "Clasificador con pesos equilibrados:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91       270\n",
      "           1       0.37      0.77      0.49        30\n",
      "\n",
      "    accuracy                           0.84       300\n",
      "   macro avg       0.67      0.81      0.70       300\n",
      "weighted avg       0.91      0.84      0.87       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Crear un conjunto de datos desbalanceado de ejemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear un clasificador de regresión logística sin ajustar pesos\n",
    "clf_unweighted = LogisticRegression(random_state=42)\n",
    "clf_unweighted.fit(X_train, y_train)\n",
    "\n",
    "# Crear un clasificador de regresión logística con pesos equilibrados\n",
    "clf_weighted = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "clf_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_unweighted = clf_unweighted.predict(X_test)\n",
    "y_pred_weighted = clf_weighted.predict(X_test)\n",
    "\n",
    "# Mostrar los informes de clasificación para ambos clasificadores\n",
    "print(\"Clasificador sin pesos:\")\n",
    "print(classification_report(y_test, y_pred_unweighted))\n",
    "\n",
    "print(\"\\nClasificador con pesos equilibrados:\")\n",
    "print(classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, primero creamos un conjunto de datos desbalanceado de ejemplo usando `make_classification`. Luego, dividimos los datos en conjuntos de entrenamiento y prueba. A continuación, creamos dos clasificadores de regresión logística: uno sin ajustar pesos y otro con pesos equilibrados usando el parámetro `class_weight='balanced'`.\n",
    "\n",
    "Finalmente, calculamos las predicciones en el conjunto de prueba para ambos clasificadores y mostramos los informes de clasificación que incluyen métricas como precisión, recall y F1-score para cada clase.\n",
    "\n",
    "La gráfica de código se mostrará en una ventana emergente separada cuando ejecutes este código. Recuerda que el conjunto de datos utilizado aquí es solo un ejemplo, y en problemas reales, debes ajustar los parámetros y las técnicas según las características de tus datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Librerías y código de soporte**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior, se utilizaron varias bibliotecas de Python para crear clasificadores de Machine Learning para datos desbalanceados. Aquí tienes una descripción de las bibliotecas utilizadas y el código de soporte en forma de funciones:\n",
    "\n",
    "1. **Bibliotecas utilizadas:**\n",
    "   - `numpy`: Biblioteca para operaciones numéricas eficientes en Python.\n",
    "   - `matplotlib`: Biblioteca para crear gráficos y visualizaciones.\n",
    "   - `sklearn.datasets`: Módulo de Scikit-learn para generar conjuntos de datos sintéticos.\n",
    "   - `sklearn.model_selection`: Módulo de Scikit-learn para dividir conjuntos de datos en entrenamiento y prueba.\n",
    "   - `sklearn.linear_model`: Módulo de Scikit-learn que contiene el modelo de regresión logística.\n",
    "   - `sklearn.metrics`: Módulo de Scikit-learn que contiene funciones para evaluar métricas de rendimiento de modelos.\n",
    "\n",
    "2. **Código de soporte:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador sin pesos:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       270\n",
      "           1       0.57      0.40      0.47        30\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.75      0.68      0.71       300\n",
      "weighted avg       0.90      0.91      0.90       300\n",
      "\n",
      "\n",
      "Clasificador con pesos equilibrados:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91       270\n",
      "           1       0.37      0.77      0.49        30\n",
      "\n",
      "    accuracy                           0.84       300\n",
      "   macro avg       0.67      0.81      0.70       300\n",
      "weighted avg       0.91      0.84      0.87       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Crear un conjunto de datos desbalanceado de ejemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Función para evaluar y mostrar informe de clasificación\n",
    "def evaluate_classifier(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Crear un clasificador de regresión logística sin ajustar pesos\n",
    "clf_unweighted = LogisticRegression(random_state=42)\n",
    "clf_unweighted.fit(X_train, y_train)\n",
    "\n",
    "# Crear un clasificador de regresión logística con pesos equilibrados\n",
    "clf_weighted = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "clf_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar y mostrar informe de clasificación para ambos clasificadores\n",
    "print(\"Clasificador sin pesos:\")\n",
    "evaluate_classifier(clf_unweighted, X_test, y_test)\n",
    "\n",
    "print(\"\\nClasificador con pesos equilibrados:\")\n",
    "evaluate_classifier(clf_weighted, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código de soporte contiene la función `evaluate_classifier` que toma un clasificador entrenado y evalúa su rendimiento en el conjunto de prueba utilizando el informe de clasificación. Luego, se crean los clasificadores de regresión logística y se evalúan utilizando esta función.\n",
    "\n",
    "Recuerda que este es solo un ejemplo y que en situaciones reales, es posible que debas adaptar y ajustar los parámetros según tus necesidades específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datos de cáncer de mama**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de cáncer de mama son ampliamente utilizados en Machine Learning para tareas de clasificación y diagnóstico médico. Uno de los conjuntos de datos más populares es el conjunto de datos de Cáncer de Mama de Wisconsin (Breast Cancer Wisconsin dataset). Este conjunto de datos está disponible en la biblioteca Scikit-learn y también en el repositorio de Machine Learning de la UCI. A continuación, te mostraré cómo cargar y trabajar con este conjunto de datos utilizando Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 0.98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos de cáncer de mama\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear y entrenar el modelo de regresión logística\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)  # Aumentar max_iter\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, cargamos el conjunto de datos de cáncer de mama utilizando `load_breast_cancer` de Scikit-learn. Luego, dividimos los datos en conjuntos de entrenamiento y prueba. Utilizamos un clasificador de regresión logística para predecir si un tumor es benigno (0) o maligno (1). Finalmente, evaluamos el rendimiento del clasificador utilizando el informe de clasificación.\n",
    "\n",
    "Recuerda que este es solo un ejemplo básico. En aplicaciones más complejas, es posible que desees explorar otros algoritmos de clasificación, ajustar los hiperparámetros y realizar una validación cruzada para obtener una evaluación más sólida del rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Técnica de asignación de pesos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La técnica de asignación de pesos es una estrategia utilizada para tratar con conjuntos de datos desbalanceados, donde una clase tiene muchas más muestras que la otra. En tales casos, los algoritmos de aprendizaje automático pueden tener dificultades para aprender patrones en la clase minoritaria debido a su escasez. La asignación de pesos consiste en dar más importancia a las muestras de la clase minoritaria durante el entrenamiento, lo que ayuda a equilibrar la influencia de ambas clases en el modelo.\n",
    "\n",
    "Aquí hay un ejemplo de cómo implementar la técnica de asignación de pesos en un clasificador de regresión logística utilizando el conjunto de datos de cáncer de mama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo con asignación de pesos: 0.98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos de cáncer de mama\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Calcular los pesos de las clases\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = {0: class_counts[1] / class_counts[0], 1: 1.0}  # Ajustar los pesos según la proporción\n",
    "\n",
    "# Crear y entrenar el modelo de regresión logística con asignación de pesos\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000, class_weight=class_weights)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisión del modelo con asignación de pesos: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, los pesos de las clases se calculan en función de la proporción entre las clases en el conjunto de entrenamiento. Se utilizan estos pesos al crear el modelo de regresión logística utilizando el parámetro `class_weight`. La clase minoritaria recibe un peso mayor para darle más importancia durante el entrenamiento.\n",
    "\n",
    "La asignación de pesos puede ser una estrategia efectiva para mejorar el rendimiento de los modelos en conjuntos de datos desbalanceados, ya que ayuda a que el modelo preste más atención a la clase minoritaria y evita la dominación de la clase mayoritaria en el proceso de aprendizaje. Sin embargo, es importante ajustar los pesos de manera adecuada según las características del conjunto de datos específico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 9** | **Siguiente 11** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../README.md) | [⏪](./9_Tipos_de_Distancias.ipynb)| [⏩](./11_K-Vecinos.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
