{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 9** | **Siguiente 11** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../../README.md) | [](./9_Tipos_de_Distancias.ipynb)| [](./11_K-Vecinos.ipynb)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **10. C贸mo crear Clasificadores de Machine Learning ante Clases Desbalanceadas asignando Pesos con Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introducci贸n al problema**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando trabajamos con conjuntos de datos en los que las clases est谩n desbalanceadas, es decir, una clase tiene muchas m谩s muestras que las otras, es importante tomar medidas para manejar este desbalance. Una forma de abordar esto es asignar pesos diferentes a las clases durante el entrenamiento de un clasificador. Esto permite que el modelo penalice m谩s los errores en la clase minoritaria y, por lo tanto, tenga un mejor rendimiento en t茅rminos de precisi贸n y recall.\n",
    "\n",
    "Aqu铆 hay un ejemplo paso a paso de c贸mo crear clasificadores de Machine Learning ante clases desbalanceadas asignando pesos usando Python y la biblioteca Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador sin pesos:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       270\n",
      "           1       0.57      0.40      0.47        30\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.75      0.68      0.71       300\n",
      "weighted avg       0.90      0.91      0.90       300\n",
      "\n",
      "\n",
      "Clasificador con pesos equilibrados:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91       270\n",
      "           1       0.37      0.77      0.49        30\n",
      "\n",
      "    accuracy                           0.84       300\n",
      "   macro avg       0.67      0.81      0.70       300\n",
      "weighted avg       0.91      0.84      0.87       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Crear un conjunto de datos desbalanceado de ejemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear un clasificador de regresi贸n log铆stica sin ajustar pesos\n",
    "clf_unweighted = LogisticRegression(random_state=42)\n",
    "clf_unweighted.fit(X_train, y_train)\n",
    "\n",
    "# Crear un clasificador de regresi贸n log铆stica con pesos equilibrados\n",
    "clf_weighted = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "clf_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred_unweighted = clf_unweighted.predict(X_test)\n",
    "y_pred_weighted = clf_weighted.predict(X_test)\n",
    "\n",
    "# Mostrar los informes de clasificaci贸n para ambos clasificadores\n",
    "print(\"Clasificador sin pesos:\")\n",
    "print(classification_report(y_test, y_pred_unweighted))\n",
    "\n",
    "print(\"\\nClasificador con pesos equilibrados:\")\n",
    "print(classification_report(y_test, y_pred_weighted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, primero creamos un conjunto de datos desbalanceado de ejemplo usando `make_classification`. Luego, dividimos los datos en conjuntos de entrenamiento y prueba. A continuaci贸n, creamos dos clasificadores de regresi贸n log铆stica: uno sin ajustar pesos y otro con pesos equilibrados usando el par谩metro `class_weight='balanced'`.\n",
    "\n",
    "Finalmente, calculamos las predicciones en el conjunto de prueba para ambos clasificadores y mostramos los informes de clasificaci贸n que incluyen m茅tricas como precisi贸n, recall y F1-score para cada clase.\n",
    "\n",
    "La gr谩fica de c贸digo se mostrar谩 en una ventana emergente separada cuando ejecutes este c贸digo. Recuerda que el conjunto de datos utilizado aqu铆 es solo un ejemplo, y en problemas reales, debes ajustar los par谩metros y las t茅cnicas seg煤n las caracter铆sticas de tus datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Librer铆as y c贸digo de soporte**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el ejemplo anterior, se utilizaron varias bibliotecas de Python para crear clasificadores de Machine Learning para datos desbalanceados. Aqu铆 tienes una descripci贸n de las bibliotecas utilizadas y el c贸digo de soporte en forma de funciones:\n",
    "\n",
    "1. **Bibliotecas utilizadas:**\n",
    "   - `numpy`: Biblioteca para operaciones num茅ricas eficientes en Python.\n",
    "   - `matplotlib`: Biblioteca para crear gr谩ficos y visualizaciones.\n",
    "   - `sklearn.datasets`: M贸dulo de Scikit-learn para generar conjuntos de datos sint茅ticos.\n",
    "   - `sklearn.model_selection`: M贸dulo de Scikit-learn para dividir conjuntos de datos en entrenamiento y prueba.\n",
    "   - `sklearn.linear_model`: M贸dulo de Scikit-learn que contiene el modelo de regresi贸n log铆stica.\n",
    "   - `sklearn.metrics`: M贸dulo de Scikit-learn que contiene funciones para evaluar m茅tricas de rendimiento de modelos.\n",
    "\n",
    "2. **C贸digo de soporte:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clasificador sin pesos:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.95       270\n",
      "           1       0.57      0.40      0.47        30\n",
      "\n",
      "    accuracy                           0.91       300\n",
      "   macro avg       0.75      0.68      0.71       300\n",
      "weighted avg       0.90      0.91      0.90       300\n",
      "\n",
      "\n",
      "Clasificador con pesos equilibrados:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91       270\n",
      "           1       0.37      0.77      0.49        30\n",
      "\n",
      "    accuracy                           0.84       300\n",
      "   macro avg       0.67      0.81      0.70       300\n",
      "weighted avg       0.91      0.84      0.87       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Crear un conjunto de datos desbalanceado de ejemplo\n",
    "X, y = make_classification(n_samples=1000, n_features=20, weights=[0.9, 0.1], random_state=42)\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Funci贸n para evaluar y mostrar informe de clasificaci贸n\n",
    "def evaluate_classifier(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Crear un clasificador de regresi贸n log铆stica sin ajustar pesos\n",
    "clf_unweighted = LogisticRegression(random_state=42)\n",
    "clf_unweighted.fit(X_train, y_train)\n",
    "\n",
    "# Crear un clasificador de regresi贸n log铆stica con pesos equilibrados\n",
    "clf_weighted = LogisticRegression(class_weight='balanced', random_state=42)\n",
    "clf_weighted.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar y mostrar informe de clasificaci贸n para ambos clasificadores\n",
    "print(\"Clasificador sin pesos:\")\n",
    "evaluate_classifier(clf_unweighted, X_test, y_test)\n",
    "\n",
    "print(\"\\nClasificador con pesos equilibrados:\")\n",
    "evaluate_classifier(clf_weighted, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este c贸digo de soporte contiene la funci贸n `evaluate_classifier` que toma un clasificador entrenado y eval煤a su rendimiento en el conjunto de prueba utilizando el informe de clasificaci贸n. Luego, se crean los clasificadores de regresi贸n log铆stica y se eval煤an utilizando esta funci贸n.\n",
    "\n",
    "Recuerda que este es solo un ejemplo y que en situaciones reales, es posible que debas adaptar y ajustar los par谩metros seg煤n tus necesidades espec铆ficas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datos de c谩ncer de mama**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos de c谩ncer de mama son ampliamente utilizados en Machine Learning para tareas de clasificaci贸n y diagn贸stico m茅dico. Uno de los conjuntos de datos m谩s populares es el conjunto de datos de C谩ncer de Mama de Wisconsin (Breast Cancer Wisconsin dataset). Este conjunto de datos est谩 disponible en la biblioteca Scikit-learn y tambi茅n en el repositorio de Machine Learning de la UCI. A continuaci贸n, te mostrar茅 c贸mo cargar y trabajar con este conjunto de datos utilizando Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi贸n del modelo: 0.98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos de c谩ncer de mama\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Crear y entrenar el modelo de regresi贸n log铆stica\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000)  # Aumentar max_iter\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la precisi贸n del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisi贸n del modelo: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, cargamos el conjunto de datos de c谩ncer de mama utilizando `load_breast_cancer` de Scikit-learn. Luego, dividimos los datos en conjuntos de entrenamiento y prueba. Utilizamos un clasificador de regresi贸n log铆stica para predecir si un tumor es benigno (0) o maligno (1). Finalmente, evaluamos el rendimiento del clasificador utilizando el informe de clasificaci贸n.\n",
    "\n",
    "Recuerda que este es solo un ejemplo b谩sico. En aplicaciones m谩s complejas, es posible que desees explorar otros algoritmos de clasificaci贸n, ajustar los hiperpar谩metros y realizar una validaci贸n cruzada para obtener una evaluaci贸n m谩s s贸lida del rendimiento del modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **T茅cnica de asignaci贸n de pesos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La t茅cnica de asignaci贸n de pesos es una estrategia utilizada para tratar con conjuntos de datos desbalanceados, donde una clase tiene muchas m谩s muestras que la otra. En tales casos, los algoritmos de aprendizaje autom谩tico pueden tener dificultades para aprender patrones en la clase minoritaria debido a su escasez. La asignaci贸n de pesos consiste en dar m谩s importancia a las muestras de la clase minoritaria durante el entrenamiento, lo que ayuda a equilibrar la influencia de ambas clases en el modelo.\n",
    "\n",
    "Aqu铆 hay un ejemplo de c贸mo implementar la t茅cnica de asignaci贸n de pesos en un clasificador de regresi贸n log铆stica utilizando el conjunto de datos de c谩ncer de mama:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi贸n del modelo con asignaci贸n de pesos: 0.98\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Cargar el conjunto de datos de c谩ncer de mama\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Calcular los pesos de las clases\n",
    "class_counts = np.bincount(y_train)\n",
    "class_weights = {0: class_counts[1] / class_counts[0], 1: 1.0}  # Ajustar los pesos seg煤n la proporci贸n\n",
    "\n",
    "# Crear y entrenar el modelo de regresi贸n log铆stica con asignaci贸n de pesos\n",
    "clf = LogisticRegression(random_state=42, max_iter=1000, class_weight=class_weights)\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Predecir en el conjunto de prueba\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calcular la precisi贸n del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Precisi贸n del modelo con asignaci贸n de pesos: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, los pesos de las clases se calculan en funci贸n de la proporci贸n entre las clases en el conjunto de entrenamiento. Se utilizan estos pesos al crear el modelo de regresi贸n log铆stica utilizando el par谩metro `class_weight`. La clase minoritaria recibe un peso mayor para darle m谩s importancia durante el entrenamiento.\n",
    "\n",
    "La asignaci贸n de pesos puede ser una estrategia efectiva para mejorar el rendimiento de los modelos en conjuntos de datos desbalanceados, ya que ayuda a que el modelo preste m谩s atenci贸n a la clase minoritaria y evita la dominaci贸n de la clase mayoritaria en el proceso de aprendizaje. Sin embargo, es importante ajustar los pesos de manera adecuada seg煤n las caracter铆sticas del conjunto de datos espec铆fico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 9** | **Siguiente 11** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../../README.md) | [](./9_Tipos_de_Distancias.ipynb)| [](./11_K-Vecinos.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
