{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 11** | **Siguiente 13** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../README.md) | [⏪](./11_K-Vecinos.ipynb)| [⏩](./13_K-means.ipynb)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **12. Cross-validation (o Validación Cruzada) para Evaluar Modelos de Machine Learning con Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Evaluación tradicional**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada (cross-validation en inglés) es una técnica fundamental en la evaluación de modelos de machine learning para estimar su rendimiento de manera más robusta y precisa. Ayuda a evitar problemas de sobreajuste y proporciona una mejor estimación del rendimiento del modelo en datos no vistos. En esta explicación, te guiaré a través de los conceptos de la validación cruzada y te proporcionaré un ejemplo práctico utilizando Python y la librería Scikit-Learn.\n",
    "\n",
    "**Concepto de Validación Cruzada**:\n",
    "\n",
    "La validación cruzada implica dividir el conjunto de datos en múltiples subconjuntos llamados \"pliegues\" o \"folds\". Luego, se entrenan y evalúan los modelos en diferentes combinaciones de pliegues para estimar su rendimiento. El objetivo es obtener una medida más precisa y confiable del rendimiento general del modelo en datos no vistos.\n",
    "\n",
    "**Pasos de la Validación Cruzada**:\n",
    "\n",
    "1. **Dividir los datos**: Los datos se dividen en k pliegues (folds). Cada pliegue se utiliza como conjunto de prueba una vez, mientras que los restantes se utilizan para entrenamiento.\n",
    "\n",
    "2. **Entrenar y evaluar**: Se entrena el modelo en k-1 pliegues y se evalúa en el pliegue restante. Esto se repite k veces, utilizando cada pliegue como conjunto de prueba una vez.\n",
    "\n",
    "3. **Calcular métricas**: Se calculan las métricas de evaluación (por ejemplo, precisión, exactitud, F1-score) para cada iteración y se promedian para obtener una estimación del rendimiento del modelo.\n",
    "\n",
    "**Ejemplo de Validación Cruzada con Python**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaciones de validación cruzada: [0.96666667 0.96666667 0.93333333 0.96666667 1.        ]\n",
      "Precisión promedio: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Crear un modelo KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Realizar validación cruzada con 5 pliegues\n",
    "scores = cross_val_score(knn, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Imprimir las puntuaciones de cada pliegue\n",
    "print(\"Puntuaciones de validación cruzada:\", scores)\n",
    "\n",
    "# Calcular la precisión promedio\n",
    "average_accuracy = np.mean(scores)\n",
    "print(\"Precisión promedio:\", average_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, utilizamos el conjunto de datos Iris y un modelo KNN. La función `cross_val_score` realiza validación cruzada con 5 pliegues (cv=5) y utiliza la métrica de precisión (\"accuracy\") como medida de evaluación. La variable `scores` contiene las puntuaciones de cada pliegue, y luego calculamos la precisión promedio.\n",
    "\n",
    "**Ventajas de la Validación Cruzada**:\n",
    "\n",
    "- Proporciona una estimación más confiable del rendimiento del modelo en datos no vistos.\n",
    "- Ayuda a evitar problemas de sobreajuste y subajuste.\n",
    "- Utiliza todos los datos para entrenamiento y prueba en diferentes combinaciones.\n",
    "\n",
    "La validación cruzada es una técnica esencial para evaluar modelos de machine learning de manera robusta y confiable, lo que la convierte en una herramienta importante en el proceso de desarrollo y selección de modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Validación cruzada ¿Por qué?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada es una técnica fundamental en el proceso de evaluación de modelos de machine learning por varias razones clave:\n",
    "\n",
    "1. **Estimación robusta del rendimiento**: Al dividir los datos en múltiples pliegues y realizar evaluaciones en diferentes subconjuntos, la validación cruzada proporciona una estimación más robusta y precisa del rendimiento del modelo en datos no vistos. Esto ayuda a reducir la posibilidad de obtener una evaluación sesgada debido a una división específica de los datos.\n",
    "\n",
    "2. **Mejor uso de los datos**: La validación cruzada utiliza todos los datos tanto para entrenamiento como para prueba en diferentes iteraciones. Esto es especialmente útil cuando se dispone de un conjunto de datos limitado, ya que maximiza la utilización de los datos disponibles para la evaluación del modelo.\n",
    "\n",
    "3. **Evaluación del rendimiento real**: La validación cruzada proporciona una evaluación más realista del rendimiento del modelo en situaciones del mundo real. Cada iteración de prueba utiliza datos no vistos durante el entrenamiento, lo que permite evaluar cómo se comportará el modelo en situaciones reales de predicción.\n",
    "\n",
    "4. **Evitar sobreajuste y subajuste**: La validación cruzada ayuda a identificar si el modelo está sobreajustando o subajustando los datos. Si el modelo tiene un rendimiento consistente en diferentes pliegues, es más probable que esté generalizando bien.\n",
    "\n",
    "5. **Selección de hiperparámetros**: La validación cruzada es crucial para la selección de hiperparámetros óptimos. Permite comparar diferentes configuraciones de hiperparámetros y elegir la que proporciona el mejor rendimiento promedio en diferentes pliegues.\n",
    "\n",
    "6. **Información adicional**: La validación cruzada proporciona información adicional sobre la variabilidad del rendimiento del modelo. Las desviaciones estándar y las diferencias en las puntuaciones entre pliegues pueden dar una idea de la estabilidad del modelo en diferentes situaciones.\n",
    "\n",
    "En resumen, la validación cruzada es esencial para obtener una evaluación precisa y confiable del rendimiento de un modelo de machine learning. Proporciona una estimación más realista del rendimiento en datos no vistos y ayuda en la toma de decisiones informadas sobre la selección de modelos y configuraciones de hiperparámetros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Validación cruzada ¿Cómo?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La validación cruzada es un enfoque que implica dividir el conjunto de datos en múltiples partes, llamados pliegues o \"folds\", y luego realizar iteraciones en las que cada pliegue se utiliza alternativamente como conjunto de prueba mientras que los demás pliegues se utilizan como conjunto de entrenamiento. Esto nos permite obtener una estimación más precisa del rendimiento del modelo en datos no vistos.\n",
    "\n",
    "A continuación, te mostraré cómo realizar la validación cruzada en Python utilizando la librería scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pliegue 1: Precisión = 0.97\n",
      "Pliegue 2: Precisión = 1.00\n",
      "Pliegue 3: Precisión = 0.93\n",
      "Pliegue 4: Precisión = 0.90\n",
      "Pliegue 5: Precisión = 1.00\n",
      "Precisión promedio: 0.96\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Cargar el conjunto de datos (por ejemplo, Iris)\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Escalar los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Crear un modelo (por ejemplo, Regresión Logística)\n",
    "model = LogisticRegression(max_iter=1000)  # Aumentar el número de iteraciones\n",
    "\n",
    "# Realizar validación cruzada con 5 pliegues\n",
    "scores = cross_val_score(model, X_scaled, y, cv=5)\n",
    "\n",
    "# Imprimir los resultados de cada pliegue\n",
    "for i, score in enumerate(scores):\n",
    "    print(f\"Pliegue {i+1}: Precisión = {score:.2f}\")\n",
    "\n",
    "# Imprimir la precisión promedio\n",
    "print(f\"Precisión promedio: {np.mean(scores):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, utilizamos el conjunto de datos Iris y un modelo de Regresión Logística como ejemplo. `cross_val_score` realiza automáticamente la validación cruzada con el número de pliegues especificado (`cv=5` en este caso). El resultado es una lista de puntuaciones de precisión para cada pliegue.\n",
    "\n",
    "La validación cruzada se encarga de dividir los datos en pliegues, entrenar y evaluar el modelo en cada pliegue, y luego devuelve las puntuaciones de rendimiento para cada iteración. Finalmente, calculamos y mostramos la precisión promedio.\n",
    "\n",
    "Esta técnica permite obtener una mejor estimación del rendimiento del modelo en datos no vistos y es especialmente útil para evitar resultados sesgados debido a una división particular de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 11** | **Siguiente 13** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../README.md) | [⏪](./11_K-Vecinos.ipynb)| [⏩](./13_K-means.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
