{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 20** | **Siguiente 22** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../../README.md) | [](./20_%20Entropia_en_Machine_Learning.ipynb)| [](./22_Modelos_de_Regresion.ipynb)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **21. Identifica Patrones y extrae Reglas de Asociaci贸n con el Algoritmo APRIORI usando Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introducci贸n**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo Apriori es un algoritmo de miner铆a de datos utilizado para identificar patrones y extraer reglas de asociaci贸n en conjuntos de datos. Las reglas de asociaci贸n son relaciones entre elementos en un conjunto de datos que ocurren con cierta frecuencia. El algoritmo Apriori busca patrones frecuentes en los datos y los utiliza para generar reglas de asociaci贸n.\n",
    "\n",
    "La idea principal detr谩s del algoritmo Apriori es que si un conjunto de elementos es frecuente (aparece con frecuencia en el conjunto de datos), entonces sus subconjuntos tambi茅n deben ser frecuentes. El algoritmo se basa en el principio del \"apriori\", que significa que si un conjunto de elementos satisface un umbral m铆nimo de frecuencia, entonces cualquier subconjunto de ese conjunto tambi茅n debe satisfacer el umbral de frecuencia.\n",
    "\n",
    "Aqu铆 hay una explicaci贸n general de c贸mo funciona el algoritmo Apriori:\n",
    "\n",
    "1. **Generar conjuntos de un solo elemento:** El algoritmo comienza generando conjuntos de un solo elemento que ocurren con una frecuencia mayor o igual al umbral m铆nimo.\n",
    "\n",
    "2. **Combinar conjuntos para obtener conjuntos m谩s grandes:** El algoritmo combina los conjuntos de un solo elemento para formar conjuntos m谩s grandes (de dos elementos, tres elementos, etc.). Luego, verifica la frecuencia de estos conjuntos y descarta aquellos que no cumplen con el umbral m铆nimo.\n",
    "\n",
    "3. **Repetir el proceso:** El algoritmo repite el proceso de combinar y verificar la frecuencia hasta que ya no es posible generar conjuntos m谩s grandes que cumplan con el umbral m铆nimo.\n",
    "\n",
    "4. **Generar reglas de asociaci贸n:** Una vez que se han identificado los conjuntos frecuentes, el algoritmo genera reglas de asociaci贸n a partir de estos conjuntos. Una regla de asociaci贸n generalmente toma la forma de \"Si A, entonces B\", donde A y B son conjuntos de elementos.\n",
    "\n",
    "Vamos a ver un ejemplo simple de c贸mo usar el algoritmo Apriori en Python utilizando la biblioteca `mlxtend`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         antecedents       consequents  antecedent support  \\\n",
      "0            (Leche)             (Pan)                 0.8   \n",
      "1              (Pan)           (Leche)                 0.8   \n",
      "2          (Cerveza)           (Leche)                 0.4   \n",
      "3            (Leche)         (Cerveza)                 0.8   \n",
      "4          (Cerveza)             (Pan)                 0.4   \n",
      "5              (Pan)         (Cerveza)                 0.8   \n",
      "6   (Cerveza, Leche)             (Pan)                 0.4   \n",
      "7     (Cerveza, Pan)           (Leche)                 0.4   \n",
      "8       (Leche, Pan)         (Cerveza)                 0.6   \n",
      "9          (Cerveza)      (Leche, Pan)                 0.4   \n",
      "10           (Leche)    (Cerveza, Pan)                 0.8   \n",
      "11             (Pan)  (Cerveza, Leche)                 0.8   \n",
      "\n",
      "    consequent support  support  confidence      lift  leverage  conviction  \\\n",
      "0                  0.8      0.6    0.750000  0.937500     -0.04         0.8   \n",
      "1                  0.8      0.6    0.750000  0.937500     -0.04         0.8   \n",
      "2                  0.8      0.4    1.000000  1.250000      0.08         inf   \n",
      "3                  0.4      0.4    0.500000  1.250000      0.08         1.2   \n",
      "4                  0.8      0.4    1.000000  1.250000      0.08         inf   \n",
      "5                  0.4      0.4    0.500000  1.250000      0.08         1.2   \n",
      "6                  0.8      0.4    1.000000  1.250000      0.08         inf   \n",
      "7                  0.8      0.4    1.000000  1.250000      0.08         inf   \n",
      "8                  0.4      0.4    0.666667  1.666667      0.16         1.8   \n",
      "9                  0.6      0.4    1.000000  1.666667      0.16         inf   \n",
      "10                 0.4      0.4    0.500000  1.250000      0.08         1.2   \n",
      "11                 0.4      0.4    0.500000  1.250000      0.08         1.2   \n",
      "\n",
      "    zhangs_metric  \n",
      "0       -0.250000  \n",
      "1       -0.250000  \n",
      "2        0.333333  \n",
      "3        1.000000  \n",
      "4        0.333333  \n",
      "5        1.000000  \n",
      "6        0.333333  \n",
      "7        0.333333  \n",
      "8        1.000000  \n",
      "9        0.666667  \n",
      "10       1.000000  \n",
      "11       1.000000  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "\n",
    "# Ejemplo de datos\n",
    "data = {'ID': [1, 2, 3, 4, 5],\n",
    "        'Leche': [1, 1, 0, 1, 1],\n",
    "        'Pan': [1, 1, 1, 1, 0],\n",
    "        'Cerveza': [0, 1, 0, 1, 0]}\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(data, columns=['ID', 'Leche', 'Pan', 'Cerveza'])\n",
    "df.set_index('ID', inplace=True)\n",
    "\n",
    "# Aplicar el algoritmo Apriori\n",
    "frequent_itemsets = apriori(df, min_support=0.2, use_colnames=True)\n",
    "rules = association_rules(frequent_itemsets, metric='lift', min_threshold=0.5)\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, estamos utilizando un conjunto de datos simple que representa compras de productos. Aplicamos el algoritmo Apriori para encontrar conjuntos frecuentes y luego generamos reglas de asociaci贸n utilizando el umbral de elevaci贸n (`lift`) como criterio. El resultado ser谩 un conjunto de reglas de asociaci贸n que muestran la relaci贸n entre los productos comprados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Reglas de asociaci贸n**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las reglas de asociaci贸n son un concepto importante en el an谩lisis de datos y la miner铆a de datos, especialmente en el 谩mbito del comercio minorista y el estudio de patrones de compra. Estas reglas permiten identificar relaciones significativas entre diferentes elementos en un conjunto de datos, lo que puede ayudar a tomar decisiones informadas y estrat茅gicas.\n",
    "\n",
    "En esencia, las reglas de asociaci贸n se refieren a relaciones entre conjuntos de elementos en los que la presencia de ciertos elementos en un conjunto (llamado \"antecedente\") implica la presencia de otros elementos en otro conjunto (llamado \"consecuente\"). Estas reglas se expresan en forma de declaraciones \"si-entonces\", donde \"si\" representa el antecedente y \"entonces\" representa el consecuente.\n",
    "\n",
    "El algoritmo Apriori es una t茅cnica popular para descubrir estas reglas de asociaci贸n en grandes conjuntos de datos. A continuaci贸n, un ejemplo detallado para comprender mejor el concepto de reglas de asociaci贸n:\n",
    "\n",
    "Supongamos que tenemos una tienda minorista y deseamos analizar los patrones de compra de los clientes para identificar relaciones entre los productos que suelen comprar juntos. Para esto, contamos con un registro de transacciones de compra que incluye los productos comprados por cada cliente.\n",
    "\n",
    "Ejemplo de transacciones:\n",
    "\n",
    "```\n",
    "Transacci贸n 1: Pan, Leche, Huevos\n",
    "Transacci贸n 2: Leche, Huevos, Queso\n",
    "Transacci贸n 3: Pan, Leche, Huevos, Queso\n",
    "Transacci贸n 4: Leche, Huevos\n",
    "```\n",
    "\n",
    "Ahora, utilizando el algoritmo Apriori, podemos identificar las reglas de asociaci贸n. Supongamos que estamos interesados en encontrar reglas con un nivel de confianza m铆nimo del 70% y un soporte m铆nimo del 50%.\n",
    "\n",
    "Regla de asociaci贸n: Pan -> Huevos (Confianza: 100%, Soporte: 25%)\n",
    "Esto significa que el 25% de las transacciones incluye pan y huevos, y todas las transacciones que contienen pan tambi茅n contienen huevos.\n",
    "\n",
    "Regla de asociaci贸n: Leche, Huevos -> Queso (Confianza: 100%, Soporte: 25%)\n",
    "Esta regla indica que el 25% de las transacciones incluye leche y huevos, y todas las transacciones que contienen leche y huevos tambi茅n contienen queso.\n",
    "\n",
    "Estas reglas de asociaci贸n nos permiten comprender mejor los h谩bitos de compra de los clientes. Por ejemplo, podr铆amos utilizar esta informaci贸n para colocar productos relacionados cerca uno del otro en la tienda, mejorar la estrategia de precios o promociones, y personalizar las recomendaciones de productos para los clientes.\n",
    "\n",
    "En resumen, las reglas de asociaci贸n son una herramienta poderosa para descubrir patrones y relaciones ocultas en conjuntos de datos, lo que puede llevar a decisiones comerciales m谩s informadas y estrat茅gicas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Algoritmo Apriori**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo Apriori es una t茅cnica fundamental en miner铆a de datos y an谩lisis de datos que se utiliza para descubrir reglas de asociaci贸n entre elementos en conjuntos de datos. El algoritmo busca patrones en los datos para identificar qu茅 elementos tienden a aparecer juntos en transacciones o conjuntos de datos. Esta informaci贸n es valiosa para comprender relaciones entre elementos y tomar decisiones informadas en 谩reas como el comercio minorista, el an谩lisis de cestas de compra y la recomendaci贸n de productos.\n",
    "\n",
    "**Funcionamiento del algoritmo Apriori:**\n",
    "\n",
    "1. **Definici贸n de soporte m铆nimo:** El algoritmo comienza con la definici贸n de un soporte m铆nimo, que es el umbral que establece la frecuencia m铆nima con la que un conjunto de elementos debe aparecer en los datos para considerarse relevante. Por ejemplo, si el soporte m铆nimo es 0.2 (20%), el algoritmo buscar谩 conjuntos de elementos que aparezcan en al menos el 20% de las transacciones.\n",
    "\n",
    "2. **Generaci贸n de conjuntos candidatos:** Inicialmente, el algoritmo identifica los elementos individuales que cumplen con el soporte m铆nimo. Luego, genera conjuntos de elementos candidatos que tienen un tama帽o mayor, combinando elementos individuales. Estos conjuntos candidatos son generados a trav茅s de un proceso llamado \"join\" y \"prune\", donde se unen conjuntos m谩s peque帽os y se eliminan aquellos que no cumplen con el soporte m铆nimo.\n",
    "\n",
    "3. **C谩lculo de soporte:** El algoritmo calcula el soporte de cada conjunto candidato, es decir, la frecuencia con la que aparece en los datos.\n",
    "\n",
    "4. **Filtrado por soporte m铆nimo:** Los conjuntos candidatos que no cumplen con el soporte m铆nimo son descartados.\n",
    "\n",
    "5. **Generaci贸n de reglas de asociaci贸n:** Con los conjuntos que pasaron el filtrado por soporte m铆nimo, el algoritmo genera reglas de asociaci贸n al evaluar diferentes combinaciones de antecedentes y consecuentes. Se calcula la confianza de cada regla, que representa la probabilidad de que el consecuente ocurra cuando el antecedente est谩 presente.\n",
    "\n",
    "6. **Filtrado por confianza m铆nima:** Las reglas de asociaci贸n que no cumplen con una confianza m铆nima predefinida tambi茅n son descartadas.\n",
    "\n",
    "**Ejemplo de Apriori:**\n",
    "\n",
    "Supongamos que tenemos datos de transacciones en una tienda y queremos encontrar reglas de asociaci贸n. Aqu铆 est谩n algunas transacciones ficticias:\n",
    "\n",
    "```\n",
    "Transacci贸n 1: Pan, Leche\n",
    "Transacci贸n 2: Leche, Huevos, Queso\n",
    "Transacci贸n 3: Pan, Huevos, Queso\n",
    "Transacci贸n 4: Leche, Huevos\n",
    "Transacci贸n 5: Pan, Leche, Huevos, Queso\n",
    "```\n",
    "\n",
    "Si establecemos un soporte m铆nimo del 40% y una confianza m铆nima del 60%, el proceso del algoritmo Apriori ser铆a:\n",
    "\n",
    "1. Identificaci贸n de elementos individuales: Pan, Leche, Huevos, Queso.\n",
    "\n",
    "2. Generaci贸n de conjuntos candidatos: {Pan, Leche}, {Pan, Huevos}, {Pan, Queso}, {Leche, Huevos}, {Leche, Queso}, {Huevos, Queso}.\n",
    "\n",
    "3. C谩lculo de soporte: Los conjuntos candidatos se eval煤an para determinar su frecuencia.\n",
    "\n",
    "4. Filtrado por soporte m铆nimo: Se descartan los conjuntos que no cumplen con el soporte m铆nimo.\n",
    "\n",
    "5. Generaci贸n de reglas de asociaci贸n: Se generan las reglas con diferentes antecedentes y consecuentes, y se calcula la confianza.\n",
    "\n",
    "6. Filtrado por confianza m铆nima: Se descartan las reglas que no cumplen con la confianza m铆nima.\n",
    "\n",
    "Al final del proceso, podr铆amos obtener reglas de asociaci贸n como:\n",
    "- {Pan} -> {Leche} (Confianza: 100%, Soporte: 40%)\n",
    "- {Huevos} -> {Queso} (Confianza: 100%, Soporte: 40%)\n",
    "- {Leche, Huevos} -> {Queso} (Confianza: 100%, Soporte: 40%)\n",
    "\n",
    "Estas reglas indican patrones de compra en la tienda, como la tendencia de los clientes a comprar queso cuando compran huevos.\n",
    "\n",
    "En resumen, el algoritmo Apriori es una herramienta poderosa para descubrir reglas de asociaci贸n en conjuntos de datos, lo que puede ayudar a comprender patrones y tomar decisiones informadas en diversos campos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datos de transacciones**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por supuesto, aqu铆 tienes un conjunto de datos ficticio que representa transacciones en una tienda. Usaremos estos datos para ilustrar c贸mo funciona el algoritmo Apriori y c贸mo se extraen reglas de asociaci贸n.\n",
    "\n",
    "```plaintext\n",
    "Transacci贸n 1: Pan, Leche, Huevos\n",
    "Transacci贸n 2: Leche, Huevos, Queso\n",
    "Transacci贸n 3: Pan, Huevos, Queso\n",
    "Transacci贸n 4: Leche, Huevos\n",
    "Transacci贸n 5: Pan, Leche, Huevos, Queso\n",
    "Transacci贸n 6: Pan, Leche, Queso\n",
    "Transacci贸n 7: Leche, Huevos\n",
    "Transacci贸n 8: Pan, Leche, Huevos, Queso\n",
    "Transacci贸n 9: Pan, Queso\n",
    "Transacci贸n 10: Leche, Huevos, Queso\n",
    "```\n",
    "\n",
    "Ahora, podemos utilizar la biblioteca `mlxtend` de Python para aplicar el algoritmo Apriori a estos datos y extraer reglas de asociaci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reglas de Asociaci贸n:\n",
      "                            antecedents                        consequents  \\\n",
      "0                    (Producto2_Huevos)                  (Producto1_Leche)   \n",
      "1                     (Producto1_Leche)                 (Producto2_Huevos)   \n",
      "2                       (Producto1_Pan)                  (Producto2_Leche)   \n",
      "3                     (Producto2_Leche)                    (Producto1_Pan)   \n",
      "4                    (Producto3_Huevos)                    (Producto1_Pan)   \n",
      "5                     (Producto3_Queso)                 (Producto2_Huevos)   \n",
      "6                    (Producto2_Huevos)                  (Producto3_Queso)   \n",
      "7                    (Producto3_Huevos)                  (Producto2_Leche)   \n",
      "8                     (Producto2_Leche)                 (Producto3_Huevos)   \n",
      "9     (Producto1_Pan, Producto3_Huevos)                  (Producto2_Leche)   \n",
      "10     (Producto1_Pan, Producto2_Leche)                 (Producto3_Huevos)   \n",
      "11  (Producto2_Leche, Producto3_Huevos)                    (Producto1_Pan)   \n",
      "12                   (Producto3_Huevos)   (Producto1_Pan, Producto2_Leche)   \n",
      "13                    (Producto2_Leche)  (Producto1_Pan, Producto3_Huevos)   \n",
      "\n",
      "    antecedent support  consequent support  support  confidence      lift  \\\n",
      "0                  0.5                 0.4      0.4    0.800000  2.000000   \n",
      "1                  0.4                 0.5      0.4    1.000000  2.000000   \n",
      "2                  0.6                 0.4      0.4    0.666667  1.666667   \n",
      "3                  0.4                 0.6      0.4    1.000000  1.666667   \n",
      "4                  0.3                 0.6      0.3    1.000000  1.666667   \n",
      "5                  0.4                 0.5      0.3    0.750000  1.500000   \n",
      "6                  0.5                 0.4      0.3    0.600000  1.500000   \n",
      "7                  0.3                 0.4      0.3    1.000000  2.500000   \n",
      "8                  0.4                 0.3      0.3    0.750000  2.500000   \n",
      "9                  0.3                 0.4      0.3    1.000000  2.500000   \n",
      "10                 0.4                 0.3      0.3    0.750000  2.500000   \n",
      "11                 0.3                 0.6      0.3    1.000000  1.666667   \n",
      "12                 0.3                 0.4      0.3    1.000000  2.500000   \n",
      "13                 0.4                 0.3      0.3    0.750000  2.500000   \n",
      "\n",
      "    leverage  conviction  zhangs_metric  \n",
      "0       0.20         3.0       1.000000  \n",
      "1       0.20         inf       0.833333  \n",
      "2       0.16         1.8       1.000000  \n",
      "3       0.16         inf       0.666667  \n",
      "4       0.12         inf       0.571429  \n",
      "5       0.10         2.0       0.555556  \n",
      "6       0.10         1.5       0.666667  \n",
      "7       0.18         inf       0.857143  \n",
      "8       0.18         2.8       1.000000  \n",
      "9       0.18         inf       0.857143  \n",
      "10      0.18         2.8       1.000000  \n",
      "11      0.12         inf       0.571429  \n",
      "12      0.18         inf       0.857143  \n",
      "13      0.18         2.8       1.000000  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import pandas as pd\n",
    "\n",
    "# Crear el dataframe de transacciones\n",
    "data = [\n",
    "    ['Pan', 'Leche', 'Huevos'],\n",
    "    ['Leche', 'Huevos', 'Queso'],\n",
    "    ['Pan', 'Huevos', 'Queso'],\n",
    "    ['Leche', 'Huevos'],\n",
    "    ['Pan', 'Leche', 'Huevos', 'Queso'],\n",
    "    ['Pan', 'Leche', 'Queso'],\n",
    "    ['Leche', 'Huevos'],\n",
    "    ['Pan', 'Leche', 'Huevos', 'Queso'],\n",
    "    ['Pan', 'Queso'],\n",
    "    ['Leche', 'Huevos', 'Queso']\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data, columns=['Producto1', 'Producto2', 'Producto3', 'Producto4'])\n",
    "\n",
    "# Codificar los productos como valores binarios\n",
    "df_encoded = pd.get_dummies(df)\n",
    "\n",
    "# Aplicar el algoritmo Apriori\n",
    "frequent_itemsets = apriori(df_encoded, min_support=0.3, use_colnames=True)\n",
    "\n",
    "# Generar reglas de asociaci贸n\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
    "\n",
    "print(\"Reglas de Asociaci贸n:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, estamos utilizando un soporte m铆nimo del 30% y una confianza m铆nima del 60% para extraer las reglas de asociaci贸n. Las reglas resultantes mostrar谩n qu茅 productos tienden a aparecer juntos en las transacciones. Puedes ajustar estos valores seg煤n tus necesidades y los datos que est茅s utilizando.\n",
    "\n",
    "Las reglas de asociaci贸n resultantes te dar谩n informaci贸n sobre qu茅 productos suelen comprarse juntos y con qu茅 nivel de confianza. Esto puede ser 煤til para comprender los patrones de compra de los clientes y tomar decisiones informadas sobre la disposici贸n de los productos en la tienda, estrategias de promoci贸n, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conjuntos de elementos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un conjunto de elementos, tambi茅n conocido como conjunto de 铆tems, es una colecci贸n de elementos 煤nicos y no ordenados. En el contexto del algoritmo Apriori y las reglas de asociaci贸n, estos conjuntos de elementos representan los productos o art铆culos que se compran en una transacci贸n o registro.\n",
    "\n",
    "En el algoritmo Apriori, los conjuntos de elementos son esenciales para descubrir patrones y relaciones de asociaci贸n en los datos. Cada conjunto de elementos representa un grupo de productos que se compraron juntos en una transacci贸n espec铆fica. El algoritmo busca conjuntos de elementos que ocurren con una frecuencia m铆nima (umbral de soporte) en el conjunto de datos.\n",
    "\n",
    "Por ejemplo, si consideramos un conjunto de transacciones de compras en un supermercado:\n",
    "\n",
    "1. Transacci贸n: Pan, Leche, Huevos\n",
    "2. Transacci贸n: Leche, Huevos, Queso\n",
    "3. Transacci贸n: Pan, Huevos, Queso\n",
    "4. ...\n",
    "\n",
    "Los conjuntos de elementos ser铆an {Pan, Leche, Huevos}, {Leche, Huevos, Queso}, {Pan, Huevos, Queso}, etc. El algoritmo Apriori analiza estos conjuntos de elementos para identificar patrones de compra frecuentes y generar reglas de asociaci贸n, como \"Si se compra Pan y Leche, entonces es probable que tambi茅n se compren Huevos\".\n",
    "\n",
    "Estos conjuntos de elementos son la base para el c谩lculo de la frecuencia de soporte, confianza, lift y otras m茅tricas que se utilizan para generar reglas de asociaci贸n significativas.\n",
    "\n",
    "En resumen, los conjuntos de elementos son una representaci贸n fundamental en el algoritmo Apriori para descubrir patrones y reglas de asociaci贸n a partir de conjuntos de datos transaccionales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Soporte de un conjunto**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El soporte de un conjunto de elementos en el contexto del algoritmo Apriori y las reglas de asociaci贸n es una medida que indica la frecuencia con la que aparece ese conjunto en el conjunto total de transacciones. En otras palabras, el soporte mide la proporci贸n de transacciones que contienen ese conjunto de elementos en relaci贸n con el total de transacciones.\n",
    "\n",
    "El c谩lculo del soporte se expresa generalmente como un porcentaje y se utiliza para determinar la popularidad de un conjunto de elementos en los datos. Un alto valor de soporte indica que el conjunto de elementos es com煤n y se compra con frecuencia, mientras que un valor bajo de soporte sugiere que el conjunto de elementos es menos frecuente.\n",
    "\n",
    "La f贸rmula para calcular el soporte de un conjunto de elementos es la siguiente:\n",
    "\n",
    "Soporte(X) = (N煤mero de transacciones que contienen X) / (Total de transacciones)\n",
    "\n",
    "Donde:\n",
    "\n",
    "- X es el conjunto de elementos que se est谩 evaluando.\n",
    "- El numerador es el n煤mero de transacciones que contienen el conjunto de elementos X.\n",
    "- El denominador es el total de transacciones en el conjunto de datos.\n",
    "\n",
    "Un umbral de soporte se establece como criterio para considerar un conjunto de elementos como frecuente. Si el soporte de un conjunto de elementos es igual o mayor que el umbral de soporte establecido, se considera que el conjunto es frecuente y es candidato para la generaci贸n de reglas de asociaci贸n.\n",
    "\n",
    "Por ejemplo, si tenemos un conjunto de transacciones de un supermercado y queremos calcular el soporte del conjunto {Leche, Pan}:\n",
    "\n",
    "- N煤mero de transacciones que contienen {Leche, Pan} = 25\n",
    "- Total de transacciones = 100\n",
    "- Soporte({Leche, Pan}) = 25 / 100 = 0.25\n",
    "\n",
    "En este caso, el soporte del conjunto {Leche, Pan} es 0.25, lo que significa que este conjunto de elementos aparece en el 25% de las transacciones.\n",
    "\n",
    "El umbral de soporte se elige seg煤n el an谩lisis de los datos y el objetivo del estudio. Conjuntos con un soporte igual o mayor al umbral se consideran significativos para la generaci贸n de reglas de asociaci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Conjuntos de elementos frecuentes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el contexto del algoritmo Apriori y las reglas de asociaci贸n, los conjuntos de elementos frecuentes son aquellos conjuntos cuyo soporte es igual o mayor que un umbral predefinido. Estos conjuntos son de inter茅s porque representan combinaciones de elementos que ocurren con suficiente frecuencia en el conjunto de datos. Los conjuntos de elementos frecuentes son la base para generar reglas de asociaci贸n, ya que son los candidatos que pueden conducir a reglas con alta confianza.\n",
    "\n",
    "El proceso de encontrar conjuntos de elementos frecuentes se denomina \"miner铆a de conjuntos de elementos frecuentes\" o \"mining frequent itemsets\". La idea es buscar combinaciones de elementos que cumplan con el umbral de soporte establecido. El algoritmo Apriori es uno de los m茅todos m谩s comunes para realizar esta tarea.\n",
    "\n",
    "El algoritmo Apriori opera en iteraciones, donde cada iteraci贸n busca conjuntos de elementos de tama帽o n+1 basados en conjuntos de elementos de tama帽o n que se consideran frecuentes en la iteraci贸n anterior. El proceso contin煤a hasta que no se pueden encontrar m谩s conjuntos de elementos frecuentes.\n",
    "\n",
    "Un ejemplo de conjuntos de elementos frecuentes podr铆a ser:\n",
    "\n",
    "Supongamos que tenemos un conjunto de transacciones de un supermercado:\n",
    "\n",
    "```\n",
    "Transacci贸n 1: Leche, Pan, Huevos\n",
    "Transacci贸n 2: Leche, Pan\n",
    "Transacci贸n 3: Leche, Huevos\n",
    "Transacci贸n 4: Pan, Huevos\n",
    "Transacci贸n 5: Leche\n",
    "```\n",
    "\n",
    "Si establecemos un umbral de soporte del 40%, los conjuntos de elementos frecuentes ser铆an aquellos que aparecen en al menos 2 de las 5 transacciones (40% de 5). En este caso, los conjuntos de elementos frecuentes ser铆an {Leche, Pan}, {Leche, Huevos}, {Pan, Huevos} y {Leche}.\n",
    "\n",
    "Estos conjuntos de elementos frecuentes son los candidatos a partir de los cuales se pueden generar reglas de asociaci贸n con alta confianza. Por ejemplo, si tenemos el conjunto frecuente {Leche, Pan}, podr铆amos generar la regla {Leche} -> {Pan} si la confianza de la regla es lo suficientemente alta.\n",
    "\n",
    "En resumen, los conjuntos de elementos frecuentes son combinaciones de elementos que ocurren con suficiente frecuencia en los datos y son la base para generar reglas de asociaci贸n en el proceso de miner铆a de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Creaci贸n de reglas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La creaci贸n de reglas de asociaci贸n implica identificar patrones interesantes y significativos entre los conjuntos de elementos frecuentes. Estas reglas se expresan en la forma de \"antecedentes\" y \"consecuentes\", donde los antecedentes son un conjunto de elementos y los consecuentes son otro conjunto de elementos. La idea es encontrar reglas que muestren relaciones fuertes entre los elementos antecedentes y consecuentes basados en el soporte y la confianza.\n",
    "\n",
    "En el contexto del algoritmo Apriori, las reglas de asociaci贸n se generan a partir de los conjuntos de elementos frecuentes encontrados previamente. Para cada conjunto frecuente, se pueden generar varias reglas de asociaci贸n considerando diferentes combinaciones de antecedentes y consecuentes. Sin embargo, no todas estas reglas ser谩n interesantes o significativas.\n",
    "\n",
    "Las m茅tricas clave utilizadas para evaluar la calidad de las reglas de asociaci贸n son el soporte, la confianza y el lift:\n",
    "\n",
    "1. Soporte: Mide la frecuencia con la que ocurre una regla en el conjunto de datos. Es la proporci贸n de transacciones que contienen tanto el antecedente como el consecuente.\n",
    "\n",
    "2. Confianza: Mide la probabilidad de que el consecuente ocurra dado que el antecedente ya ha ocurrido. Es la proporci贸n de transacciones que contienen tanto el antecedente como el consecuente con respecto a las transacciones que contienen el antecedente.\n",
    "\n",
    "3. Lift: Mide cu谩nto m谩s probable es que ocurra el consecuente dado el antecedente en comparaci贸n con si fueran independientes. Un lift mayor que 1 indica una relaci贸n positiva entre el antecedente y el consecuente.\n",
    "\n",
    "El proceso de creaci贸n de reglas de asociaci贸n implica:\n",
    "\n",
    "1. Tomar cada conjunto frecuente y generar todas las combinaciones posibles de antecedentes y consecuentes.\n",
    "\n",
    "2. Calcular el soporte y la confianza para cada regla.\n",
    "\n",
    "3. Filtrar las reglas basadas en umbrales de soporte y confianza predefinidos.\n",
    "\n",
    "4. Opcionalmente, evaluar el lift para identificar relaciones interesantes y significativas.\n",
    "\n",
    "5. Presentar las reglas de asociaci贸n que cumplen con los criterios establecidos.\n",
    "\n",
    "Un ejemplo de regla de asociaci贸n podr铆a ser:\n",
    "\n",
    "Conjunto frecuente: {Leche, Pan}\n",
    "Regla: {Leche} -> {Pan}\n",
    "Soporte: 0.4 (40% de las transacciones contienen tanto Leche como Pan)\n",
    "Confianza: 0.8 (80% de las transacciones que contienen Leche tambi茅n contienen Pan)\n",
    "Lift: 1.33 (Pan es 1.33 veces m谩s probable dado que Leche ya ha ocurrido)\n",
    "\n",
    "En resumen, la creaci贸n de reglas de asociaci贸n implica encontrar patrones interesantes entre los conjuntos de elementos frecuentes utilizando m茅tricas como el soporte, la confianza y el lift. Estas reglas pueden proporcionar informaci贸n valiosa sobre las relaciones entre los elementos en un conjunto de datos, lo que puede ser 煤til en la toma de decisiones y en la generaci贸n de estrategias de marketing y ventas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **M茅tricas para las reglas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el contexto de las reglas de asociaci贸n, existen varias m茅tricas que se utilizan para evaluar la calidad y la relevancia de las reglas generadas por algoritmos como Apriori. Estas m茅tricas ayudan a identificar qu茅 reglas son interesantes y significativas en funci贸n de la frecuencia de los elementos y las relaciones entre ellos. Algunas de las m茅tricas m谩s comunes son:\n",
    "\n",
    "1. Soporte:\n",
    "El soporte de una regla es la proporci贸n de transacciones en las que aparecen tanto el antecedente como el consecuente. Cuanto mayor sea el soporte, m谩s frecuente es la regla en el conjunto de datos. Una regla con alto soporte indica que es com煤n y puede no ser muy interesante por s铆 sola.\n",
    "\n",
    "2. Confianza:\n",
    "La confianza de una regla mide la probabilidad de que ocurra el consecuente dado que ya ha ocurrido el antecedente. Una alta confianza indica una relaci贸n fuerte entre los elementos antecedentes y consecuentes. La confianza se calcula dividiendo el soporte conjunto de antecedente y consecuente entre el soporte del antecedente.\n",
    "\n",
    "3. Lift (Elevaci贸n):\n",
    "El lift mide cu谩nto m谩s probable es que ocurra el consecuente dado el antecedente en comparaci贸n con si fueran independientes. Un lift mayor que 1 indica que el consecuente es m谩s probable dado el antecedente. Un lift igual a 1 significa que el antecedente y el consecuente son independientes. El lift se calcula dividiendo el soporte conjunto de antecedente y consecuente entre el producto de los soportes del antecedente y el consecuente.\n",
    "\n",
    "4. Leverage (Apalancamiento):\n",
    "El leverage mide la diferencia entre el soporte conjunto de antecedente y consecuente y el producto de los soportes del antecedente y el consecuente. Un leverage mayor que 0 indica que los elementos antecedentes y consecuentes tienden a aparecer juntos m谩s de lo esperado si fueran independientes.\n",
    "\n",
    "5. Conviction:\n",
    "La convicci贸n mide cu谩nto m谩s probable es que ocurra el consecuente dado que no ocurri贸 el antecedente. Cuanto mayor sea la convicci贸n, m谩s fuerte es la relaci贸n entre el antecedente y el consecuente. La convicci贸n se calcula dividiendo el soporte del consecuente entre el complemento de la confianza del antecedente.\n",
    "\n",
    "Estas m茅tricas ayudan a los analistas a filtrar y seleccionar reglas de asociaci贸n relevantes y 煤tiles. Sin embargo, es importante recordar que no existe una m茅trica 煤nica que sea adecuada para todos los casos. La elecci贸n de las m茅tricas depende del contexto y los objetivos del an谩lisis. En algunos casos, puede ser necesario usar varias m茅tricas en conjunto para tomar decisiones informadas sobre qu茅 reglas son valiosas y merecen atenci贸n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Soporte de una regla**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El soporte de una regla de asociaci贸n es una m茅trica que indica la proporci贸n de transacciones en un conjunto de datos en las que aparecen tanto el antecedente como el consecuente de esa regla. En otras palabras, el soporte mide la frecuencia con la que la regla se cumple en relaci贸n con el total de transacciones.\n",
    "\n",
    "La f贸rmula para calcular el soporte de una regla es la siguiente:\n",
    "\n",
    "$\\text{Soporte}(\\text{antecedente} \\rightarrow \\text{consecuente}) = \\frac{\\text{N煤mero de transacciones que contienen antecedente y consecuente}}{\\text{Total de transacciones en el conjunto de datos}}$\n",
    "\n",
    "D贸nde:\n",
    "\n",
    "- N煤mero de transacciones que contienen antecedente y consecuente es la cantidad de transacciones en las que se encuentran tanto el antecedente como el consecuente de la regla.\n",
    "- Total de transacciones en el conjunto de datos es la cantidad total de transacciones en el conjunto de datos.\n",
    "\n",
    "Un alto valor de soporte indica que la regla es com煤n en el conjunto de datos, mientras que un valor bajo de soporte sugiere que la regla es menos com煤n.\n",
    "\n",
    "Vamos a ilustrar esto con un ejemplo:\n",
    "\n",
    "Supongamos que tenemos un conjunto de datos de transacciones que registra la compra de productos en una tienda. Queremos calcular el soporte de la regla de asociaci贸n \"Leche -> Pan\", lo que significa que queremos determinar la frecuencia con la que los clientes compran leche y pan juntos.\n",
    "\n",
    "- N煤mero de transacciones que contienen \"Leche\" y \"Pan\": 25 transacciones\n",
    "- Total de transacciones en el conjunto de datos: 100 transacciones\n",
    "\n",
    "$\\text{Soporte}(\\text{Leche} \\rightarrow \\text{Pan}) = \\frac{25}{100} = 0.25$\n",
    "\n",
    "En este caso, el soporte de la regla \"Leche -> Pan\" es 0.25, lo que significa que el 25% de las transacciones en el conjunto de datos contienen tanto leche como pan.\n",
    "\n",
    "El soporte es una medida importante en el an谩lisis de reglas de asociaci贸n, ya que nos ayuda a identificar qu茅 reglas son frecuentes y, por lo tanto, potencialmente interesantes para comprender patrones de comportamiento en los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Confianza de una regla**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La confianza de una regla de asociaci贸n es una m茅trica que indica la probabilidad de que el consecuente ocurra dado que el antecedente ya ha ocurrido. En otras palabras, mide la proporci贸n de veces que el consecuente aparece en las transacciones en las que el antecedente tambi茅n aparece.\n",
    "\n",
    "La f贸rmula para calcular la confianza de una regla es la siguiente:\n",
    "\n",
    "$\\text{Confianza}(\\text{antecedente} \\rightarrow \\text{consecuente}) = \\frac{\\text{N煤mero de transacciones que contienen antecedente y consecuente}}{\\text{N煤mero de transacciones que contienen antecedente}}$\n",
    "\n",
    "D贸nde:\n",
    "\n",
    "- N煤mero de transacciones que contienen antecedente y consecuente es la cantidad de transacciones en las que se encuentran tanto el antecedente como el consecuente de la regla.\n",
    "- N煤mero de transacciones que contienen antecedente es la cantidad de transacciones en las que se encuentra el antecedente de la regla.\n",
    "\n",
    "La confianza var铆a entre 0 y 1, donde 1 indica una confianza completa, lo que significa que el consecuente siempre ocurre cuando el antecedente est谩 presente en una transacci贸n.\n",
    "\n",
    "Vamos a usar el mismo ejemplo para ilustrar esto:\n",
    "\n",
    "Supongamos que queremos calcular la confianza de la regla \"Leche -> Pan\" en nuestro conjunto de datos de transacciones.\n",
    "\n",
    "- N煤mero de transacciones que contienen \"Leche\" y \"Pan\": 25 transacciones\n",
    "- N煤mero de transacciones que contienen \"Leche\": 40 transacciones\n",
    "\n",
    "$\\text{Confianza}(\\text{Leche} \\rightarrow \\text{Pan}) = \\frac{25}{40} = 0.625$\n",
    "\n",
    "En este caso, la confianza de la regla \"Leche -> Pan\" es 0.625, lo que significa que el 62.5% de las veces que los clientes compran leche tambi茅n compran pan.\n",
    "\n",
    "La confianza es una medida 煤til para evaluar cu谩n s贸lida es una regla y cu谩nta informaci贸n nueva proporciona el consecuente una vez que se ha observado el antecedente. Sin embargo, la confianza por s铆 sola no considera la frecuencia de ocurrencia del consecuente por s铆 mismo, lo que puede llevar a interpretaciones sesgadas en ciertos casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Lift de una regla**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Lift (elevaci贸n) es una m茅trica utilizada en el an谩lisis de reglas de asociaci贸n para evaluar la importancia y la fuerza de una regla en t茅rminos de la relaci贸n entre el antecedente y el consecuente. El Lift compara la confianza observada de una regla con la confianza esperada en caso de que el antecedente y el consecuente fueran independientes. En esencia, el Lift nos dice cu谩nto m谩s probable es que ocurra el consecuente cuando se cumple el antecedente en comparaci贸n con su ocurrencia aleatoria.\n",
    "\n",
    "La f贸rmula para calcular el Lift de una regla es la siguiente:\n",
    "\n",
    "$\\text{Lift}(\\text{antecedente} \\rightarrow \\text{consecuente}) = \\frac{\\text{Confianza}(\\text{antecedente} \\rightarrow \\text{consecuente})}{\\text{Soporte}(\\text{consecuente})}$\n",
    "\n",
    "D贸nde:\n",
    "\n",
    "- Confianza($\\text{antecedente} \\rightarrow \\text{consecuente}$) es la confianza de la regla entre el antecedente y el consecuente.\n",
    "\n",
    "- Soporte($\\text{consecuente}$) es el soporte del consecuente, es decir, la proporci贸n de transacciones en las que aparece el consecuente.\n",
    "\n",
    "El Lift tiene los siguientes valores posibles:\n",
    "- Lift > 1: Indica que la ocurrencia del antecedente aumenta la probabilidad de ocurrencia del consecuente. Cuanto mayor es el Lift, m谩s fuerte es la relaci贸n.\n",
    "- Lift = 1: Indica que el antecedente y el consecuente son independientes, ya que la confianza observada es igual a la confianza esperada en caso de independencia.\n",
    "- Lift < 1: Indica que la ocurrencia del antecedente disminuye la probabilidad de ocurrencia del consecuente.\n",
    "\n",
    "Vamos a utilizar el mismo ejemplo para ilustrar esto:\n",
    "\n",
    "Supongamos que queremos calcular el Lift de la regla \"Leche -> Pan\" en nuestro conjunto de datos de transacciones.\n",
    "\n",
    "- Confianza(\\text{Leche} \\rightarrow \\text{Pan}) = 0.625 (calculado previamente)\n",
    "- Soporte(\\text{Pan}) = 70 / 100 = 0.7 (el 70% de las transacciones contiene pan)\n",
    "\n",
    "$\\text{Lift}(\\text{Leche} \\rightarrow \\text{Pan}) = \\frac{0.625}{0.7} \\approx 0.893$\n",
    "\n",
    "En este caso, el Lift de la regla \"Leche -> Pan\" es aproximadamente 0.893. Esto indica que la ocurrencia de \"Leche\" disminuye la probabilidad de que ocurra \"Pan\". Un Lift menor a 1 sugiere que esta regla podr铆a no ser tan significativa en t茅rminos de asociaci贸n entre los productos.\n",
    "\n",
    "El Lift es una m茅trica importante ya que permite comprender si una regla es m谩s que simplemente el resultado de una ocurrencia aleatoria. Si el Lift es significativamente mayor a 1, es posible que la regla sea 煤til para tomar decisiones basadas en patrones de compra reales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Algoritmo Apriori con Python**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El algoritmo Apriori es ampliamente utilizado para la extracci贸n de reglas de asociaci贸n en conjuntos de datos transaccionales. Aqu铆 te mostrar茅 c贸mo implementar el algoritmo Apriori utilizando la biblioteca `mlxtend` en Python.\n",
    "\n",
    "Antes de comenzar, aseg煤rate de tener la biblioteca `mlxtend` instalada. Puedes instalarla usando el siguiente comando si a煤n no lo has hecho:\n",
    "\n",
    "```bash\n",
    "pip install mlxtend\n",
    "```\n",
    "\n",
    "Ahora, vamos a implementar el algoritmo Apriori en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/mlxtend/frequent_patterns/fpcommon.py:110: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjuntos de elementos frecuentes:\n",
      "   support              itemsets\n",
      "0      0.8              (Huevos)\n",
      "1      0.8               (Leche)\n",
      "2      0.8                 (Pan)\n",
      "3      0.6       (Huevos, Leche)\n",
      "4      0.6         (Huevos, Pan)\n",
      "5      0.6          (Leche, Pan)\n",
      "6      0.4  (Huevos, Leche, Pan)\n",
      "\n",
      "Reglas de asociaci贸n:\n",
      "       antecedents consequents  antecedent support  consequent support  \\\n",
      "0         (Huevos)     (Leche)                 0.8                 0.8   \n",
      "1          (Leche)    (Huevos)                 0.8                 0.8   \n",
      "2         (Huevos)       (Pan)                 0.8                 0.8   \n",
      "3            (Pan)    (Huevos)                 0.8                 0.8   \n",
      "4          (Leche)       (Pan)                 0.8                 0.8   \n",
      "5            (Pan)     (Leche)                 0.8                 0.8   \n",
      "6  (Huevos, Leche)       (Pan)                 0.6                 0.8   \n",
      "7    (Huevos, Pan)     (Leche)                 0.6                 0.8   \n",
      "8     (Leche, Pan)    (Huevos)                 0.6                 0.8   \n",
      "\n",
      "   support  confidence      lift  leverage  conviction  zhangs_metric  \n",
      "0      0.6    0.750000  0.937500     -0.04         0.8      -0.250000  \n",
      "1      0.6    0.750000  0.937500     -0.04         0.8      -0.250000  \n",
      "2      0.6    0.750000  0.937500     -0.04         0.8      -0.250000  \n",
      "3      0.6    0.750000  0.937500     -0.04         0.8      -0.250000  \n",
      "4      0.6    0.750000  0.937500     -0.04         0.8      -0.250000  \n",
      "5      0.6    0.750000  0.937500     -0.04         0.8      -0.250000  \n",
      "6      0.4    0.666667  0.833333     -0.08         0.6      -0.333333  \n",
      "7      0.4    0.666667  0.833333     -0.08         0.6      -0.333333  \n",
      "8      0.4    0.666667  0.833333     -0.08         0.6      -0.333333  \n"
     ]
    }
   ],
   "source": [
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "import pandas as pd\n",
    "\n",
    "# Crear el dataframe de transacciones (ejemplo)\n",
    "data = {'Transaccion': ['T1', 'T2', 'T3', 'T4', 'T5'],\n",
    "        'Productos': [['Leche', 'Pan', 'Huevos'],\n",
    "                      ['Leche', 'Pan'],\n",
    "                      ['Leche', 'Huevos'],\n",
    "                      ['Pan', 'Huevos'],\n",
    "                      ['Leche', 'Pan', 'Huevos']]}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convertir la lista de productos en un conjunto para cada transacci贸n\n",
    "df['Productos'] = df['Productos'].apply(set)\n",
    "\n",
    "# Crear un DataFrame de ceros y unos para representar la presencia de productos en cada transacci贸n\n",
    "oht = df['Productos'].apply(lambda x: pd.Series([1 if item in x else 0 for item in df['Productos'][0]]))\n",
    "oht.columns = df['Productos'][0]\n",
    "\n",
    "# Aplicar el algoritmo Apriori\n",
    "frequent_itemsets = apriori(oht, min_support=0.4, use_colnames=True)\n",
    "\n",
    "# Imprimir los conjuntos de elementos frecuentes\n",
    "print(\"Conjuntos de elementos frecuentes:\")\n",
    "print(frequent_itemsets)\n",
    "\n",
    "# Generar las reglas de asociaci贸n\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.6)\n",
    "\n",
    "# Imprimir las reglas de asociaci贸n\n",
    "print(\"\\nReglas de asociaci贸n:\")\n",
    "print(rules)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, hemos creado un DataFrame `df` que contiene las transacciones y los conjuntos de productos correspondientes. Luego, convertimos las listas de productos en conjuntos para que el algoritmo Apriori pueda trabajar con ellas.\n",
    "\n",
    "Usamos la funci贸n `apriori` para encontrar los conjuntos de elementos frecuentes con un umbral de soporte m铆nimo de 0.4. Luego, utilizamos la funci贸n `association_rules` para generar las reglas de asociaci贸n con un umbral m铆nimo de confianza del 60%.\n",
    "\n",
    "La salida mostrar谩 los conjuntos de elementos frecuentes y las reglas de asociaci贸n encontradas.\n",
    "\n",
    "Recuerda que este es solo un ejemplo simple. En aplicaciones pr谩cticas, puedes usar conjuntos de datos m谩s grandes y ajustar los par谩metros del algoritmo seg煤n tus necesidades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 20** | **Siguiente 22** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../../README.md) | [](./20_%20Entropia_en_Machine_Learning.ipynb)| [](./22_Modelos_de_Regresion.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
