{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 8** | **Siguiente 10** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../../README.md) | [](./8.Reduccion_de_la_dimensi%C3%B3n.ipynb)| [](./10.Gradiente_Descendente.ipynb)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **9. Selecci贸n de Modelos & Boosting**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Selecci贸n de Modelos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La selecci贸n de modelos es una parte fundamental del proceso de machine learning. Consiste en elegir el modelo de aprendizaje autom谩tico que mejor se ajusta a los datos y proporciona las mejores predicciones. En general, se desea seleccionar un modelo que tenga una buena capacidad de generalizaci贸n, es decir, que sea capaz de hacer predicciones precisas en datos que no ha visto antes.\n",
    "\n",
    "Hay varias t茅cnicas para seleccionar modelos, algunas de las cuales se describen a continuaci贸n:\n",
    "\n",
    "**1. Validaci贸n cruzada:**\n",
    "\n",
    " esta t茅cnica implica dividir los datos en `k` partes iguales. Se entrena el modelo en `k-1` partes y se eval煤a en la parte restante. Este proceso se repite `k` veces, de modo que cada parte se utiliza como conjunto de prueba exactamente una vez. Al final, se calcula el promedio de las m茅tricas de evaluaci贸n (por ejemplo, precisi贸n, exactitud, F1) para todas las `k` iteraciones. La validaci贸n cruzada puede ayudar a evaluar la capacidad de generalizaci贸n de un modelo y seleccionar el mejor modelo en funci贸n de las m茅tricas de evaluaci贸n.\n",
    "\n",
    "**2. Validaci贸n de retenci贸n:**\n",
    "\n",
    " esta t茅cnica implica dividir los datos en dos partes, un conjunto de entrenamiento y un conjunto de prueba. El modelo se entrena en el conjunto de entrenamiento y se eval煤a en el conjunto de prueba. La validaci贸n de retenci贸n puede ser 煤til cuando se tienen muchos datos y la validaci贸n cruzada es computacionalmente costosa.\n",
    "\n",
    "**3. Selecci贸n basada en la complejidad del modelo:**\n",
    "\n",
    " a veces, se desea seleccionar un modelo simple en lugar de uno complejo. Esto se debe a que los modelos complejos pueden sobreajustarse a los datos de entrenamiento, lo que significa que se ajustan demasiado a ellos y no generalizan bien. Una forma de seleccionar un modelo m谩s simple es utilizar regularizaci贸n, que agrega una penalizaci贸n por la complejidad del modelo a la funci贸n de p茅rdida que se optimiza durante el entrenamiento.\n",
    "\n",
    "A continuaci贸n, se presenta un ejemplo de c贸mo se puede usar la validaci贸n cruzada para seleccionar el mejor modelo de regresi贸n log铆stica en funci贸n de la precisi贸n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi贸n media: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Cargar los datos\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Crear un modelo de regresi贸n log铆stica\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Validaci贸n cruzada con 5 iteraciones\n",
    "scores = cross_val_score(lr, X, y, cv=5)\n",
    "\n",
    "# Imprimir la precisi贸n media\n",
    "print(\"Precisi贸n media:\", scores.mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este c贸digo carga el conjunto de datos de `iris`, crea un modelo de regresi贸n log铆stica y utiliza la validaci贸n cruzada con 5 iteraciones para calcular la precisi贸n media del modelo. Se puede modificar el c贸digo para probar otros modelos y m茅tricas de evaluaci贸n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La selecci贸n de modelos en el 谩rea de machine learning es el proceso de elegir el mejor modelo de aprendizaje autom谩tico para un conjunto de datos determinado. Este proceso implica la comparaci贸n de varios modelos de aprendizaje autom谩tico y la elecci贸n del modelo que tenga el mejor rendimiento en el conjunto de datos.\n",
    "\n",
    "Existen varias t茅cnicas para seleccionar modelos de aprendizaje autom谩tico. Algunas de ellas son:\n",
    "\n",
    "**1. Validaci贸n cruzada:**\n",
    "\n",
    " es una t茅cnica que se utiliza para evaluar el rendimiento de un modelo en un conjunto de datos. La validaci贸n cruzada implica dividir el conjunto de datos en varios subconjuntos y entrenar el modelo en cada uno de ellos, utilizando el resto para evaluar el rendimiento. Esto ayuda a evitar el sobreajuste y a evaluar el rendimiento del modelo de manera m谩s precisa.\n",
    "\n",
    "**2. Selecci贸n de caracter铆sticas:**\n",
    "\n",
    " esta t茅cnica implica seleccionar las caracter铆sticas m谩s importantes del conjunto de datos para entrenar el modelo. Esto ayuda a mejorar la precisi贸n del modelo y reducir el tiempo de entrenamiento. La selecci贸n de caracter铆sticas se puede hacer utilizando t茅cnicas como la eliminaci贸n recursiva de caracter铆sticas y la selecci贸n de caracter铆sticas basada en 谩rboles.\n",
    "\n",
    "**3. Comparaci贸n de modelos:**\n",
    "\n",
    " esta t茅cnica implica comparar varios modelos de aprendizaje autom谩tico para elegir el que tenga el mejor rendimiento en el conjunto de datos. Para comparar los modelos, se pueden utilizar m茅tricas como la precisi贸n, la sensibilidad, la especificidad y la F1-score.\n",
    "\n",
    "A continuaci贸n se muestra un ejemplo de selecci贸n de modelos utilizando validaci贸n cruzada y comparaci贸n de modelos en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi贸n modelo 1: 0.96 (+/- 0.07)\n",
      "Precisi贸n modelo 2: 0.97 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Cargar conjunto de datos\n",
    "iris = load_iris()\n",
    "\n",
    "# Crear modelos\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "\n",
    "# Validaci贸n cruzada\n",
    "scores1 = cross_val_score(model1, iris.data, iris.target, cv=5)\n",
    "scores2 = cross_val_score(model2, iris.data, iris.target, cv=5)\n",
    "\n",
    "# Comparaci贸n de modelos\n",
    "print(\"Precisi贸n modelo 1: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std() * 2))\n",
    "print(\"Precisi贸n modelo 2: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo se cargan los datos de `iris` y se crean dos modelos: un clasificador de 谩rbol de decisi贸n y un clasificador `k-NN`. Luego, se utiliza la validaci贸n cruzada para evaluar el rendimiento de cada modelo en el conjunto de datos y se comparan los resultados. En la salida del c贸digo se puede ver la precisi贸n media de cada modelo y la desviaci贸n est谩ndar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **XGBoost**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost es una biblioteca de aprendizaje autom谩tico de c贸digo abierto que se utiliza para tareas de regresi贸n, clasificaci贸n y clasificaci贸n multiclase. XGBoost significa Extreme Gradient Boosting, lo que sugiere que es una versi贸n mejorada del algoritmo de refuerzo de gradiente est谩ndar. Se basa en el algoritmo de refuerzo de gradiente, que implica la creaci贸n secuencial de 谩rboles de decisi贸n ponderados, donde cada nuevo 谩rbol corrige los errores cometidos por los 谩rboles previos.\n",
    "\n",
    "XGBoost es extremadamente popular en el aprendizaje autom谩tico, ya que es muy preciso y se puede utilizar para una amplia gama de tareas, incluyendo la regresi贸n y la clasificaci贸n. Tambi茅n es altamente escalable y eficiente en t茅rminos de memoria y CPU, lo que lo hace adecuado para conjuntos de datos grandes.\n",
    "\n",
    "A continuaci贸n se presenta un ejemplo de c贸mo utilizar XGBoost en Python para un problema de clasificaci贸n binaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisi贸n: 93.00%\n"
     ]
    }
   ],
   "source": [
    "# Importar librer铆as\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Crear conjunto de datos\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear modelo de XGBoost\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Entrenar modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar precisi贸n del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisi贸n: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este c贸digo primero crea un conjunto de datos de clasificaci贸n binaria utilizando la funci贸n `make_classification` de `Scikit-learn`. Luego divide el conjunto de datos en entrenamiento y prueba utilizando la funci贸n `train_test_split`. Luego, crea un modelo de clasificaci贸n `XGBoost` utilizando `XGBClassifier` y lo entrena en el conjunto de entrenamiento utilizando el m茅todo `fit`. Finalmente, hace predicciones en el conjunto de prueba utilizando el m茅todo `predict`, eval煤a la precisi贸n del modelo utilizando la m茅trica de precisi贸n y la imprime en la pantalla.\n",
    "\n",
    "`XGBoost` tambi茅n proporciona una forma de visualizar la importancia de las caracter铆sticas en el modelo utilizando el m茅todo `plot_importance`. Aqu铆 hay un ejemplo de c贸mo hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar importancia de caracter铆sticas\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Plot feature importance\n",
    "plot_importance(model)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este c贸digo genera una gr谩fica que muestra la importancia de las caracter铆sticas en el modelo. Esta informaci贸n puede ser 煤til para determinar qu茅 caracter铆sticas son m谩s importantes para el modelo y si se deben considerar otras caracter铆sticas o se deben eliminar algunas de las caracter铆sticas existentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **k-Fold Cross Validation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `k-Fold Cross Validation` es una t茅cnica utilizada en machine learning para evaluar el rendimiento de un modelo en t茅rminos de su capacidad de generalizaci贸n. El objetivo de la t茅cnica es estimar el rendimiento de un modelo entrenado en un conjunto de datos, y evaluar su capacidad para generalizar a nuevos datos.\n",
    "\n",
    "En resumen, el k-Fold Cross Validation divide el conjunto de datos en `k` partes iguales (k es un n煤mero entero), y entrena y eval煤a el modelo `k` veces, cada vez utilizando una parte diferente como conjunto de validaci贸n y las restantes `k-1` partes como conjunto de entrenamiento. El resultado final es la media de las m茅tricas de rendimiento de cada una de las `k` iteraciones.\n",
    "\n",
    "A continuaci贸n, se muestra un ejemplo de c贸mo se puede implementar el k-Fold Cross Validation en Python utilizando la biblioteca `Scikit-Learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuaci贸n media de precisi贸n: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "iris = load_iris()\n",
    "\n",
    "# Dividir el conjunto de datos en k partes iguales\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Inicializar la lista de puntuaciones de precisi贸n\n",
    "scores = []\n",
    "\n",
    "# Iterar sobre cada una de las k iteraciones\n",
    "for train_index, test_index in kf.split(iris.data):\n",
    "    # Dividir el conjunto de datos en conjuntos de entrenamiento y validaci贸n\n",
    "    X_train, X_test = iris.data[train_index], iris.data[test_index]\n",
    "    y_train, y_test = iris.target[train_index], iris.target[test_index]\n",
    "    \n",
    "    # Inicializar el modelo y ajustarlo al conjunto de entrenamiento\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de validaci贸n y agregar la puntuaci贸n a la lista\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calcular la puntuaci贸n media de precisi贸n\n",
    "mean_score = sum(scores) / len(scores)\n",
    "\n",
    "print(\"Puntuaci贸n media de precisi贸n:\", mean_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se utiliza el conjunto de datos de flores `Iris` para demostrar c贸mo funciona el k-Fold Cross Validation. El conjunto de datos se divide en `5` partes iguales utilizando la clase `KFold` de `Scikit-Learn`, y se entrena y eval煤a un modelo de regresi贸n log铆stica en cada una de las `5` iteraciones. Al final, se calcula la puntuaci贸n media de precisi贸n de todas las iteraciones, que es una medida del rendimiento general del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Grid Search**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Grid Search es una t茅cnica de optimizaci贸n de hiperpar谩metros en machine learning que permite encontrar la mejor combinaci贸n de valores de hiperpar谩metros para un modelo espec铆fico. En t茅rminos simples, se trata de un proceso de prueba y error en el que se buscan los valores 贸ptimos de los hiperpar谩metros mediante la evaluaci贸n de diferentes combinaciones de valores.\n",
    "\n",
    "En lugar de probar diferentes valores de hiperpar谩metros manualmente, el Grid Search automatiza el proceso evaluando sistem谩ticamente todas las combinaciones posibles de valores de hiperpar谩metros. Por ejemplo, si un modelo tiene tres hiperpar谩metros, el Grid Search probar谩 todas las posibles combinaciones de valores de los tres hiperpar谩metros.\n",
    "\n",
    "A continuaci贸n se presenta un ejemplo de c贸mo realizar un Grid Search para optimizar los hiperpar谩metros de un modelo de regresi贸n log铆stica utilizando la biblioteca `scikit-learn` en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "70 fits failed out of a total of 105.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.92970036        nan        nan 0.92797702        nan\n",
      "        nan 0.94201211        nan        nan 0.93676448        nan\n",
      "        nan 0.93496351        nan        nan 0.94555193        nan\n",
      "        nan 0.93676448        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperpar谩metros:  {'C': 100, 'penalty': 'l2'}\n",
      "Puntaje del modelo con mejores hiperpar谩metros:  0.9455519329296692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Cargar los datos\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Crear el modelo de regresi贸n log铆stica\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Definir la cuadr铆cula de hiperpar谩metros para Grid Search\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'penalty': ['l1', 'l2', 'elasticnet']}\n",
    "\n",
    "# Realizar Grid Search con validaci贸n cruzada de 5 pliegues\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# Entrenar el modelo con Grid Search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Imprimir los mejores hiperpar谩metros y puntajes\n",
    "print(\"Mejores hiperpar谩metros: \", grid_search.best_params_)\n",
    "print(\"Puntaje del modelo con mejores hiperpar谩metros: \", grid_search.best_score_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se utiliza el conjunto de datos de c谩ncer de mama de la biblioteca `scikit-learn`. Se crea un modelo de regresi贸n log铆stica y se define una cuadr铆cula de hiperpar谩metros que contiene diferentes valores para los hiperpar谩metros `C` y `penalty`. Luego, se utiliza el Grid Search para encontrar los mejores valores de los hiperpar谩metros utilizando la validaci贸n cruzada de 5 pliegues. Finalmente, se imprime el conjunto de mejores hiperpar谩metros y el puntaje del modelo utilizando estos hiperpar谩metros.\n",
    "\n",
    "La siguiente gr谩fica muestra c贸mo se realizar铆a el Grid Search para dos hiperpar谩metros diferentes, donde cada punto representa una combinaci贸n de valores de hiperpar谩metros y el eje z muestra el puntaje de validaci贸n cruzada correspondiente:\n",
    "\n",
    "En resumen, el Grid Search es una t茅cnica 煤til para encontrar los mejores valores de hiperpar谩metros en un modelo de machine learning mediante la evaluaci贸n sistem谩tica de todas las posibles combinaciones de valores de hiperpar谩metros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Accuracy:  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos de ejemplo\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Definir cuadr铆cula de hiperpar谩metros\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': [0.1, 1, 10]}\n",
    "\n",
    "# Crear modelo SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Crear objeto Grid Search\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "\n",
    "# Ajustar Grid Search a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperpar谩metros\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Utilizar el modelo SVM con los mejores par谩metros para predecir las clases del conjunto de pruebas\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr谩s 8** | **Siguiente 10** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [](../../README.md) | [](./8.Reduccion_de_la_dimensi%C3%B3n.ipynb)| [](./10.Gradiente_Descendente.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
