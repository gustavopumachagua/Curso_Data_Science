{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 8** | **Siguiente 10** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../README.md) | [⏪](./8.Reduccion_de_la_dimensi%C3%B3n.ipynb)| [⏩](./10.Gradiente_Descendente.ipynb)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **9. Selección de Modelos & Boosting**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Selección de Modelos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La selección de modelos es una parte fundamental del proceso de machine learning. Consiste en elegir el modelo de aprendizaje automático que mejor se ajusta a los datos y proporciona las mejores predicciones. En general, se desea seleccionar un modelo que tenga una buena capacidad de generalización, es decir, que sea capaz de hacer predicciones precisas en datos que no ha visto antes.\n",
    "\n",
    "Hay varias técnicas para seleccionar modelos, algunas de las cuales se describen a continuación:\n",
    "\n",
    "**1. Validación cruzada:**\n",
    "\n",
    " esta técnica implica dividir los datos en `k` partes iguales. Se entrena el modelo en `k-1` partes y se evalúa en la parte restante. Este proceso se repite `k` veces, de modo que cada parte se utiliza como conjunto de prueba exactamente una vez. Al final, se calcula el promedio de las métricas de evaluación (por ejemplo, precisión, exactitud, F1) para todas las `k` iteraciones. La validación cruzada puede ayudar a evaluar la capacidad de generalización de un modelo y seleccionar el mejor modelo en función de las métricas de evaluación.\n",
    "\n",
    "**2. Validación de retención:**\n",
    "\n",
    " esta técnica implica dividir los datos en dos partes, un conjunto de entrenamiento y un conjunto de prueba. El modelo se entrena en el conjunto de entrenamiento y se evalúa en el conjunto de prueba. La validación de retención puede ser útil cuando se tienen muchos datos y la validación cruzada es computacionalmente costosa.\n",
    "\n",
    "**3. Selección basada en la complejidad del modelo:**\n",
    "\n",
    " a veces, se desea seleccionar un modelo simple en lugar de uno complejo. Esto se debe a que los modelos complejos pueden sobreajustarse a los datos de entrenamiento, lo que significa que se ajustan demasiado a ellos y no generalizan bien. Una forma de seleccionar un modelo más simple es utilizar regularización, que agrega una penalización por la complejidad del modelo a la función de pérdida que se optimiza durante el entrenamiento.\n",
    "\n",
    "A continuación, se presenta un ejemplo de cómo se puede usar la validación cruzada para seleccionar el mejor modelo de regresión logística en función de la precisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión media: 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Cargar los datos\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Crear un modelo de regresión logística\n",
    "lr = LogisticRegression()\n",
    "\n",
    "# Validación cruzada con 5 iteraciones\n",
    "scores = cross_val_score(lr, X, y, cv=5)\n",
    "\n",
    "# Imprimir la precisión media\n",
    "print(\"Precisión media:\", scores.mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código carga el conjunto de datos de `iris`, crea un modelo de regresión logística y utiliza la validación cruzada con 5 iteraciones para calcular la precisión media del modelo. Se puede modificar el código para probar otros modelos y métricas de evaluación."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La selección de modelos en el área de machine learning es el proceso de elegir el mejor modelo de aprendizaje automático para un conjunto de datos determinado. Este proceso implica la comparación de varios modelos de aprendizaje automático y la elección del modelo que tenga el mejor rendimiento en el conjunto de datos.\n",
    "\n",
    "Existen varias técnicas para seleccionar modelos de aprendizaje automático. Algunas de ellas son:\n",
    "\n",
    "**1. Validación cruzada:**\n",
    "\n",
    " es una técnica que se utiliza para evaluar el rendimiento de un modelo en un conjunto de datos. La validación cruzada implica dividir el conjunto de datos en varios subconjuntos y entrenar el modelo en cada uno de ellos, utilizando el resto para evaluar el rendimiento. Esto ayuda a evitar el sobreajuste y a evaluar el rendimiento del modelo de manera más precisa.\n",
    "\n",
    "**2. Selección de características:**\n",
    "\n",
    " esta técnica implica seleccionar las características más importantes del conjunto de datos para entrenar el modelo. Esto ayuda a mejorar la precisión del modelo y reducir el tiempo de entrenamiento. La selección de características se puede hacer utilizando técnicas como la eliminación recursiva de características y la selección de características basada en árboles.\n",
    "\n",
    "**3. Comparación de modelos:**\n",
    "\n",
    " esta técnica implica comparar varios modelos de aprendizaje automático para elegir el que tenga el mejor rendimiento en el conjunto de datos. Para comparar los modelos, se pueden utilizar métricas como la precisión, la sensibilidad, la especificidad y la F1-score.\n",
    "\n",
    "A continuación se muestra un ejemplo de selección de modelos utilizando validación cruzada y comparación de modelos en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión modelo 1: 0.96 (+/- 0.07)\n",
      "Precisión modelo 2: 0.97 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Cargar conjunto de datos\n",
    "iris = load_iris()\n",
    "\n",
    "# Crear modelos\n",
    "model1 = DecisionTreeClassifier()\n",
    "model2 = KNeighborsClassifier()\n",
    "\n",
    "# Validación cruzada\n",
    "scores1 = cross_val_score(model1, iris.data, iris.target, cv=5)\n",
    "scores2 = cross_val_score(model2, iris.data, iris.target, cv=5)\n",
    "\n",
    "# Comparación de modelos\n",
    "print(\"Precisión modelo 1: %0.2f (+/- %0.2f)\" % (scores1.mean(), scores1.std() * 2))\n",
    "print(\"Precisión modelo 2: %0.2f (+/- %0.2f)\" % (scores2.mean(), scores2.std() * 2))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo se cargan los datos de `iris` y se crean dos modelos: un clasificador de árbol de decisión y un clasificador `k-NN`. Luego, se utiliza la validación cruzada para evaluar el rendimiento de cada modelo en el conjunto de datos y se comparan los resultados. En la salida del código se puede ver la precisión media de cada modelo y la desviación estándar."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **XGBoost**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost es una biblioteca de aprendizaje automático de código abierto que se utiliza para tareas de regresión, clasificación y clasificación multiclase. XGBoost significa Extreme Gradient Boosting, lo que sugiere que es una versión mejorada del algoritmo de refuerzo de gradiente estándar. Se basa en el algoritmo de refuerzo de gradiente, que implica la creación secuencial de árboles de decisión ponderados, donde cada nuevo árbol corrige los errores cometidos por los árboles previos.\n",
    "\n",
    "XGBoost es extremadamente popular en el aprendizaje automático, ya que es muy preciso y se puede utilizar para una amplia gama de tareas, incluyendo la regresión y la clasificación. También es altamente escalable y eficiente en términos de memoria y CPU, lo que lo hace adecuado para conjuntos de datos grandes.\n",
    "\n",
    "A continuación se presenta un ejemplo de cómo utilizar XGBoost en Python para un problema de clasificación binaria:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión: 93.00%\n"
     ]
    }
   ],
   "source": [
    "# Importar librerías\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Crear conjunto de datos\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=10, n_classes=2, random_state=42)\n",
    "\n",
    "# Dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Crear modelo de XGBoost\n",
    "model = XGBClassifier()\n",
    "\n",
    "# Entrenar modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar precisión del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Precisión: %.2f%%\" % (accuracy * 100.0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código primero crea un conjunto de datos de clasificación binaria utilizando la función `make_classification` de `Scikit-learn`. Luego divide el conjunto de datos en entrenamiento y prueba utilizando la función `train_test_split`. Luego, crea un modelo de clasificación `XGBoost` utilizando `XGBClassifier` y lo entrena en el conjunto de entrenamiento utilizando el método `fit`. Finalmente, hace predicciones en el conjunto de prueba utilizando el método `predict`, evalúa la precisión del modelo utilizando la métrica de precisión y la imprime en la pantalla.\n",
    "\n",
    "`XGBoost` también proporciona una forma de visualizar la importancia de las características en el modelo utilizando el método `plot_importance`. Aquí hay un ejemplo de cómo hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizar importancia de características\n",
    "from xgboost import plot_importance\n",
    "from matplotlib import pyplot\n",
    "\n",
    "# Plot feature importance\n",
    "plot_importance(model)\n",
    "pyplot.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código genera una gráfica que muestra la importancia de las características en el modelo. Esta información puede ser útil para determinar qué características son más importantes para el modelo y si se deben considerar otras características o se deben eliminar algunas de las características existentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **k-Fold Cross Validation**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El `k-Fold Cross Validation` es una técnica utilizada en machine learning para evaluar el rendimiento de un modelo en términos de su capacidad de generalización. El objetivo de la técnica es estimar el rendimiento de un modelo entrenado en un conjunto de datos, y evaluar su capacidad para generalizar a nuevos datos.\n",
    "\n",
    "En resumen, el k-Fold Cross Validation divide el conjunto de datos en `k` partes iguales (k es un número entero), y entrena y evalúa el modelo `k` veces, cada vez utilizando una parte diferente como conjunto de validación y las restantes `k-1` partes como conjunto de entrenamiento. El resultado final es la media de las métricas de rendimiento de cada una de las `k` iteraciones.\n",
    "\n",
    "A continuación, se muestra un ejemplo de cómo se puede implementar el k-Fold Cross Validation en Python utilizando la biblioteca `Scikit-Learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Puntuación media de precisión: 0.9600000000000002\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Cargar el conjunto de datos\n",
    "iris = load_iris()\n",
    "\n",
    "# Dividir el conjunto de datos en k partes iguales\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Inicializar la lista de puntuaciones de precisión\n",
    "scores = []\n",
    "\n",
    "# Iterar sobre cada una de las k iteraciones\n",
    "for train_index, test_index in kf.split(iris.data):\n",
    "    # Dividir el conjunto de datos en conjuntos de entrenamiento y validación\n",
    "    X_train, X_test = iris.data[train_index], iris.data[test_index]\n",
    "    y_train, y_test = iris.target[train_index], iris.target[test_index]\n",
    "    \n",
    "    # Inicializar el modelo y ajustarlo al conjunto de entrenamiento\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluar el modelo en el conjunto de validación y agregar la puntuación a la lista\n",
    "    score = model.score(X_test, y_test)\n",
    "    scores.append(score)\n",
    "\n",
    "# Calcular la puntuación media de precisión\n",
    "mean_score = sum(scores) / len(scores)\n",
    "\n",
    "print(\"Puntuación media de precisión:\", mean_score)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se utiliza el conjunto de datos de flores `Iris` para demostrar cómo funciona el k-Fold Cross Validation. El conjunto de datos se divide en `5` partes iguales utilizando la clase `KFold` de `Scikit-Learn`, y se entrena y evalúa un modelo de regresión logística en cada una de las `5` iteraciones. Al final, se calcula la puntuación media de precisión de todas las iteraciones, que es una medida del rendimiento general del modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Grid Search**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El Grid Search es una técnica de optimización de hiperparámetros en machine learning que permite encontrar la mejor combinación de valores de hiperparámetros para un modelo específico. En términos simples, se trata de un proceso de prueba y error en el que se buscan los valores óptimos de los hiperparámetros mediante la evaluación de diferentes combinaciones de valores.\n",
    "\n",
    "En lugar de probar diferentes valores de hiperparámetros manualmente, el Grid Search automatiza el proceso evaluando sistemáticamente todas las combinaciones posibles de valores de hiperparámetros. Por ejemplo, si un modelo tiene tres hiperparámetros, el Grid Search probará todas las posibles combinaciones de valores de los tres hiperparámetros.\n",
    "\n",
    "A continuación se presenta un ejemplo de cómo realizar un Grid Search para optimizar los hiperparámetros de un modelo de regresión logística utilizando la biblioteca `scikit-learn` en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "70 fits failed out of a total of 105.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "35 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.92970036        nan        nan 0.92797702        nan\n",
      "        nan 0.94201211        nan        nan 0.93676448        nan\n",
      "        nan 0.93496351        nan        nan 0.94555193        nan\n",
      "        nan 0.93676448        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros:  {'C': 100, 'penalty': 'l2'}\n",
      "Puntaje del modelo con mejores hiperparámetros:  0.9455519329296692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Cargar los datos\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "\n",
    "# Crear el modelo de regresión logística\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Definir la cuadrícula de hiperparámetros para Grid Search\n",
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "              'penalty': ['l1', 'l2', 'elasticnet']}\n",
    "\n",
    "# Realizar Grid Search con validación cruzada de 5 pliegues\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5)\n",
    "\n",
    "# Entrenar el modelo con Grid Search\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros y puntajes\n",
    "print(\"Mejores hiperparámetros: \", grid_search.best_params_)\n",
    "print(\"Puntaje del modelo con mejores hiperparámetros: \", grid_search.best_score_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se utiliza el conjunto de datos de cáncer de mama de la biblioteca `scikit-learn`. Se crea un modelo de regresión logística y se define una cuadrícula de hiperparámetros que contiene diferentes valores para los hiperparámetros `C` y `penalty`. Luego, se utiliza el Grid Search para encontrar los mejores valores de los hiperparámetros utilizando la validación cruzada de 5 pliegues. Finalmente, se imprime el conjunto de mejores hiperparámetros y el puntaje del modelo utilizando estos hiperparámetros.\n",
    "\n",
    "La siguiente gráfica muestra cómo se realizaría el Grid Search para dos hiperparámetros diferentes, donde cada punto representa una combinación de valores de hiperparámetros y el eje z muestra el puntaje de validación cruzada correspondiente:\n",
    "\n",
    "En resumen, el Grid Search es una técnica útil para encontrar los mejores valores de hiperparámetros en un modelo de machine learning mediante la evaluación sistemática de todas las posibles combinaciones de valores de hiperparámetros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Accuracy:  0.9777777777777777\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "\n",
    "# Cargar datos de ejemplo\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "# Definir cuadrícula de hiperparámetros\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': [0.1, 1, 10]}\n",
    "\n",
    "# Crear modelo SVM\n",
    "svm = SVC()\n",
    "\n",
    "# Crear objeto Grid Search\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "\n",
    "# Ajustar Grid Search a los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Imprimir los mejores hiperparámetros\n",
    "print(\"Best parameters: \", grid_search.best_params_)\n",
    "\n",
    "# Utilizar el modelo SVM con los mejores parámetros para predecir las clases del conjunto de pruebas\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Evaluar el rendimiento del modelo\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(\"Accuracy: \", accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 8** | **Siguiente 10** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../README.md) | [⏪](./8.Reduccion_de_la_dimensi%C3%B3n.ipynb)| [⏩](./10.Gradiente_Descendente.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
