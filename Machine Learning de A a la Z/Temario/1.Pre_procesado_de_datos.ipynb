{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **Siguiente 2** |\n",
    "|----------- |-------------- |\n",
    "| [üè†](../../README.md) | [‚è©](./2.Regresion.ipynb)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Pre procesado de datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datos categ√≥ricos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos categ√≥ricos, tambi√©n conocidos como variables categ√≥ricas, son aquellos que representan caracter√≠sticas o cualidades que pueden ser clasificadas en diferentes categor√≠as o grupos. Estas categor√≠as pueden ser nominales o ordinales, dependiendo del tipo de informaci√≥n que se est√© representando.\n",
    "\n",
    "`Las variables categ√≥ricas nominales` no tienen un orden l√≥gico entre las diferentes categor√≠as, simplemente se usan para clasificar la informaci√≥n en diferentes grupos.\n",
    "\n",
    "**Ejemplos** de variables categ√≥ricas nominales son el g√©nero, la nacionalidad, la preferencia pol√≠tica o el color de ojos. Estas variables no pueden ser medidas o comparadas en t√©rminos de mayor o menor, simplemente se pueden contar la cantidad de individuos en cada categor√≠a.\n",
    "\n",
    "Por otro lado, `las variables categ√≥ricas ordinales` s√≠ tienen un orden l√≥gico entre las diferentes categor√≠as.\n",
    "\n",
    "**Ejemplos** de variables categ√≥ricas ordinales son el nivel educativo, la clasificaci√≥n socioecon√≥mica o el grado de satisfacci√≥n. En este caso, las diferentes categor√≠as se pueden ordenar en funci√≥n de un criterio l√≥gico, por ejemplo, el nivel educativo se puede ordenar de menor a mayor: primaria, secundaria, universitaria, posgrado, etc.\n",
    "\n",
    "En resumen, los datos categ√≥ricos son aquellos que representan caracter√≠sticas o cualidades que se pueden clasificar en diferentes categor√≠as o grupos, y que pueden ser nominales o ordinales dependiendo del tipo de informaci√≥n que se est√© representando."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem√°tica de los datos categ√≥ricos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos categ√≥ricos son aquellos que representan una variable que toma valores de una lista finita y discreta de categor√≠as o etiquetas. Aunque son comunes en muchos campos de estudio, los datos categ√≥ricos pueden presentar varias problem√°ticas que dificultan su an√°lisis. Algunas de estas problem√°ticas son:\n",
    "\n",
    "1. **Escalas de medici√≥n:**\n",
    " Las variables categ√≥ricas no tienen una escala de medici√≥n clara, lo que dificulta la comparaci√≥n entre ellas. **Por ejemplo**, no se puede decir que una categor√≠a es el doble o la mitad de otra categor√≠a.\n",
    "\n",
    "2. **Representaci√≥n num√©rica:**\n",
    " A menudo, los datos categ√≥ricos se representan mediante n√∫meros, pero estos n√∫meros no tienen ning√∫n significado num√©rico real. **Por ejemplo**, si tenemos una variable que representa colores, los n√∫meros asignados a cada color no tienen un valor num√©rico real.\n",
    "\n",
    "3. **An√°lisis estad√≠stico:**\n",
    " Muchos m√©todos estad√≠sticos requieren que los datos sean num√©ricos, por lo que los datos categ√≥ricos pueden presentar dificultades en el an√°lisis. A menudo se utilizan t√©cnicas especiales, como modelos de regresi√≥n log√≠stica o an√°lisis de contingencia, para analizar datos categ√≥ricos.\n",
    "\n",
    "4. **Sesgo de la muestra:** Los datos categ√≥ricos pueden estar sesgados si la muestra no es representativa de la poblaci√≥n de inter√©s. Por ejemplo, si se recopilan datos sobre preferencias de color solo de personas que trabajan en una empresa de moda, es posible que los resultados no sean generalizables a la poblaci√≥n en general.\n",
    "\n",
    "5. **Categor√≠as incompletas:**\n",
    " A veces, las categor√≠as en una variable categ√≥rica pueden ser incompletas o ambiguas, lo que dificulta su an√°lisis. Por **ejemplo**, si se tiene una variable que representa la edad, pero algunas categor√≠as est√°n ausentes o no son claras, puede ser dif√≠cil interpretar los resultados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Variables](../imagenes%20Machine_Learning/Variables.webp \"Variables\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tipos de datos categ√≥ricos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen diferentes tipos de datos categ√≥ricos, algunos de los cuales se detallan a continuaci√≥n:\n",
    "\n",
    "1. **Nominales:**\n",
    " Los datos nominales son aquellos que representan categor√≠as sin ning√∫n orden o jerarqu√≠a espec√≠fica. Por **ejemplo**, el g√©nero, el pa√≠s de origen, la marca de un producto, etc.\n",
    "\n",
    "2. **Ordinales:**\n",
    " Los datos ordinales son aquellos que representan categor√≠as con un orden o jerarqu√≠a espec√≠fica. Por **ejemplo**, las calificaciones escolares (A, B, C, D, E), el nivel socioecon√≥mico (bajo, medio, alto), la opini√≥n sobre algo (muy bueno, bueno, regular, malo, muy malo), etc.\n",
    "\n",
    "3. **Binarios:**\n",
    " Los datos binarios son aquellos que representan solo dos categor√≠as posibles. Por **ejemplo**, s√≠ o no, verdadero o falso, hombre o mujer, etc.\n",
    "\n",
    "4. **Polit√≥micos:**\n",
    " Los datos polit√≥micos son aquellos que representan m√°s de dos categor√≠as posibles. Por **ejemplo**, el color de un objeto, las preferencias de comida (dulce, salado, amargo, √°cido), el nivel de educaci√≥n (primaria, secundaria, universitaria), etc.\n",
    "\n",
    "Es importante tener en cuenta que la elecci√≥n del tipo de dato categ√≥rico depende del contexto en el que se est√° trabajando y de la naturaleza de la variable que se est√° midiendo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejemplos de datos ordinales**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos un dataframe que representa la informaci√≥n de un conjunto de estudiantes y sus calificaciones en diferentes asignaturas. Algunos ejemplos de datos ordinales que podr√≠an estar presentes en este dataframe son:\n",
    "\n",
    "* La calificaci√≥n en cada asignatura, que se puede representar mediante una escala ordinal, como A, B, C, D, E, donde A es la calificaci√≥n m√°s alta y E es la calificaci√≥n m√°s baja.\n",
    "\n",
    "* El nivel de dificultad de cada asignatura, que tambi√©n se puede representar mediante una escala ordinal, como alta, media, baja, donde alta representa el nivel m√°s dif√≠cil y baja el nivel m√°s f√°cil.\n",
    "\n",
    "* El grado de satisfacci√≥n de los estudiantes con cada asignatura, que se puede representar mediante una escala ordinal, como muy satisfecho, satisfecho, indiferente, insatisfecho, muy insatisfecho, donde muy satisfecho representa el nivel m√°s alto de satisfacci√≥n y muy insatisfecho el nivel m√°s bajo.\n",
    "\n",
    "En todos estos casos, los datos tienen un orden o jerarqu√≠a espec√≠fica que permite su clasificaci√≥n y an√°lisis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar c√≥mo se pueden representar datos ordinales en un dataframe utilizando Python, podemos crear un peque√±o ejemplo utilizando la librer√≠a Pandas.\n",
    "\n",
    "Supongamos que tenemos un dataframe que representa la informaci√≥n de un conjunto de estudiantes y sus calificaciones en tres asignaturas (Matem√°ticas, F√≠sica y Qu√≠mica), y que las calificaciones se han registrado utilizando la escala ordinal A, B, C, D, E. Podr√≠amos crear el dataframe de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estudiante Matem√°ticas F√≠sica Qu√≠mica\n",
      "0       Juan           A      B       C\n",
      "1      Mar√≠a           B      C       C\n",
      "2      Pedro           C      D       D\n",
      "3        Ana           C      E       D\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Estudiante': ['Juan', 'Mar√≠a', 'Pedro', 'Ana'],\n",
    "    'Matem√°ticas': ['A', 'B', 'C', 'C'],\n",
    "    'F√≠sica': ['B', 'C', 'D', 'E'],\n",
    "    'Qu√≠mica': ['C', 'C', 'D', 'D']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, las columnas de calificaciones para cada asignatura representan datos ordinales, ya que cada calificaci√≥n tiene un orden espec√≠fico. Podemos analizar estos datos de diferentes maneras, como calcular el promedio de calificaciones de cada estudiante o determinar la asignatura con la calificaci√≥n m√°s alta."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Contexto de los datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El contexto de los datos se refiere al conjunto de circunstancias y condiciones en las que se recopilaron los datos, incluyendo la fuente de los datos, el prop√≥sito de la recopilaci√≥n de los datos, el m√©todo utilizado para recopilar los datos y cualquier otra informaci√≥n relevante.\n",
    "\n",
    "El contexto es importante porque puede afectar la validez y la fiabilidad de los datos, y por lo tanto, la interpretaci√≥n y los resultados que se pueden obtener a partir de ellos. Algunos factores importantes a considerar en el contexto de los datos son:\n",
    "\n",
    "* **La fuente de los datos:**\n",
    " ¬øQui√©n recopil√≥ los datos? ¬øSon datos de una fuente confiable y verificada?\n",
    "\n",
    "* **El prop√≥sito de la recopilaci√≥n de los datos:**\n",
    " ¬øCu√°l fue el objetivo principal de la recopilaci√≥n de los datos? ¬øSe recopilaron los datos para responder a una pregunta espec√≠fica o para explorar un tema m√°s amplio?\n",
    "\n",
    "* **El m√©todo utilizado para recopilar los datos:**\n",
    " ¬øSe utilizaron m√©todos adecuados y v√°lidos para recopilar los datos? ¬øSe consideraron los posibles sesgos en el m√©todo de recopilaci√≥n de los datos?\n",
    "\n",
    "* **La naturaleza de los datos:**\n",
    " ¬øSon los datos categ√≥ricos o num√©ricos? ¬øCu√°l es la escala de medida utilizada para los datos?\n",
    "\n",
    "* **El periodo de tiempo en que se recopilaron los datos:**\n",
    " ¬øLos datos son actuales o se recopilaron en el pasado? ¬øEs importante considerar los cambios en el contexto que pueden haber ocurrido desde que se recopilaron los datos?\n",
    "\n",
    "En resumen, el contexto de los datos es esencial para interpretarlos de manera adecuada y utilizarlos de manera efectiva en la toma de decisiones o en la investigaci√≥n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Codificaci√≥n ordinal (Ordinal Encoder)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La codificaci√≥n ordinal, tambi√©n conocida como Ordinal Encoder, es una t√©cnica de preprocesamiento de datos que se utiliza para convertir variables categ√≥ricas ordinales en valores num√©ricos ordenados. Esto se hace asignando un n√∫mero entero √∫nico a cada categor√≠a, basado en su posici√≥n en la escala ordinal.\n",
    "\n",
    "Por **ejemplo**, supongamos que tenemos una columna llamada `\"Nivel de educaci√≥n\"` con las siguientes categor√≠as ordinales: `\"Primaria\"`, `\"Secundaria\"`, `\"Bachillerato\"`, `\"T√©cnico\"`, `\"Profesional\"`, `\"Maestr√≠a\"` y `\"Doctorado\"`.\n",
    " La codificaci√≥n ordinal asignar√≠a los siguientes n√∫meros enteros a cada categor√≠a: 1 para `\"Primaria\"`, 2 para `\"Secundaria\"`, 3 para `\"Bachillerato\"`, 4 para `\"T√©cnico\"`, 5 para `\"Profesional\"`, 6 para `\"Maestr√≠a\"` y 7 para `\"Doctorado\"`.\n",
    "\n",
    "A continuaci√≥n se presenta un ejemplo de c√≥mo utilizar la codificaci√≥n ordinal en Python con la biblioteca `Scikit-Learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Nivel de educaci√≥n\n",
      "0                 3.0\n",
      "1                 5.0\n",
      "2                 0.0\n",
      "3                 6.0\n",
      "4                 4.0\n",
      "5                 2.0\n",
      "6                 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Creamos un dataframe con datos categ√≥ricos ordinales\n",
    "df = pd.DataFrame({'Nivel de educaci√≥n': ['Primaria', 'Secundaria', 'Bachillerato', 'T√©cnico', 'Profesional', 'Maestr√≠a', 'Doctorado']})\n",
    "\n",
    "# Instanciamos el codificador ordinal\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Ajustamos el codificador a los datos del dataframe\n",
    "encoder.fit(df)\n",
    "\n",
    "# Transformamos los datos categ√≥ricos ordinales en valores num√©ricos ordenados\n",
    "transformed_data = encoder.transform(df)\n",
    "\n",
    "# Creamos un nuevo dataframe con los datos transformados\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=df.columns)\n",
    "\n",
    "print(transformed_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, el codificador ordinal convierte la columna `\"Nivel de educaci√≥n\"` en valores num√©ricos ordenados del 0 al 6, basado en la posici√≥n de cada categor√≠a en la escala ordinal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Codificaci√≥n One-Hot (One-Hot Encoder)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La codificaci√≥n `One-Hot` (tambi√©n conocida como One-Hot Encoder) es una t√©cnica de preprocesamiento de datos que se utiliza para convertir variables categ√≥ricas en variables num√©ricas binarias. Cada categor√≠a de la variable original se convierte en una nueva columna binaria, y se asigna un valor de 1 si la instancia pertenece a esa categor√≠a, y 0 si no lo hace.\n",
    "\n",
    "Por ejemplo, si tenemos una columna `\"Color\"` con tres categor√≠as: `\"Rojo\"`, `\"Verde\"` y `\"Azul\"`, la codificaci√≥n `One-Hot` crear√≠a tres nuevas columnas: `\"Rojo\"`, `\"Verde\"` y `\"Azul\"`. Si una instancia tiene el color `\"Rojo\"`, su columna correspondiente tendr√° un valor de 1 y las otras dos columnas tendr√°n un valor de 0.\n",
    "\n",
    "A continuaci√≥n, se presenta un ejemplo de c√≥mo utilizar la codificaci√≥n `One-Hot` en Python con la biblioteca `Scikit-Learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_Azul  Color_Rojo  Color_Verde\n",
      "0         0.0         1.0          0.0\n",
      "1         0.0         0.0          1.0\n",
      "2         1.0         0.0          0.0\n",
      "3         0.0         1.0          0.0\n",
      "4         0.0         1.0          0.0\n",
      "5         0.0         0.0          1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Creamos un dataframe con datos categ√≥ricos\n",
    "df = pd.DataFrame({'Color': ['Rojo', 'Verde', 'Azul', 'Rojo', 'Rojo', 'Verde']})\n",
    "\n",
    "# Instanciamos el codificador One-Hot\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Ajustamos el codificador a los datos del dataframe\n",
    "encoder.fit(df)\n",
    "\n",
    "# Transformamos los datos categ√≥ricos en valores num√©ricos binarios\n",
    "transformed_data = encoder.transform(df).toarray()\n",
    "\n",
    "# Obtenemos los nombres de las nuevas columnas\n",
    "feature_names = encoder.get_feature_names_out(input_features=['Color'])\n",
    "\n",
    "# Creamos un nuevo dataframe con los datos transformados\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=feature_names)\n",
    "\n",
    "print(transformed_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, el codificador `One-Hot` convierte la columna `\"Color\"` en tres nuevas columnas binarias `\"x0_Azul\"`, `\"x0_Rojo\"` y `\"x0_Verde\"`. Cada columna representa una categor√≠a √∫nica y se asigna un valor de 1 si la instancia pertenece a esa categor√≠a y 0 si no lo hace."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparaci√≥n de las codificaciones v√≠a un clasificador**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, compararemos el desempe√±o de la codificaci√≥n ordinal y `one-hot` encoding en un clasificador de regresi√≥n log√≠stica utilizando el conjunto de datos `Iris`. Primero, cargamos el conjunto de datos y separamos las caracter√≠sticas `(X)` y las etiquetas `(y)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Separar caracter√≠sticas y etiquetas\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n, creamos dos transformadores utilizando el codificador ordinal y `one-hot encoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definir las caracter√≠sticas categ√≥ricas y num√©ricas\n",
    "categorical_cols = [3]\n",
    "numeric_cols = [0, 1, 2]\n",
    "\n",
    "# Crear un transformador con el codificador ordinal\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_transformer = Pipeline(steps=[('ordinal_encoder', ordinal_encoder)])\n",
    "preprocessor_ordinal = ColumnTransformer(transformers=[\n",
    "    ('ordinal', ordinal_transformer, categorical_cols),\n",
    "    ('numeric', 'passthrough', numeric_cols)\n",
    "])\n",
    "\n",
    "# Crear un transformador con el codificador one-hot\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_transformer = Pipeline(steps=[('onehot_encoder', onehot_encoder)])\n",
    "preprocessor_onehot = ColumnTransformer(transformers=[\n",
    "    ('onehot', onehot_transformer, categorical_cols),\n",
    "    ('numeric', 'passthrough', numeric_cols)\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, creamos dos clasificadores de regresi√≥n log√≠stica, uno para cada transformador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un clasificador de regresi√≥n log√≠stica con el transformador ordinal\n",
    "clf_ordinal = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_ordinal),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Crear un clasificador de regresi√≥n log√≠stica con el transformador one-hot\n",
    "clf_onehot = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_onehot),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos ambos clasificadores con los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [3]),\n",
       "                                                 (&#x27;numeric&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [0, 1, 2])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [3]),\n",
       "                                                 (&#x27;numeric&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [0, 1, 2])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehot_encoder&#x27;,\n",
       "                                                  OneHotEncoder())]),\n",
       "                                 [3]),\n",
       "                                (&#x27;numeric&#x27;, &#x27;passthrough&#x27;, [0, 1, 2])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehot</label><div class=\"sk-toggleable__content\"><pre>[3]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numeric</label><div class=\"sk-toggleable__content\"><pre>[0, 1, 2]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('onehot',\n",
       "                                                  Pipeline(steps=[('onehot_encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [3]),\n",
       "                                                 ('numeric', 'passthrough',\n",
       "                                                  [0, 1, 2])])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el clasificador con el transformador ordinal\n",
    "clf_ordinal.fit(X_train, y_train)\n",
    "\n",
    "# Entrenar el clasificador con el transformador one-hot\n",
    "clf_onehot.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, evaluamos el desempe√±o de ambos clasificadores en los datos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy con codificaci√≥n ordinal: 1.00\n",
      "Accuracy con codificaci√≥n one-hot: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones con el clasificador con el transformador ordinal\n",
    "y_pred_ordinal = clf_ordinal.predict(X_test)\n",
    "accuracy_ordinal = accuracy_score(y_test, y_pred_ordinal)\n",
    "\n",
    "# Hacer predicciones con el clasificador con el transformador one-hot\n",
    "y_pred_onehot = clf_onehot.predict(X_test)\n",
    "accuracy_onehot = accuracy_score(y_test, y_pred_onehot)\n",
    "\n",
    "# Imprimir el desempe√±o de ambos clasificadores\n",
    "print(f'Accuracy con codificaci√≥n ordinal: {accuracy_ordinal:.2f}')\n",
    "print(f'Accuracy con codificaci√≥n one-hot: {accuracy_onehot:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C√≥mo dividir el data set en entrenamiento y test**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el aprendizaje autom√°tico, es com√∫n dividir el conjunto de datos en dos subconjuntos: el conjunto de entrenamiento y el conjunto de prueba. El conjunto de entrenamiento se utiliza para ajustar el modelo de aprendizaje autom√°tico, mientras que el conjunto de prueba se utiliza para evaluar el rendimiento del modelo.\n",
    "\n",
    "Aqu√≠ te explicar√© c√≥mo dividir un conjunto de datos en Python utilizando la librer√≠a `Scikit-learn`.\n",
    "\n",
    "Primero, necesitamos cargar el conjunto de datos. Para este ejemplo, utilizaremos el conjunto de datos `iris` que ya viene incluido en `Scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n, vamos a dividir los datos en un conjunto de entrenamiento y un conjunto de prueba. `Scikit-learn` proporciona la funci√≥n `train_test_split` para dividir los datos de manera aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu√≠, `iris.data` son los datos de entrada y `iris.target` son las etiquetas de clase correspondientes. `test_size` es el porcentaje del conjunto de datos que se utilizar√° para el conjunto de prueba, que en este caso es del 30%. `random_state` es una semilla aleatoria para asegurarnos de que obtenemos la misma divisi√≥n de datos cada vez que ejecutamos el c√≥digo.\n",
    "\n",
    "Ahora tenemos cuatro conjuntos de datos: `X_train`, `X_test`, `y_train`, y `y_test`. `X_train` y `y_train` se utilizan para entrenar el modelo, mientras que `X_test` y `y_test` se utilizan para evaluar el rendimiento del modelo.\n",
    "\n",
    "Finalmente, podemos verificar el tama√±o de los conjuntos de datos de entrenamiento y prueba utilizando la funci√≥n `shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (105, 4)\n",
      "y_train shape: (105,)\n",
      "X_test shape: (45, 4)\n",
      "y_test shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, la funci√≥n `train_test_split` nos permite dividir un conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba de manera aleatoria en Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![C√≥mo dividir el data set en entrenamiento y test](../imagenes%20Machine_Learning/dataset%20_entrenamiento_test.webp \"C√≥mo dividir el data set en entrenamiento y test\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C√≥mo escalar los datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el aprendizaje autom√°tico, es com√∫n que las diferentes caracter√≠sticas (variables) de un conjunto de datos tengan diferentes escalas o rangos de valores. Por ejemplo, una caracter√≠stica puede tener valores entre 0 y 1, mientras que otra puede tener valores entre 0 y 1000. Escalar los datos es un proceso que transforma los valores de las caracter√≠sticas en una escala com√∫n, lo que puede mejorar la eficacia de los algoritmos de aprendizaje autom√°tico.\n",
    "\n",
    "Aqu√≠ te explicar√© c√≥mo escalar los datos en Python utilizando la librer√≠a `Scikit-learn`.\n",
    "\n",
    "Primero, necesitamos cargar el conjunto de datos. Para este ejemplo, utilizaremos el conjunto de datos iris que ya viene incluido en `Scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci√≥n, vamos a escalar los datos utilizando la funci√≥n `StandardScaler` de `Scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(iris.data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu√≠, `StandardScaler` es un objeto de la clase `StandardScaler` que se utiliza para escalar los datos. La funci√≥n `fit_transform` se utiliza para ajustar el escalador a los datos y transformar los datos de entrada `iris.data` en una escala com√∫n `X_scaled`. El conjunto de datos escalado resultante `X_scaled` es un `numpy` `array` con las mismas dimensiones que `iris.data`.\n",
    "\n",
    "Podemos verificar los valores escalados de los datos utilizando la funci√≥n `mean` y `std` de `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de los datos originales: [5.84333333 3.05733333 3.758      1.19933333]\n",
      "Desviaci√≥n est√°ndar de los datos originales: [0.82530129 0.43441097 1.75940407 0.75969263]\n",
      "Media de los datos escalados: [-1.69031455e-15 -1.84297022e-15 -1.69864123e-15 -1.40924309e-15]\n",
      "Desviaci√≥n est√°ndar de los datos escalados: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Media de los datos originales:\", np.mean(iris.data, axis=0))\n",
    "print(\"Desviaci√≥n est√°ndar de los datos originales:\", np.std(iris.data, axis=0))\n",
    "print(\"Media de los datos escalados:\", np.mean(X_scaled, axis=0))\n",
    "print(\"Desviaci√≥n est√°ndar de los datos escalados:\", np.std(X_scaled, axis=0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que los datos escalados tienen una media de casi 0 y una desviaci√≥n est√°ndar de 1, lo que indica que est√°n en una escala com√∫n.\n",
    "\n",
    "En resumen, la funci√≥n `StandardScaler` de `Scikit-learn` nos permite escalar los datos para transformar las diferentes caracter√≠sticas en una escala com√∫n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **Siguiente 2** |\n",
    "|----------- |-------------- |\n",
    "| [üè†](../../README.md) | [‚è©](./2.Regresion.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
