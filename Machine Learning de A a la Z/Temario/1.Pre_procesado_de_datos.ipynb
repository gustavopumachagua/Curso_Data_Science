{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **Siguiente 2** |\n",
    "|----------- |-------------- |\n",
    "| [](../../README.md) | [](./2.Regresion.ipynb)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Pre procesado de datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Datos categ贸ricos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos categ贸ricos, tambi茅n conocidos como variables categ贸ricas, son aquellos que representan caracter铆sticas o cualidades que pueden ser clasificadas en diferentes categor铆as o grupos. Estas categor铆as pueden ser nominales o ordinales, dependiendo del tipo de informaci贸n que se est茅 representando.\n",
    "\n",
    "`Las variables categ贸ricas nominales` no tienen un orden l贸gico entre las diferentes categor铆as, simplemente se usan para clasificar la informaci贸n en diferentes grupos.\n",
    "\n",
    "**Ejemplos** de variables categ贸ricas nominales son el g茅nero, la nacionalidad, la preferencia pol铆tica o el color de ojos. Estas variables no pueden ser medidas o comparadas en t茅rminos de mayor o menor, simplemente se pueden contar la cantidad de individuos en cada categor铆a.\n",
    "\n",
    "Por otro lado, `las variables categ贸ricas ordinales` s铆 tienen un orden l贸gico entre las diferentes categor铆as.\n",
    "\n",
    "**Ejemplos** de variables categ贸ricas ordinales son el nivel educativo, la clasificaci贸n socioecon贸mica o el grado de satisfacci贸n. En este caso, las diferentes categor铆as se pueden ordenar en funci贸n de un criterio l贸gico, por ejemplo, el nivel educativo se puede ordenar de menor a mayor: primaria, secundaria, universitaria, posgrado, etc.\n",
    "\n",
    "En resumen, los datos categ贸ricos son aquellos que representan caracter铆sticas o cualidades que se pueden clasificar en diferentes categor铆as o grupos, y que pueden ser nominales o ordinales dependiendo del tipo de informaci贸n que se est茅 representando."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Problem谩tica de los datos categ贸ricos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los datos categ贸ricos son aquellos que representan una variable que toma valores de una lista finita y discreta de categor铆as o etiquetas. Aunque son comunes en muchos campos de estudio, los datos categ贸ricos pueden presentar varias problem谩ticas que dificultan su an谩lisis. Algunas de estas problem谩ticas son:\n",
    "\n",
    "1. **Escalas de medici贸n:**\n",
    " Las variables categ贸ricas no tienen una escala de medici贸n clara, lo que dificulta la comparaci贸n entre ellas. **Por ejemplo**, no se puede decir que una categor铆a es el doble o la mitad de otra categor铆a.\n",
    "\n",
    "2. **Representaci贸n num茅rica:**\n",
    " A menudo, los datos categ贸ricos se representan mediante n煤meros, pero estos n煤meros no tienen ning煤n significado num茅rico real. **Por ejemplo**, si tenemos una variable que representa colores, los n煤meros asignados a cada color no tienen un valor num茅rico real.\n",
    "\n",
    "3. **An谩lisis estad铆stico:**\n",
    " Muchos m茅todos estad铆sticos requieren que los datos sean num茅ricos, por lo que los datos categ贸ricos pueden presentar dificultades en el an谩lisis. A menudo se utilizan t茅cnicas especiales, como modelos de regresi贸n log铆stica o an谩lisis de contingencia, para analizar datos categ贸ricos.\n",
    "\n",
    "4. **Sesgo de la muestra:** Los datos categ贸ricos pueden estar sesgados si la muestra no es representativa de la poblaci贸n de inter茅s. Por ejemplo, si se recopilan datos sobre preferencias de color solo de personas que trabajan en una empresa de moda, es posible que los resultados no sean generalizables a la poblaci贸n en general.\n",
    "\n",
    "5. **Categor铆as incompletas:**\n",
    " A veces, las categor铆as en una variable categ贸rica pueden ser incompletas o ambiguas, lo que dificulta su an谩lisis. Por **ejemplo**, si se tiene una variable que representa la edad, pero algunas categor铆as est谩n ausentes o no son claras, puede ser dif铆cil interpretar los resultados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Variables](../imagenes%20Machine_Learning/Variables.webp \"Variables\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Tipos de datos categ贸ricos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen diferentes tipos de datos categ贸ricos, algunos de los cuales se detallan a continuaci贸n:\n",
    "\n",
    "1. **Nominales:**\n",
    " Los datos nominales son aquellos que representan categor铆as sin ning煤n orden o jerarqu铆a espec铆fica. Por **ejemplo**, el g茅nero, el pa铆s de origen, la marca de un producto, etc.\n",
    "\n",
    "2. **Ordinales:**\n",
    " Los datos ordinales son aquellos que representan categor铆as con un orden o jerarqu铆a espec铆fica. Por **ejemplo**, las calificaciones escolares (A, B, C, D, E), el nivel socioecon贸mico (bajo, medio, alto), la opini贸n sobre algo (muy bueno, bueno, regular, malo, muy malo), etc.\n",
    "\n",
    "3. **Binarios:**\n",
    " Los datos binarios son aquellos que representan solo dos categor铆as posibles. Por **ejemplo**, s铆 o no, verdadero o falso, hombre o mujer, etc.\n",
    "\n",
    "4. **Polit贸micos:**\n",
    " Los datos polit贸micos son aquellos que representan m谩s de dos categor铆as posibles. Por **ejemplo**, el color de un objeto, las preferencias de comida (dulce, salado, amargo, 谩cido), el nivel de educaci贸n (primaria, secundaria, universitaria), etc.\n",
    "\n",
    "Es importante tener en cuenta que la elecci贸n del tipo de dato categ贸rico depende del contexto en el que se est谩 trabajando y de la naturaleza de la variable que se est谩 midiendo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Ejemplos de datos ordinales**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que tenemos un dataframe que representa la informaci贸n de un conjunto de estudiantes y sus calificaciones en diferentes asignaturas. Algunos ejemplos de datos ordinales que podr铆an estar presentes en este dataframe son:\n",
    "\n",
    "* La calificaci贸n en cada asignatura, que se puede representar mediante una escala ordinal, como A, B, C, D, E, donde A es la calificaci贸n m谩s alta y E es la calificaci贸n m谩s baja.\n",
    "\n",
    "* El nivel de dificultad de cada asignatura, que tambi茅n se puede representar mediante una escala ordinal, como alta, media, baja, donde alta representa el nivel m谩s dif铆cil y baja el nivel m谩s f谩cil.\n",
    "\n",
    "* El grado de satisfacci贸n de los estudiantes con cada asignatura, que se puede representar mediante una escala ordinal, como muy satisfecho, satisfecho, indiferente, insatisfecho, muy insatisfecho, donde muy satisfecho representa el nivel m谩s alto de satisfacci贸n y muy insatisfecho el nivel m谩s bajo.\n",
    "\n",
    "En todos estos casos, los datos tienen un orden o jerarqu铆a espec铆fica que permite su clasificaci贸n y an谩lisis."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para ilustrar c贸mo se pueden representar datos ordinales en un dataframe utilizando Python, podemos crear un peque帽o ejemplo utilizando la librer铆a Pandas.\n",
    "\n",
    "Supongamos que tenemos un dataframe que representa la informaci贸n de un conjunto de estudiantes y sus calificaciones en tres asignaturas (Matem谩ticas, F铆sica y Qu铆mica), y que las calificaciones se han registrado utilizando la escala ordinal A, B, C, D, E. Podr铆amos crear el dataframe de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Estudiante Matem谩ticas F铆sica Qu铆mica\n",
      "0       Juan           A      B       C\n",
      "1      Mar铆a           B      C       C\n",
      "2      Pedro           C      D       D\n",
      "3        Ana           C      E       D\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Estudiante': ['Juan', 'Mar铆a', 'Pedro', 'Ana'],\n",
    "    'Matem谩ticas': ['A', 'B', 'C', 'C'],\n",
    "    'F铆sica': ['B', 'C', 'D', 'E'],\n",
    "    'Qu铆mica': ['C', 'C', 'D', 'D']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso, las columnas de calificaciones para cada asignatura representan datos ordinales, ya que cada calificaci贸n tiene un orden espec铆fico. Podemos analizar estos datos de diferentes maneras, como calcular el promedio de calificaciones de cada estudiante o determinar la asignatura con la calificaci贸n m谩s alta."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Contexto de los datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El contexto de los datos se refiere al conjunto de circunstancias y condiciones en las que se recopilaron los datos, incluyendo la fuente de los datos, el prop贸sito de la recopilaci贸n de los datos, el m茅todo utilizado para recopilar los datos y cualquier otra informaci贸n relevante.\n",
    "\n",
    "El contexto es importante porque puede afectar la validez y la fiabilidad de los datos, y por lo tanto, la interpretaci贸n y los resultados que se pueden obtener a partir de ellos. Algunos factores importantes a considerar en el contexto de los datos son:\n",
    "\n",
    "* **La fuente de los datos:**\n",
    " 驴Qui茅n recopil贸 los datos? 驴Son datos de una fuente confiable y verificada?\n",
    "\n",
    "* **El prop贸sito de la recopilaci贸n de los datos:**\n",
    " 驴Cu谩l fue el objetivo principal de la recopilaci贸n de los datos? 驴Se recopilaron los datos para responder a una pregunta espec铆fica o para explorar un tema m谩s amplio?\n",
    "\n",
    "* **El m茅todo utilizado para recopilar los datos:**\n",
    " 驴Se utilizaron m茅todos adecuados y v谩lidos para recopilar los datos? 驴Se consideraron los posibles sesgos en el m茅todo de recopilaci贸n de los datos?\n",
    "\n",
    "* **La naturaleza de los datos:**\n",
    " 驴Son los datos categ贸ricos o num茅ricos? 驴Cu谩l es la escala de medida utilizada para los datos?\n",
    "\n",
    "* **El periodo de tiempo en que se recopilaron los datos:**\n",
    " 驴Los datos son actuales o se recopilaron en el pasado? 驴Es importante considerar los cambios en el contexto que pueden haber ocurrido desde que se recopilaron los datos?\n",
    "\n",
    "En resumen, el contexto de los datos es esencial para interpretarlos de manera adecuada y utilizarlos de manera efectiva en la toma de decisiones o en la investigaci贸n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Codificaci贸n ordinal (Ordinal Encoder)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La codificaci贸n ordinal, tambi茅n conocida como Ordinal Encoder, es una t茅cnica de preprocesamiento de datos que se utiliza para convertir variables categ贸ricas ordinales en valores num茅ricos ordenados. Esto se hace asignando un n煤mero entero 煤nico a cada categor铆a, basado en su posici贸n en la escala ordinal.\n",
    "\n",
    "Por **ejemplo**, supongamos que tenemos una columna llamada `\"Nivel de educaci贸n\"` con las siguientes categor铆as ordinales: `\"Primaria\"`, `\"Secundaria\"`, `\"Bachillerato\"`, `\"T茅cnico\"`, `\"Profesional\"`, `\"Maestr铆a\"` y `\"Doctorado\"`.\n",
    " La codificaci贸n ordinal asignar铆a los siguientes n煤meros enteros a cada categor铆a: 1 para `\"Primaria\"`, 2 para `\"Secundaria\"`, 3 para `\"Bachillerato\"`, 4 para `\"T茅cnico\"`, 5 para `\"Profesional\"`, 6 para `\"Maestr铆a\"` y 7 para `\"Doctorado\"`.\n",
    "\n",
    "A continuaci贸n se presenta un ejemplo de c贸mo utilizar la codificaci贸n ordinal en Python con la biblioteca `Scikit-Learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Nivel de educaci贸n\n",
      "0                 3.0\n",
      "1                 5.0\n",
      "2                 0.0\n",
      "3                 6.0\n",
      "4                 4.0\n",
      "5                 2.0\n",
      "6                 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Creamos un dataframe con datos categ贸ricos ordinales\n",
    "df = pd.DataFrame({'Nivel de educaci贸n': ['Primaria', 'Secundaria', 'Bachillerato', 'T茅cnico', 'Profesional', 'Maestr铆a', 'Doctorado']})\n",
    "\n",
    "# Instanciamos el codificador ordinal\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "# Ajustamos el codificador a los datos del dataframe\n",
    "encoder.fit(df)\n",
    "\n",
    "# Transformamos los datos categ贸ricos ordinales en valores num茅ricos ordenados\n",
    "transformed_data = encoder.transform(df)\n",
    "\n",
    "# Creamos un nuevo dataframe con los datos transformados\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=df.columns)\n",
    "\n",
    "print(transformed_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, el codificador ordinal convierte la columna `\"Nivel de educaci贸n\"` en valores num茅ricos ordenados del 0 al 6, basado en la posici贸n de cada categor铆a en la escala ordinal."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Codificaci贸n One-Hot (One-Hot Encoder)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La codificaci贸n `One-Hot` (tambi茅n conocida como One-Hot Encoder) es una t茅cnica de preprocesamiento de datos que se utiliza para convertir variables categ贸ricas en variables num茅ricas binarias. Cada categor铆a de la variable original se convierte en una nueva columna binaria, y se asigna un valor de 1 si la instancia pertenece a esa categor铆a, y 0 si no lo hace.\n",
    "\n",
    "Por ejemplo, si tenemos una columna `\"Color\"` con tres categor铆as: `\"Rojo\"`, `\"Verde\"` y `\"Azul\"`, la codificaci贸n `One-Hot` crear铆a tres nuevas columnas: `\"Rojo\"`, `\"Verde\"` y `\"Azul\"`. Si una instancia tiene el color `\"Rojo\"`, su columna correspondiente tendr谩 un valor de 1 y las otras dos columnas tendr谩n un valor de 0.\n",
    "\n",
    "A continuaci贸n, se presenta un ejemplo de c贸mo utilizar la codificaci贸n `One-Hot` en Python con la biblioteca `Scikit-Learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Color_Azul  Color_Rojo  Color_Verde\n",
      "0         0.0         1.0          0.0\n",
      "1         0.0         0.0          1.0\n",
      "2         1.0         0.0          0.0\n",
      "3         0.0         1.0          0.0\n",
      "4         0.0         1.0          0.0\n",
      "5         0.0         0.0          1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Creamos un dataframe con datos categ贸ricos\n",
    "df = pd.DataFrame({'Color': ['Rojo', 'Verde', 'Azul', 'Rojo', 'Rojo', 'Verde']})\n",
    "\n",
    "# Instanciamos el codificador One-Hot\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# Ajustamos el codificador a los datos del dataframe\n",
    "encoder.fit(df)\n",
    "\n",
    "# Transformamos los datos categ贸ricos en valores num茅ricos binarios\n",
    "transformed_data = encoder.transform(df).toarray()\n",
    "\n",
    "# Obtenemos los nombres de las nuevas columnas\n",
    "feature_names = encoder.get_feature_names_out(input_features=['Color'])\n",
    "\n",
    "# Creamos un nuevo dataframe con los datos transformados\n",
    "transformed_df = pd.DataFrame(transformed_data, columns=feature_names)\n",
    "\n",
    "print(transformed_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, el codificador `One-Hot` convierte la columna `\"Color\"` en tres nuevas columnas binarias `\"x0_Azul\"`, `\"x0_Rojo\"` y `\"x0_Verde\"`. Cada columna representa una categor铆a 煤nica y se asigna un valor de 1 si la instancia pertenece a esa categor铆a y 0 si no lo hace."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Comparaci贸n de las codificaciones v铆a un clasificador**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, compararemos el desempe帽o de la codificaci贸n ordinal y `one-hot` encoding en un clasificador de regresi贸n log铆stica utilizando el conjunto de datos `Iris`. Primero, cargamos el conjunto de datos y separamos las caracter铆sticas `(X)` y las etiquetas `(y)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar el conjunto de datos Iris\n",
    "iris = load_iris()\n",
    "\n",
    "# Separar caracter铆sticas y etiquetas\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Dividir los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n, creamos dos transformadores utilizando el codificador ordinal y `one-hot encoder`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Definir las caracter铆sticas categ贸ricas y num茅ricas\n",
    "categorical_cols = [3]\n",
    "numeric_cols = [0, 1, 2]\n",
    "\n",
    "# Crear un transformador con el codificador ordinal\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_transformer = Pipeline(steps=[('ordinal_encoder', ordinal_encoder)])\n",
    "preprocessor_ordinal = ColumnTransformer(transformers=[\n",
    "    ('ordinal', ordinal_transformer, categorical_cols),\n",
    "    ('numeric', 'passthrough', numeric_cols)\n",
    "])\n",
    "\n",
    "# Crear un transformador con el codificador one-hot\n",
    "onehot_encoder = OneHotEncoder()\n",
    "onehot_transformer = Pipeline(steps=[('onehot_encoder', onehot_encoder)])\n",
    "preprocessor_onehot = ColumnTransformer(transformers=[\n",
    "    ('onehot', onehot_transformer, categorical_cols),\n",
    "    ('numeric', 'passthrough', numeric_cols)\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luego, creamos dos clasificadores de regresi贸n log铆stica, uno para cada transformador:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear un clasificador de regresi贸n log铆stica con el transformador ordinal\n",
    "clf_ordinal = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_ordinal),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Crear un clasificador de regresi贸n log铆stica con el transformador one-hot\n",
    "clf_onehot = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor_onehot),\n",
    "    ('classifier', LogisticRegression())\n",
    "])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos ambos clasificadores con los datos de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [3]),\n",
       "                                                 (&#x27;numeric&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [0, 1, 2])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;preprocessor&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;onehot_encoder&#x27;,\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [3]),\n",
       "                                                 (&#x27;numeric&#x27;, &#x27;passthrough&#x27;,\n",
       "                                                  [0, 1, 2])])),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">preprocessor: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;onehot_encoder&#x27;,\n",
       "                                                  OneHotEncoder())]),\n",
       "                                 [3]),\n",
       "                                (&#x27;numeric&#x27;, &#x27;passthrough&#x27;, [0, 1, 2])])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">onehot</label><div class=\"sk-toggleable__content\"><pre>[3]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">numeric</label><div class=\"sk-toggleable__content\"><pre>[0, 1, 2]</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">passthrough</label><div class=\"sk-toggleable__content\"><pre>passthrough</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('onehot',\n",
       "                                                  Pipeline(steps=[('onehot_encoder',\n",
       "                                                                   OneHotEncoder())]),\n",
       "                                                  [3]),\n",
       "                                                 ('numeric', 'passthrough',\n",
       "                                                  [0, 1, 2])])),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entrenar el clasificador con el transformador ordinal\n",
    "clf_ordinal.fit(X_train, y_train)\n",
    "\n",
    "# Entrenar el clasificador con el transformador one-hot\n",
    "clf_onehot.fit(X_train, y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, evaluamos el desempe帽o de ambos clasificadores en los datos de prueba:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy con codificaci贸n ordinal: 1.00\n",
      "Accuracy con codificaci贸n one-hot: 1.00\n"
     ]
    }
   ],
   "source": [
    "# Hacer predicciones con el clasificador con el transformador ordinal\n",
    "y_pred_ordinal = clf_ordinal.predict(X_test)\n",
    "accuracy_ordinal = accuracy_score(y_test, y_pred_ordinal)\n",
    "\n",
    "# Hacer predicciones con el clasificador con el transformador one-hot\n",
    "y_pred_onehot = clf_onehot.predict(X_test)\n",
    "accuracy_onehot = accuracy_score(y_test, y_pred_onehot)\n",
    "\n",
    "# Imprimir el desempe帽o de ambos clasificadores\n",
    "print(f'Accuracy con codificaci贸n ordinal: {accuracy_ordinal:.2f}')\n",
    "print(f'Accuracy con codificaci贸n one-hot: {accuracy_onehot:.2f}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C贸mo dividir el data set en entrenamiento y test**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el aprendizaje autom谩tico, es com煤n dividir el conjunto de datos en dos subconjuntos: el conjunto de entrenamiento y el conjunto de prueba. El conjunto de entrenamiento se utiliza para ajustar el modelo de aprendizaje autom谩tico, mientras que el conjunto de prueba se utiliza para evaluar el rendimiento del modelo.\n",
    "\n",
    "Aqu铆 te explicar茅 c贸mo dividir un conjunto de datos en Python utilizando la librer铆a `Scikit-learn`.\n",
    "\n",
    "Primero, necesitamos cargar el conjunto de datos. Para este ejemplo, utilizaremos el conjunto de datos `iris` que ya viene incluido en `Scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n, vamos a dividir los datos en un conjunto de entrenamiento y un conjunto de prueba. `Scikit-learn` proporciona la funci贸n `train_test_split` para dividir los datos de manera aleatoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3, random_state=42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu铆, `iris.data` son los datos de entrada y `iris.target` son las etiquetas de clase correspondientes. `test_size` es el porcentaje del conjunto de datos que se utilizar谩 para el conjunto de prueba, que en este caso es del 30%. `random_state` es una semilla aleatoria para asegurarnos de que obtenemos la misma divisi贸n de datos cada vez que ejecutamos el c贸digo.\n",
    "\n",
    "Ahora tenemos cuatro conjuntos de datos: `X_train`, `X_test`, `y_train`, y `y_test`. `X_train` y `y_train` se utilizan para entrenar el modelo, mientras que `X_test` y `y_test` se utilizan para evaluar el rendimiento del modelo.\n",
    "\n",
    "Finalmente, podemos verificar el tama帽o de los conjuntos de datos de entrenamiento y prueba utilizando la funci贸n `shape`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (105, 4)\n",
      "y_train shape: (105,)\n",
      "X_test shape: (45, 4)\n",
      "y_test shape: (45,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"y_test shape:\", y_test.shape)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En resumen, la funci贸n `train_test_split` nos permite dividir un conjunto de datos en un conjunto de entrenamiento y un conjunto de prueba de manera aleatoria en Python."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![C贸mo dividir el data set en entrenamiento y test](../imagenes%20Machine_Learning/dataset%20_entrenamiento_test.webp \"C贸mo dividir el data set en entrenamiento y test\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **C贸mo escalar los datos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el aprendizaje autom谩tico, es com煤n que las diferentes caracter铆sticas (variables) de un conjunto de datos tengan diferentes escalas o rangos de valores. Por ejemplo, una caracter铆stica puede tener valores entre 0 y 1, mientras que otra puede tener valores entre 0 y 1000. Escalar los datos es un proceso que transforma los valores de las caracter铆sticas en una escala com煤n, lo que puede mejorar la eficacia de los algoritmos de aprendizaje autom谩tico.\n",
    "\n",
    "Aqu铆 te explicar茅 c贸mo escalar los datos en Python utilizando la librer铆a `Scikit-learn`.\n",
    "\n",
    "Primero, necesitamos cargar el conjunto de datos. Para este ejemplo, utilizaremos el conjunto de datos iris que ya viene incluido en `Scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n, vamos a escalar los datos utilizando la funci贸n `StandardScaler` de `Scikit-learn`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(iris.data)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqu铆, `StandardScaler` es un objeto de la clase `StandardScaler` que se utiliza para escalar los datos. La funci贸n `fit_transform` se utiliza para ajustar el escalador a los datos y transformar los datos de entrada `iris.data` en una escala com煤n `X_scaled`. El conjunto de datos escalado resultante `X_scaled` es un `numpy` `array` con las mismas dimensiones que `iris.data`.\n",
    "\n",
    "Podemos verificar los valores escalados de los datos utilizando la funci贸n `mean` y `std` de `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Media de los datos originales: [5.84333333 3.05733333 3.758      1.19933333]\n",
      "Desviaci贸n est谩ndar de los datos originales: [0.82530129 0.43441097 1.75940407 0.75969263]\n",
      "Media de los datos escalados: [-1.69031455e-15 -1.84297022e-15 -1.69864123e-15 -1.40924309e-15]\n",
      "Desviaci贸n est谩ndar de los datos escalados: [1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(\"Media de los datos originales:\", np.mean(iris.data, axis=0))\n",
    "print(\"Desviaci贸n est谩ndar de los datos originales:\", np.std(iris.data, axis=0))\n",
    "print(\"Media de los datos escalados:\", np.mean(X_scaled, axis=0))\n",
    "print(\"Desviaci贸n est谩ndar de los datos escalados:\", np.std(X_scaled, axis=0))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que los datos escalados tienen una media de casi 0 y una desviaci贸n est谩ndar de 1, lo que indica que est谩n en una escala com煤n.\n",
    "\n",
    "En resumen, la funci贸n `StandardScaler` de `Scikit-learn` nos permite escalar los datos para transformar las diferentes caracter铆sticas en una escala com煤n."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **Siguiente 2** |\n",
    "|----------- |-------------- |\n",
    "| [](../../README.md) | [](./2.Regresion.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
