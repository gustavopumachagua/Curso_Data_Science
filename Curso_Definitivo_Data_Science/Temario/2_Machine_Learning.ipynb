{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr√°s 1** | **Siguiente 3** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [üè†](../../README.md) | [‚è™](./1_Machine_Learning.ipynb)| [‚è©](./3_Machine_Learning.ipynb)|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **11. ¬øQu√© son los tensores?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un tensor es una estructura matem√°tica que generaliza los conceptos de escalares, vectores y matrices a dimensiones superiores. En el contexto del Aprendizaje Profundo y la programaci√≥n en Python con bibliotecas como TensorFlow y PyTorch, los tensores se utilizan para representar y manipular datos multidimensionales. Aqu√≠ tienes una explicaci√≥n detallada con ejemplos:\n",
    "\n",
    "**1. Escalares, Vectores y Matrices:**\n",
    "   - Un **escalar** es un n√∫mero √∫nico, como 42 o 3.1416.\n",
    "   - Un **vector** es un conjunto de n√∫meros organizados en una sola dimensi√≥n. Por ejemplo, [1, 2, 3].\n",
    "   - Una **matriz** es un conjunto de n√∫meros organizados en dos dimensiones. Ejemplo:\n",
    "\n",
    "     ```\n",
    "     [1, 2, 3]\n",
    "     [4, 5, 6]\n",
    "     ```\n",
    "\n",
    "**2. Tensores de Orden Superior:**\n",
    "   - Los tensores son una generalizaci√≥n de escalares, vectores y matrices que pueden tener un n√∫mero arbitrario de dimensiones.\n",
    "   - Un tensor de **orden 0** es un escalar, un tensor de **orden 1** es un vector y un tensor de **orden 2** es una matriz.\n",
    "\n",
    "**3. Ejemplos de Tensores:**\n",
    "   - Un tensor de **orden 3** podr√≠a representar un cubo de datos tridimensional, como un conjunto de im√°genes en color, donde cada p√≠xel tiene tres valores (rojo, verde, azul).\n",
    "   - Un tensor de **orden 4** podr√≠a representar un conjunto de videos, donde cada cuadro de video es un tensor de orden 3 (una imagen) y los cuadros se organizan en una secuencia temporal.\n",
    "   - Un tensor de **orden n** puede representar datos multidimensionales m√°s complejos, como vol√∫menes de im√°genes en resonancia magn√©tica o datos clim√°ticos tridimensionales.\n",
    "\n",
    "**4. Ejemplos Pr√°cticos:**\n",
    "   - En el contexto del Aprendizaje Profundo, las im√°genes a menudo se representan como tensores. Una imagen en blanco y negro puede ser un tensor de orden 2, donde cada elemento del tensor representa la intensidad del p√≠xel. Una imagen en color se representa como un tensor de orden 3, donde cada p√≠xel tiene tres valores (rojo, verde, azul).\n",
    "\n",
    "   ```\n",
    "   Imagen en blanco y negro (tensor de orden 2):\n",
    "   [[0.1, 0.2, 0.3],\n",
    "    [0.4, 0.5, 0.6],\n",
    "    [0.7, 0.8, 0.9]]\n",
    "\n",
    "   Imagen en color (tensor de orden 3):\n",
    "   [[[0.1, 0.2, 0.3],\n",
    "     [0.4, 0.5, 0.6],\n",
    "     [0.7, 0.8, 0.9]],\n",
    "    [[0.2, 0.3, 0.4],\n",
    "     [0.5, 0.6, 0.7],\n",
    "     [0.8, 0.9, 0.1]]]\n",
    "   ```\n",
    "\n",
    "**5. Operaciones con Tensores:**\n",
    "   - Los tensores se utilizan en operaciones matem√°ticas en Aprendizaje Profundo, como la multiplicaci√≥n de matrices, la convoluci√≥n en im√°genes, la propagaci√≥n hacia atr√°s en redes neuronales y m√°s. Estas operaciones se escalan para funcionar en datos multidimensionales.\n",
    "\n",
    "En resumen, los tensores son una herramienta esencial en Aprendizaje Profundo y representan datos multidimensionales en forma de matrices n-dimensionales. Son fundamentales para la representaci√≥n y manipulaci√≥n de datos en el entrenamiento y la inferencia de modelos de Aprendizaje Autom√°tico, y permiten trabajar con datos de alta dimensionalidad, como im√°genes, secuencias de texto y m√°s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tensor en aprendizaje autom√°tico**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el contexto del Aprendizaje Autom√°tico (Machine Learning), un tensor es una estructura de datos multidimensional que se utiliza para representar y manipular datos. Los tensores son fundamentales para el procesamiento de datos en tareas de Aprendizaje Autom√°tico y se utilizan en bibliotecas como TensorFlow y PyTorch. Aqu√≠ tienes una explicaci√≥n detallada con ejemplos:\n",
    "\n",
    "**1. Definici√≥n de Tensores:**\n",
    "   - Un tensor es una generalizaci√≥n de escalares, vectores y matrices a dimensiones superiores. Puede ser un n√∫mero √∫nico (escalar), un conjunto de n√∫meros en una sola dimensi√≥n (vector), un conjunto de n√∫meros organizados en dos dimensiones (matriz) o tener m√°s de dos dimensiones.\n",
    "\n",
    "**2. Orden de un Tensor:**\n",
    "   - El orden de un tensor se refiere a la cantidad de dimensiones que tiene. Un tensor de orden 0 es un escalar, un tensor de orden 1 es un vector, un tensor de orden 2 es una matriz, y as√≠ sucesivamente.\n",
    "\n",
    "**3. Ejemplos de Tensores:**\n",
    "   - **Tensor de Orden 0 (Escalar):**\n",
    "     - Ejemplo: `5.0` o `3.1416`\n",
    "     - Un valor √∫nico, sin dimensiones.\n",
    "\n",
    "   - **Tensor de Orden 1 (Vector):**\n",
    "     - Ejemplo: `[1, 2, 3]`\n",
    "     - Un conjunto de valores organizados en una sola dimensi√≥n.\n",
    "\n",
    "   - **Tensor de Orden 2 (Matriz):**\n",
    "     - Ejemplo:\n",
    "     ```\n",
    "     [[1, 2, 3],\n",
    "      [4, 5, 6],\n",
    "      [7, 8, 9]]\n",
    "     ```\n",
    "     - Un conjunto de valores organizados en dos dimensiones.\n",
    "\n",
    "   - **Tensor de Orden 3 o Superior:**\n",
    "     - Ejemplo:\n",
    "     ```\n",
    "     [[[1, 2, 3],\n",
    "       [4, 5, 6]],\n",
    "      [[7, 8, 9],\n",
    "       [10, 11, 12]]\n",
    "     ]\n",
    "     ```\n",
    "     - Un tensor de orden 3 representa datos tridimensionales, como un conjunto de im√°genes en color, donde cada p√≠xel tiene tres valores (rojo, verde, azul).\n",
    "\n",
    "**4. Aplicaciones en Aprendizaje Autom√°tico:**\n",
    "   - En Aprendizaje Autom√°tico, los tensores se utilizan para representar datos, par√°metros de modelos y gradientes en operaciones matem√°ticas.\n",
    "   - Los datos de entrenamiento se representan como tensores. Por ejemplo, un conjunto de im√°genes en escala de grises se representa como un tensor de orden 4, donde la primera dimensi√≥n corresponde al n√∫mero de ejemplos, la segunda dimensi√≥n a los canales de color (en este caso, 1), y las dos √∫ltimas dimensiones son el alto y el ancho de la imagen.\n",
    "\n",
    "**5. Operaciones con Tensores:**\n",
    "   - En Aprendizaje Autom√°tico, se realizan operaciones matem√°ticas en tensores, como la multiplicaci√≥n de matrices, la convoluci√≥n en im√°genes, la propagaci√≥n hacia atr√°s en redes neuronales y m√°s.\n",
    "   - Por ejemplo, en una red neuronal, los pesos y las activaciones se representan como tensores, y las operaciones de propagaci√≥n hacia adelante y hacia atr√°s implican operaciones de tensor.\n",
    "\n",
    "**6. Bibliotecas de Aprendizaje Autom√°tico:**\n",
    "   - TensorFlow y PyTorch son bibliotecas populares que proporcionan estructuras de datos de tensor y operaciones de tensor optimizadas para Aprendizaje Autom√°tico.\n",
    "\n",
    "**7. Representaci√≥n de Tensores en TensorFlow:**\n",
    "   - En TensorFlow, puedes crear tensores de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(5.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Escalar\n",
    "escalar = tf.constant(5.0)\n",
    "print(escalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Vector\n",
    "vector = tf.constant([1, 2, 3])\n",
    "print(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2 3]\n",
      " [4 5 6]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Matriz\n",
    "matriz = tf.constant([[1, 2, 3], [4, 5, 6]])\n",
    "print(matriz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]], shape=(2, 2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Tensor de orden 3\n",
    "tensor_3d = tf.constant([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "print(tensor_3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tensores son esenciales en Aprendizaje Autom√°tico porque permiten representar y manipular datos de manera eficiente y extensible, lo que facilita el procesamiento de datos en tareas de modelado y predicci√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tensor](../img/tensor1.jpg \"Tensor\")\n",
    "![Tensor](../img/tensor.jpg \"Tensor\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **12. Enmarcando un problema de aprendizaje autom√°tico | C√≥mo planificar un proyecto de ciencia de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enmarcar un problema de Aprendizaje Autom√°tico y planificar un proyecto de Ciencia de Datos son pasos cruciales para el √©xito en la resoluci√≥n de problemas utilizando datos. A continuaci√≥n, se proporciona una explicaci√≥n detallada de c√≥mo hacerlo, junto con ejemplos:\n",
    "\n",
    "**1. Identificar el Problema:**\n",
    "   - El primer paso es definir claramente el problema que se pretende resolver. ¬øQu√© pregunta deseas responder o qu√© objetivo deseas alcanzar? Por ejemplo, si eres una empresa de comercio electr√≥nico, podr√≠as preguntarte: \"¬øC√≥mo podemos reducir la tasa de abandono del carrito de compras?\"\n",
    "\n",
    "**2. Recopilaci√≥n de Datos:**\n",
    "   - Identifica y re√∫ne los datos necesarios para abordar el problema. Los datos pueden provenir de m√∫ltiples fuentes, como bases de datos internas, registros, API externas o datos p√∫blicos. Para el ejemplo del comercio electr√≥nico, los datos podr√≠an incluir registros de actividad de los usuarios, historiales de compras y datos de navegaci√≥n en el sitio web.\n",
    "\n",
    "**3. Limpieza y Preparaci√≥n de Datos:**\n",
    "   - Los datos rara vez est√°n listos para su an√°lisis directo. Debes realizar tareas de limpieza y preparaci√≥n, que incluyen tratar con valores faltantes, eliminar duplicados y convertir datos en un formato utilizable. Por ejemplo, podr√≠as necesitar eliminar registros con informaci√≥n incompleta o inconsistente en tu conjunto de datos.\n",
    "\n",
    "**4. An√°lisis Exploratorio de Datos:**\n",
    "   - Realiza un an√°lisis exploratorio para comprender tus datos. Esto incluye visualizar datos, calcular estad√≠sticas descriptivas y buscar patrones. Por ejemplo, podr√≠as usar gr√°ficos para visualizar la distribuci√≥n de edades de tus usuarios y c√≥mo se relaciona con el abandono del carrito.\n",
    "\n",
    "**5. Selecci√≥n de Caracter√≠sticas:**\n",
    "   - Identifica las caracter√≠sticas (variables) que son relevantes para el problema. Esto puede requerir el uso de t√©cnicas de selecci√≥n de caracter√≠sticas. En el caso del comercio electr√≥nico, las caracter√≠sticas relevantes pueden incluir la duraci√≥n de la sesi√≥n del usuario, el n√∫mero de productos en el carrito, el historial de compras, etc.\n",
    "\n",
    "**6. Dise√±o de un Modelo de Aprendizaje Autom√°tico:**\n",
    "   - Selecciona el tipo de modelo de Aprendizaje Autom√°tico adecuado para el problema. Puedes optar por un enfoque de clasificaci√≥n, regresi√≥n, agrupaci√≥n, etc. Por ejemplo, podr√≠as elegir utilizar un modelo de regresi√≥n log√≠stica para predecir el abandono del carrito.\n",
    "\n",
    "**7. Conjunto de Entrenamiento y Pruebas:**\n",
    "   - Divide tus datos en conjuntos de entrenamiento y prueba. El conjunto de entrenamiento se utiliza para entrenar el modelo, y el conjunto de pruebas se utiliza para evaluar su rendimiento. Por ejemplo, podr√≠as asignar el 80% de los datos para entrenamiento y el 20% para pruebas.\n",
    "\n",
    "**8. Entrenamiento del Modelo:**\n",
    "   - Utiliza el conjunto de entrenamiento para entrenar el modelo. Esto implica ajustar los par√°metros del modelo para que pueda hacer predicciones precisas basadas en los datos de entrenamiento.\n",
    "\n",
    "**9. Evaluaci√≥n del Modelo:**\n",
    "   - Eval√∫a el rendimiento del modelo utilizando m√©tricas adecuadas para el tipo de problema que est√°s resolviendo. Por ejemplo, si est√°s prediciendo el abandono del carrito, podr√≠as usar m√©tricas como la precisi√≥n, la sensibilidad y la especificidad.\n",
    "\n",
    "**10. Optimizaci√≥n y Ajuste:**\n",
    "    - Si el rendimiento del modelo no cumple con los criterios deseados, puedes ajustar hiperpar√°metros, probar diferentes algoritmos o realizar ingenier√≠a de caracter√≠sticas para mejorar el modelo.\n",
    "\n",
    "**11. Implementaci√≥n y Puesta en Producci√≥n:**\n",
    "    - Una vez que el modelo es satisfactorio, puedes implementarlo en un entorno de producci√≥n. En el caso del comercio electr√≥nico, esto podr√≠a implicar la integraci√≥n del modelo en el sitio web para identificar usuarios propensos al abandono del carrito.\n",
    "\n",
    "**12. Seguimiento y Mantenimiento Continuo:**\n",
    "    - Monitorea el rendimiento del modelo en producci√≥n y realiza un mantenimiento continuo. Los datos y las condiciones cambian con el tiempo, por lo que es importante mantener el modelo actualizado y efectivo.\n",
    "\n",
    "**13. Comunicaci√≥n de Resultados:**\n",
    "    - Comunica los resultados y las conclusiones a las partes interesadas. Puedes presentar informes, visualizaciones y explicaciones para garantizar que las decisiones basadas en datos sean comprensibles y √∫tiles.\n",
    "\n",
    "Planificar un proyecto de Ciencia de Datos y Aprendizaje Autom√°tico de esta manera ayuda a garantizar que est√©s abordando un problema con una metodolog√≠a s√≥lida y orientada a resultados. Adem√°s, facilita la toma de decisiones basadas en datos y la creaci√≥n de soluciones efectivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **13.EDA mediante an√°lisis univariado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El An√°lisis Exploratorio de Datos (EDA, por sus siglas en ingl√©s) es una etapa fundamental en el proceso de Ciencia de Datos que implica explorar y comprender un conjunto de datos antes de realizar an√°lisis m√°s avanzados o modelado. El an√°lisis univariado es una parte esencial del EDA y se centra en el estudio de una variable (caracter√≠stica) a la vez. Aqu√≠ te proporciono una explicaci√≥n detallada del EDA mediante an√°lisis univariado, junto con ejemplos:\n",
    "\n",
    "**1. ¬øQu√© es el An√°lisis Univariado?**\n",
    "   - El an√°lisis univariado se enfoca en entender una sola variable en un conjunto de datos. El objetivo es describir, resumir y visualizar la distribuci√≥n y las propiedades de una variable individual.\n",
    "\n",
    "**2. Ejemplos de Variables Univariadas:**\n",
    "   - Ejemplos comunes de variables univariadas incluyen la edad de las personas, el ingreso anual, el n√∫mero de compras en l√≠nea, la temperatura diaria, etc.\n",
    "\n",
    "**3. T√©cnicas de An√°lisis Univariado:**\n",
    "   - A continuaci√≥n, se detallan algunas t√©cnicas comunes utilizadas en el an√°lisis univariado:\n",
    "\n",
    "   a. **Medidas de Resumen:** Calcular estad√≠sticas descriptivas, como la media, la mediana, la moda, la desviaci√≥n est√°ndar, el rango y los percentiles. Por ejemplo, al analizar las edades de una poblaci√≥n, puedes calcular la mediana para identificar la edad que divide la poblaci√≥n en dos mitades iguales.\n",
    "\n",
    "   b. **Visualizaciones:** Crear gr√°ficos y visualizaciones que muestren la distribuci√≥n de la variable. Ejemplos de gr√°ficos incluyen histogramas, gr√°ficos de barras, gr√°ficos de caja, gr√°ficos de densidad y diagramas de dispersi√≥n. Por ejemplo, al analizar las calificaciones de estudiantes, puedes usar un histograma para mostrar la distribuci√≥n de las calificaciones.\n",
    "\n",
    "   c. **Tablas de Contingencia:** Si la variable es categ√≥rica, puedes crear tablas de contingencia que muestren la frecuencia de cada categor√≠a. Esto es √∫til para comprender la distribuci√≥n de categor√≠as. Por ejemplo, al analizar los g√©neros de empleados en una empresa, puedes crear una tabla de contingencia que muestre la cantidad de empleados en cada categor√≠a de g√©nero.\n",
    "\n",
    "**4. Ejemplo de An√°lisis Univariado:**\n",
    "   - Supongamos que tienes un conjunto de datos que contiene las edades de una muestra de personas. Para realizar un an√°lisis univariado de la variable \"edad\", podr√≠as hacer lo siguiente:\n",
    "\n",
    "   a. Calcular la media, mediana y desviaci√≥n est√°ndar para tener una idea general de la distribuci√≥n de edades.\n",
    "\n",
    "   b. Crear un histograma que muestre la distribuci√≥n de edades en grupos, lo que te ayudar√≠a a identificar patrones, como si la mayor√≠a de las personas son j√≥venes o de mediana edad.\n",
    "\n",
    "   c. Calcular percentiles, como el percentil 25 y el percentil 75, para entender mejor la dispersi√≥n de las edades.\n",
    "\n",
    "   d. Si es relevante, puedes crear un gr√°fico de caja para identificar valores at√≠picos o extremos en la distribuci√≥n de edades.\n",
    "\n",
    "**5. Beneficios del An√°lisis Univariado:**\n",
    "   - El an√°lisis univariado te permite obtener una comprensi√≥n s√≥lida de cada variable en tu conjunto de datos. Te ayuda a detectar valores at√≠picos, identificar patrones y tomar decisiones informadas sobre el preprocesamiento de datos y las futuras etapas de an√°lisis.\n",
    "\n",
    "El an√°lisis univariado es el primer paso para explorar y entender tus datos antes de avanzar en an√°lisis m√°s complejos, como el an√°lisis bivariado (que implica el estudio de dos variables juntas) y la construcci√≥n de modelos de Aprendizaje Autom√°tico. Es fundamental para garantizar que tus decisiones y an√°lisis se basen en una comprensi√≥n s√≥lida de los datos subyacentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **14. EDA mediante an√°lisis bivariado y multivariado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El An√°lisis Exploratorio de Datos (EDA, por sus siglas en ingl√©s) es una etapa fundamental en el proceso de Ciencia de Datos que implica explorar y comprender un conjunto de datos antes de realizar an√°lisis m√°s avanzados o modelado. El an√°lisis bivariado y multivariado son extensiones del an√°lisis univariado y se centran en el estudio de relaciones entre dos o m√°s variables en un conjunto de datos. Aqu√≠ tienes una explicaci√≥n detallada del EDA mediante an√°lisis bivariado y multivariado, junto con ejemplos:\n",
    "\n",
    "**1. An√°lisis Bivariado:**\n",
    "\n",
    "   - El an√°lisis bivariado se enfoca en entender las relaciones entre dos variables en un conjunto de datos. El objetivo es explorar c√≥mo dos variables interact√∫an y se relacionan entre s√≠.\n",
    "\n",
    "**2. Ejemplos de An√°lisis Bivariado:**\n",
    "\n",
    "   - Ejemplos comunes de an√°lisis bivariado incluyen estudiar la relaci√≥n entre la edad y los ingresos, la correlaci√≥n entre la publicidad y las ventas, la comparaci√≥n de la temperatura y la demanda de productos, etc.\n",
    "\n",
    "**3. T√©cnicas de An√°lisis Bivariado:**\n",
    "\n",
    "   - A continuaci√≥n, se detallan algunas t√©cnicas comunes utilizadas en el an√°lisis bivariado:\n",
    "\n",
    "   a. **Matriz de Correlaci√≥n:** Calcula coeficientes de correlaci√≥n entre dos variables num√©ricas. Por ejemplo, puedes calcular la correlaci√≥n entre la edad de los clientes y el gasto promedio.\n",
    "\n",
    "   b. **Gr√°ficos de Dispersi√≥n:** Crea gr√°ficos de dispersi√≥n para visualizar la relaci√≥n entre dos variables num√©ricas. Por ejemplo, puedes usar un gr√°fico de dispersi√≥n para analizar la relaci√≥n entre el tiempo de estudio y las calificaciones de los estudiantes.\n",
    "\n",
    "   c. **Tablas de Contingencia:** Si una variable es categ√≥rica, puedes crear tablas de contingencia para mostrar c√≥mo se relaciona con otra variable categ√≥rica. Por ejemplo, puedes crear una tabla de contingencia que muestre la relaci√≥n entre el g√©nero de los empleados y su departamento.\n",
    "\n",
    "**4. Ejemplo de An√°lisis Bivariado:**\n",
    "\n",
    "   - Supongamos que tienes un conjunto de datos que contiene las edades y los ingresos de las personas. Para realizar un an√°lisis bivariado de estas dos variables, podr√≠as hacer lo siguiente:\n",
    "\n",
    "   a. Calcular el coeficiente de correlaci√≥n, que te dir√° si existe una relaci√≥n lineal entre la edad y los ingresos. Un valor cercano a 1 indicar√≠a una correlaci√≥n positiva, mientras que un valor cercano a -1 indicar√≠a una correlaci√≥n negativa.\n",
    "\n",
    "   b. Crear un gr√°fico de dispersi√≥n que muestre la relaci√≥n entre la edad y los ingresos. Esto te ayudar√° a visualizar cualquier patr√≥n o tendencia en los datos.\n",
    "\n",
    "**5. An√°lisis Multivariado:**\n",
    "\n",
    "   - El an√°lisis multivariado implica el estudio de relaciones entre m√°s de dos variables en un conjunto de datos. El objetivo es comprender c√≥mo m√∫ltiples variables interact√∫an y se influyen mutuamente.\n",
    "\n",
    "**6. Ejemplos de An√°lisis Multivariado:**\n",
    "\n",
    "   - Ejemplos comunes de an√°lisis multivariado incluyen estudiar c√≥mo m√∫ltiples factores afectan las ventas de productos, analizar la interacci√≥n entre variables econ√≥micas y sociales en un estudio demogr√°fico, o comprender c√≥mo diferentes caracter√≠sticas de un autom√≥vil influyen en su precio de venta.\n",
    "\n",
    "**7. T√©cnicas de An√°lisis Multivariado:**\n",
    "\n",
    "   - A continuaci√≥n, se detallan algunas t√©cnicas comunes utilizadas en el an√°lisis multivariado:\n",
    "\n",
    "   a. **An√°lisis de Regresi√≥n M√∫ltiple:** Permite modelar la relaci√≥n entre una variable dependiente y m√∫ltiples variables independientes. Por ejemplo, podr√≠as usar un an√°lisis de regresi√≥n m√∫ltiple para entender c√≥mo las caracter√≠sticas del producto influyen en las ventas.\n",
    "\n",
    "   b. **An√°lisis de Componentes Principales (PCA):** Reduce la dimensionalidad de los datos manteniendo la informaci√≥n m√°s importante. Es √∫til cuando se tienen muchas variables y se busca simplificar el an√°lisis.\n",
    "\n",
    "   c. **An√°lisis de Cl√∫ster (Clustering):** Agrupa observaciones similares en grupos (cl√∫steres) en funci√≥n de m√∫ltiples variables. Esto ayuda a identificar patrones o segmentos en los datos.\n",
    "\n",
    "**8. Ejemplo de An√°lisis Multivariado:**\n",
    "\n",
    "   - Supongamos que tienes un conjunto de datos que contiene informaci√≥n sobre productos, incluyendo precio, tama√±o, caracter√≠sticas, y ventas. Para realizar un an√°lisis multivariado, podr√≠as hacer lo siguiente:\n",
    "\n",
    "   a. Utilizar un an√°lisis de regresi√≥n m√∫ltiple para modelar c√≥mo el precio, el tama√±o y las caracter√≠sticas del producto influyen en las ventas. Esto te permitir√° comprender qu√© variables son m√°s importantes en la predicci√≥n de las ventas.\n",
    "\n",
    "   b. Aplicar el an√°lisis de componentes principales (PCA) para reducir la dimensionalidad de los datos y visualizar la estructura subyacente de las variables.\n",
    "\n",
    "**9. Beneficios del An√°lisis Bivariado y Multivariado:**\n",
    "\n",
    "   - Estos tipos de an√°lisis permiten descubrir relaciones, patrones y dependencias entre variables, lo que es esencial para tomar decisiones informadas en Ciencia de Datos y Aprendizaje Autom√°tico. Tambi√©n ayudan a identificar variables predictoras importantes y a entender c√≥mo interact√∫an las variables en un sistema complejo.\n",
    "\n",
    "En resumen, el an√°lisis bivariado y multivariado son t√©cnicas esenciales en el An√°lisis Exploratorio de Datos que te permiten profundizar en la comprensi√≥n de tus datos al estudiar las relaciones entre variables. Esto es fundamental para la toma de decisiones basadas en datos y para el dise√±o de modelos m√°s precisos y efectivos en proyectos de Ciencia de Datos y Aprendizaje Autom√°tico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **15. ¬øQu√© es la ingenier√≠a de caracter√≠sticas?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La ingenier√≠a de caracter√≠sticas es un proceso fundamental en Ciencia de Datos y Aprendizaje Autom√°tico que implica la creaci√≥n, selecci√≥n y transformaci√≥n de variables (caracter√≠sticas) a partir de los datos brutos para mejorar el rendimiento de los modelos y la capacidad de extraer informaci√≥n significativa. A continuaci√≥n, te proporciono una explicaci√≥n detallada de la ingenier√≠a de caracter√≠sticas con ejemplos:\n",
    "\n",
    "**1. ¬øQu√© es la Ingenier√≠a de Caracter√≠sticas?**\n",
    "\n",
    "   - La ingenier√≠a de caracter√≠sticas es el proceso de preparar y manipular los datos mediante la creaci√≥n, modificaci√≥n o selecci√≥n de caracter√≠sticas que sean m√°s relevantes y √∫tiles para el problema que se est√° abordando. El objetivo es mejorar la precisi√≥n de los modelos de Aprendizaje Autom√°tico y facilitar la extracci√≥n de informaci√≥n significativa.\n",
    "\n",
    "**2. Ejemplos de Ingenier√≠a de Caracter√≠sticas:**\n",
    "\n",
    "   - Aqu√≠ hay ejemplos concretos de lo que podr√≠a involucrar la ingenier√≠a de caracter√≠sticas:\n",
    "\n",
    "   a. **Creaci√≥n de Caracter√≠sticas:** Puedes crear nuevas caracter√≠sticas a partir de las existentes. Por ejemplo, si tienes un conjunto de datos de ventas que incluye la fecha de compra, puedes crear una caracter√≠stica de \"d√≠a de la semana\" o \"mes\" a partir de la fecha.\n",
    "\n",
    "   b. **Codificaci√≥n de Variables Categ√≥ricas:** Si tienes variables categ√≥ricas, como el g√©nero (\"hombre\" o \"mujer\"), puedes codificarlas num√©ricamente, por ejemplo, como 0 y 1.\n",
    "\n",
    "   c. **Normalizaci√≥n y Escalado:** Puedes normalizar o escalar caracter√≠sticas num√©ricas para asegurarte de que tengan la misma escala. Esto es importante en algoritmos sensibles a la escala, como las m√°quinas de soporte vectorial (SVM).\n",
    "\n",
    "   d. **Extracci√≥n de Caracter√≠sticas de Texto:** En el procesamiento de lenguaje natural, puedes extraer caracter√≠sticas de texto, como recuento de palabras, TF-IDF (frecuencia de t√©rmino-inversa de frecuencia de documento) o embeddings de palabras.\n",
    "\n",
    "   e. **Selecci√≥n de Caracter√≠sticas:** Puedes identificar y seleccionar las caracter√≠sticas m√°s importantes para tu modelo, lo que reduce la complejidad y mejora la generalizaci√≥n.\n",
    "\n",
    "   f. **Creaci√≥n de Caracter√≠sticas Interactivas:** Puedes crear caracter√≠sticas que capturen interacciones entre variables. Por ejemplo, en un conjunto de datos de ventas en l√≠nea, podr√≠as crear una caracter√≠stica que sea el producto del precio y la cantidad para medir el valor de la compra.\n",
    "\n",
    "**3. Importancia de la Ingenier√≠a de Caracter√≠sticas:**\n",
    "\n",
    "   - La calidad de las caracter√≠sticas utilizadas en un modelo es tan importante como el algoritmo de aprendizaje en s√≠. Caracter√≠sticas adecuadas pueden llevar a modelos m√°s precisos y significativos, mientras que caracter√≠sticas inadecuadas pueden llevar a resultados deficientes.\n",
    "\n",
    "**4. Ejemplo de Ingenier√≠a de Caracter√≠sticas:**\n",
    "\n",
    "   - Supongamos que trabajas con un conjunto de datos de viviendas en venta y deseas predecir el precio de una vivienda. El conjunto de datos contiene caracter√≠sticas como el n√∫mero de habitaciones, el tama√±o del terreno y la ubicaci√≥n. Ejemplos de ingenier√≠a de caracter√≠sticas podr√≠an incluir:\n",
    "\n",
    "   a. Creaci√≥n de una caracter√≠stica \"tama√±o del terreno por habitaci√≥n\" que podr√≠a indicar la densidad de construcci√≥n.\n",
    "\n",
    "   b. Codificaci√≥n de la ubicaci√≥n (categ√≥rica) en una variable num√©rica utilizando t√©cnicas como \"one-hot encoding\".\n",
    "\n",
    "   c. Normalizaci√≥n de las caracter√≠sticas para asegurarse de que tengan la misma escala, lo que podr√≠a mejorar la precisi√≥n del modelo.\n",
    "\n",
    "   d. Creaci√≥n de caracter√≠sticas adicionales, como \"distancia a las escuelas\" o \"n√∫mero de servicios p√∫blicos cercanos\".\n",
    "\n",
    "**5. Herramientas y Bibliotecas:**\n",
    "\n",
    "   - Para llevar a cabo la ingenier√≠a de caracter√≠sticas, puedes utilizar bibliotecas de Ciencia de Datos como scikit-learn en Python, que proporciona herramientas y transformadores para realizar muchas de estas operaciones.\n",
    "\n",
    "La ingenier√≠a de caracter√≠sticas es un proceso creativo y fundamental en Ciencia de Datos y Aprendizaje Autom√°tico. Permite adaptar los datos para que se ajusten mejor a los modelos y a los objetivos espec√≠ficos del proyecto, lo que conduce a una mejora significativa en el rendimiento y la eficacia de los modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **16. Escalado de funciones: estandarizaci√≥n**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estandarizaci√≥n es una t√©cnica de preprocesamiento de datos com√∫n en Ciencia de Datos y Aprendizaje Autom√°tico que se utiliza para asegurarse de que las caracter√≠sticas tengan una media de 0 y una desviaci√≥n est√°ndar de 1. Esto es importante en algoritmos que son sensibles a la escala de las caracter√≠sticas, como las M√°quinas de Soporte Vectorial (SVM), el An√°lisis de Componentes Principales (PCA) y otros. Aqu√≠ tienes una explicaci√≥n detallada de la estandarizaci√≥n con ejemplos:\n",
    "\n",
    "**1. ¬øQu√© es la Estandarizaci√≥n (o Escalado de Funciones)?**\n",
    "\n",
    "   - La estandarizaci√≥n es una t√©cnica que ajusta la escala de las caracter√≠sticas en un conjunto de datos para que tengan una distribuci√≥n con una media de 0 y una desviaci√≥n est√°ndar de 1. Esto significa que los valores de las caracter√≠sticas estar√°n centrados alrededor de 0 y tendr√°n una dispersi√≥n uniforme.\n",
    "\n",
    "**2. F√≥rmula de la Estandarizaci√≥n:**\n",
    "\n",
    "   - La f√≥rmula para estandarizar una variable $(X)$ se expresa como:\n",
    "\n",
    "   $[X_{\\text{estandarizado}} = \\frac{X - \\mu}{\\sigma}]$\n",
    "\n",
    "   Donde:\n",
    "   - $(X_{\\text{estandarizado}})$ es el valor estandarizado de la variable.\n",
    "   - $(X)$ es el valor original de la variable.\n",
    "   - $(\\mu)$ es la media (promedio) de la variable.\n",
    "   - $(\\sigma)$ es la desviaci√≥n est√°ndar de la variable.\n",
    "\n",
    "**3. Ejemplo de Estandarizaci√≥n:**\n",
    "\n",
    "   - Supongamos que tienes un conjunto de datos con una caracter√≠stica, como \"ingresos mensuales\", que tiene una media de $4,000 y una desviaci√≥n est√°ndar de $1,000. Para estandarizar esta caracter√≠stica, puedes aplicar la f√≥rmula de estandarizaci√≥n:\n",
    "\n",
    "   $[X_{\\text{estandarizado}} = \\frac{X - 4000}{1000}]$\n",
    "\n",
    "   - Si un individuo tiene un ingreso mensual de $4,500, despu√©s de la estandarizaci√≥n, el valor estandarizado ser√≠a:\n",
    "\n",
    "   $[X_{\\text{estandarizado}} = \\frac{4500 - 4000}{1000} = 0.5]$\n",
    "\n",
    "   - De manera similar, si otro individuo tiene un ingreso mensual de $3,800, su valor estandarizado ser√≠a:\n",
    "\n",
    "   $[X_{\\text{estandarizado}} = \\frac{3800 - 4000}{1000} = -0.2]$\n",
    "\n",
    "**4. Beneficios de la Estandarizaci√≥n:**\n",
    "\n",
    "   - La estandarizaci√≥n ofrece varios beneficios:\n",
    "\n",
    "   a. Ayuda a que las caracter√≠sticas tengan una escala comparable, lo que es importante en algoritmos que utilizan distancias euclidianas, como k-means o PCA.\n",
    "\n",
    "   b. Evita que las caracter√≠sticas con magnitudes m√°s grandes dominen o sesguen la importancia de otras caracter√≠sticas en los modelos.\n",
    "\n",
    "   c. Facilita la interpretaci√≥n de los coeficientes en algoritmos de regresi√≥n, ya que los coeficientes reflejar√°n el cambio en la variable objetivo por cada desviaci√≥n est√°ndar en lugar de por unidad de la variable original.\n",
    "\n",
    "**5. Herramientas y Bibliotecas:**\n",
    "\n",
    "   - En Python, puedes utilizar bibliotecas como scikit-learn para realizar la estandarizaci√≥n de caracter√≠sticas. Por ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "[[100.    2. ]\n",
      " [ 50.    1.5]\n",
      " [ 80.    2.2]\n",
      " [ 90.    2. ]]\n",
      "\n",
      "Datos estandarizados:\n",
      "[[ 1.06904497  0.29002095]\n",
      " [-1.60356745 -1.64345203]\n",
      " [ 0.          1.06341014]\n",
      " [ 0.53452248  0.29002095]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Crear un conjunto de datos de ejemplo\n",
    "datos = np.array([[100.0, 2.0],\n",
    "                  [50.0, 1.5],\n",
    "                  [80.0, 2.2],\n",
    "                  [90.0, 2.0]])\n",
    "\n",
    "# Crear un objeto StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Ajustar el scaler a tus datos y transformar las caracter√≠sticas\n",
    "datos_estandarizados = scaler.fit_transform(datos)\n",
    "\n",
    "# Las caracter√≠sticas ahora est√°n estandarizadas\n",
    "print(\"Datos originales:\")\n",
    "print(datos)\n",
    "print(\"\\nDatos estandarizados:\")\n",
    "print(datos_estandarizados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estandarizaci√≥n es una t√©cnica esencial en el preprocesamiento de datos que asegura que las caracter√≠sticas tengan una escala uniforme y facilita la aplicaci√≥n de algoritmos de Aprendizaje Autom√°tico en los que la escala es importante. Esto mejora la capacidad de los modelos para realizar predicciones precisas y coherentes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **17. Escalado de funciones: Normalization | MinMaxScaling | MaxAbsScaling | RobustScaling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El escalado de funciones es una t√©cnica com√∫n en Ciencia de Datos y Aprendizaje Autom√°tico para transformar las caracter√≠sticas de un conjunto de datos a un rango espec√≠fico. Aqu√≠ tienes una explicaci√≥n detallada de varios m√©todos de escalado de funciones (Normalization, Min-Max Scaling, Max Absolute Scaling y Robust Scaling) junto con ejemplos en c√≥digo en Python.\n",
    "\n",
    "**1. Normalization (Escalamiento a la unidad):**\n",
    "\n",
    "La normalizaci√≥n (tambi√©n conocida como L2 Normalization) escala cada muestra de datos para que su norma L2 (longitud del vector) sea igual a 1. Es √∫til cuando trabajas con algoritmos sensibles a la magnitud de los valores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[X_{\\text{normalized}} = \\frac{X}{\\sqrt{X_1^2 + X_2^2 + \\ldots + X_n^2}}]$\n",
    "\n",
    "Donde:\n",
    "- $(X_{\\text{normalized}})$ es el valor normalizado.\n",
    "- $(X)$ es el valor original.\n",
    "- $(X_1, X_2, \\ldots, X_n)$ son los valores originales de las caracter√≠sticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "[[2 4]\n",
      " [1 3]\n",
      " [4 5]]\n",
      "\n",
      "Datos normalizados:\n",
      "[[0.4472136  0.89442719]\n",
      " [0.31622777 0.9486833 ]\n",
      " [0.62469505 0.78086881]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "import numpy as np\n",
    "\n",
    "# Crear un conjunto de datos de ejemplo\n",
    "data = np.array([[2, 4],\n",
    "                 [1, 3],\n",
    "                 [4, 5]])\n",
    "\n",
    "# Crear un objeto Normalizer\n",
    "normalizer = Normalizer()\n",
    "\n",
    "# Aplicar la normalizaci√≥n\n",
    "normalized_data = normalizer.transform(data)\n",
    "\n",
    "print(\"Datos originales:\")\n",
    "print(data)\n",
    "print(\"\\nDatos normalizados:\")\n",
    "print(normalized_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**2. Min-Max Scaling (Escalamiento Min-Max):**\n",
    "\n",
    "Min-Max Scaling escala los datos para que est√©n en un rango espec√≠fico, generalmente entre 0 y 1. Es √∫til cuando deseas que tus datos est√©n en una escala espec√≠fica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[X_{\\text{scaled}} = \\frac{X - X_{\\text{min}}}{X_{\\text{max}} - X_{\\text{min}}}]$\n",
    "\n",
    "Donde:\n",
    "- $(X_{\\text{scaled}})$ es el valor escalado.\n",
    "- $(X)$ es el valor original.\n",
    "- $(X_{\\text{min}})$ es el valor m√≠nimo en el conjunto de datos.\n",
    "- $(X_{\\text{max}})$ es el valor m√°ximo en el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "[[2 4]\n",
      " [1 3]\n",
      " [4 5]]\n",
      "\n",
      "Datos escalados Min-Max:\n",
      "[[0.33333333 0.5       ]\n",
      " [0.         0.        ]\n",
      " [1.         1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "\n",
    "# Crear un conjunto de datos de ejemplo\n",
    "data = np.array([[2, 4],\n",
    "                 [1, 3],\n",
    "                 [4, 5]])\n",
    "\n",
    "# Crear un objeto MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Aplicar el escalado Min-Max\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Datos originales:\")\n",
    "print(data)\n",
    "print(\"\\nDatos escalados Min-Max:\")\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Max Absolute Scaling (Escalamiento M√°ximo Absoluto):**\n",
    "\n",
    "Max Absolute Scaling escala los datos dividiendo cada valor por el valor absoluto m√°ximo en el conjunto de datos. Esto asegura que todos los datos est√©n en el rango [-1, 1]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[X_{\\text{scaled}} = \\frac{X}{\\max(|X|)}]$\n",
    "\n",
    "Donde:\n",
    "- $(X_{\\text{scaled}})$ es el valor escalado.\n",
    "- $(X)$ es el valor original.\n",
    "- $(\\max(|X|))$ es el valor absoluto m√°ximo en el conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "[[-2  4]\n",
      " [ 1  3]\n",
      " [ 4 -5]]\n",
      "\n",
      "Datos escalados Max Absolute:\n",
      "[[-0.5   0.8 ]\n",
      " [ 0.25  0.6 ]\n",
      " [ 1.   -1.  ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "import numpy as np\n",
    "\n",
    "# Crear un conjunto de datos de ejemplo\n",
    "data = np.array([[-2, 4],\n",
    "                 [1, 3],\n",
    "                 [4, -5]])\n",
    "\n",
    "# Crear un objeto MaxAbsScaler\n",
    "scaler = MaxAbsScaler()\n",
    "\n",
    "# Aplicar el escalado Max Absolute\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Datos originales:\")\n",
    "print(data)\n",
    "print(\"\\nDatos escalados Max Absolute:\")\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Robust Scaling (Escalamiento Robusto):**\n",
    "\n",
    "El escalado robusto utiliza estad√≠sticas resistentes a los valores at√≠picos para escalar los datos. Resta la mediana de cada caracter√≠stica y luego la divide por el rango intercuart√≠lico (IQR). Esto lo hace m√°s robusto frente a valores at√≠picos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$[X_{\\text{scaled}} = \\frac{X - \\text{Mediana}(X)}{\\text{IQR}(X)}]$\n",
    "\n",
    "Donde:\n",
    "- $(X_{\\text{scaled}})$ es el valor escalado.\n",
    "- $(X)$ es el valor original.\n",
    "- $(\\text{Mediana}(X))$ es la mediana de la caracter√≠stica.\n",
    "- $(\\text{IQR}(X))$ es el rango intercuart√≠lico de la caracter√≠stica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "[[  2   4]\n",
      " [  1   3]\n",
      " [100   5]\n",
      " [  4   5]]\n",
      "\n",
      "Datos escalados robustos:\n",
      "[[-0.03809524 -0.4       ]\n",
      " [-0.07619048 -1.2       ]\n",
      " [ 3.6952381   0.4       ]\n",
      " [ 0.03809524  0.4       ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "import numpy as np\n",
    "\n",
    "# Crear un conjunto de datos de ejemplo con valores at√≠picos\n",
    "data = np.array([[2, 4],\n",
    "                 [1, 3],\n",
    "                 [100, 5],\n",
    "                 [4, 5]])\n",
    "\n",
    "# Crear un objeto RobustScaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "# Aplicar el escalado robusto\n",
    "scaled_data = scaler.fit_transform(data)\n",
    "\n",
    "print(\"Datos originales:\")\n",
    "print(data)\n",
    "print(\"\\nDatos escalados robustos:\")\n",
    "print(scaled_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos m√©todos de escalado de funciones son √∫tiles para asegurarse de que los datos se ajusten a la escala deseada y para mejorar la eficiencia y el rendimiento de los modelos de Aprendizaje Autom√°tico, especialmente cuando los algoritmos son sensibles a la magnitud de los valores. La elecci√≥n del m√©todo de escalado depende de las caracter√≠sticas de tus datos y los requisitos de tu modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **18. Codificaci√≥n de datos categ√≥ricos | Codificaci√≥n ordinal | Codificaci√≥n de etiquetas**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La codificaci√≥n de datos categ√≥ricos es un proceso esencial en el preprocesamiento de datos cuando se trabaja con variables categ√≥ricas en Ciencia de Datos y Aprendizaje Autom√°tico. Hay varios enfoques para codificar estas variables, y dos de los m√°s comunes son la codificaci√≥n ordinal y la codificaci√≥n de etiquetas. Aqu√≠ te proporciono una explicaci√≥n detallada de ambos enfoques con ejemplos en c√≥digo en Python.\n",
    "\n",
    "**1. Codificaci√≥n Ordinal:**\n",
    "\n",
    "La codificaci√≥n ordinal se utiliza cuando las categor√≠as categ√≥ricas tienen un orden intr√≠nseco. Por ejemplo, las calificaciones acad√©micas (\"bajo\", \"medio\", \"alto\") o los tama√±os de ropa (\"S\", \"M\", \"L\", \"XL\") son ejemplos de variables categ√≥ricas ordinales.\n",
    "\n",
    "El proceso implica asignar valores num√©ricos a cada categor√≠a en funci√≥n de su posici√≥n en el orden. Aqu√≠ tienes un ejemplo en c√≥digo utilizando la biblioteca scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "['bajo', 'medio', 'alto', 'medio', 'bajo']\n",
      "\n",
      "Datos codificados:\n",
      "[[0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Datos de ejemplo con una variable categ√≥rica ordinal\n",
    "categorias = [\"bajo\", \"medio\", \"alto\", \"medio\", \"bajo\"]\n",
    "\n",
    "# Crear un objeto OrdinalEncoder\n",
    "encoder = OrdinalEncoder(categories=[[\"bajo\", \"medio\", \"alto\"]])\n",
    "\n",
    "# Ajustar el encoder a las categor√≠as y transformar los datos\n",
    "datos_codificados = encoder.fit_transform(np.array(categorias).reshape(-1, 1))\n",
    "\n",
    "print(\"Datos originales:\")\n",
    "print(categorias)\n",
    "print(\"\\nDatos codificados:\")\n",
    "print(datos_codificados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, las categor√≠as \"bajo\", \"medio\" y \"alto\" se codifican como 0, 1 y 2, respectivamente, seg√∫n el orden especificado en la lista de categor√≠as.\n",
    "\n",
    "**2. Codificaci√≥n de Etiquetas:**\n",
    "\n",
    "La codificaci√≥n de etiquetas se utiliza cuando las categor√≠as categ√≥ricas no tienen un orden intr√≠nseco, y simplemente se les asigna un valor num√©rico √∫nico. Este enfoque es com√∫n en casos de variables categ√≥ricas nominales, como colores, g√©neros, ciudades, etc.\n",
    "\n",
    "Aqu√≠ tienes un ejemplo en c√≥digo utilizando la biblioteca scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "['rojo', 'verde', 'azul', 'rojo', 'verde']\n",
      "\n",
      "Datos codificados:\n",
      "[1 2 0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Datos de ejemplo con una variable categ√≥rica nominal\n",
    "categorias = [\"rojo\", \"verde\", \"azul\", \"rojo\", \"verde\"]\n",
    "\n",
    "# Crear un objeto LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "\n",
    "# Ajustar el encoder a las categor√≠as y transformar los datos\n",
    "datos_codificados = encoder.fit_transform(categorias)\n",
    "\n",
    "print(\"Datos originales:\")\n",
    "print(categorias)\n",
    "print(\"\\nDatos codificados:\")\n",
    "print(datos_codificados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, las categor√≠as \"rojo\", \"verde\" y \"azul\" se codifican como 0, 1 y 2, respectivamente, sin tener en cuenta ning√∫n orden espec√≠fico.\n",
    "\n",
    "Es importante recordar que la elecci√≥n entre la codificaci√≥n ordinal y la codificaci√≥n de etiquetas depende de la naturaleza de los datos y del problema en cuesti√≥n. La codificaci√≥n ordinal se utiliza cuando existe un orden natural entre las categor√≠as, mientras que la codificaci√≥n de etiquetas se utiliza cuando las categor√≠as son nominales y no tienen un orden intr√≠nseco."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **19. One Hot Encoding | Handling Categorical Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El \"One-Hot Encoding\" es una t√©cnica de codificaci√≥n utilizada para manejar datos categ√≥ricos en Ciencia de Datos y Aprendizaje Autom√°tico. Esta t√©cnica convierte variables categ√≥ricas en una representaci√≥n binaria (0 o 1) para que puedan ser utilizadas eficazmente por los modelos de Aprendizaje Autom√°tico. Aqu√≠ te proporciono una explicaci√≥n detallada del \"One-Hot Encoding\" con ejemplos en c√≥digo en Python.\n",
    "\n",
    "**1. ¬øQu√© es el One-Hot Encoding?**\n",
    "\n",
    "El \"One-Hot Encoding\" es un enfoque que convierte cada categor√≠a √∫nica en una variable binaria (0 o 1). Cada categor√≠a se representa como una columna distinta en la que se asigna un 1 si la observaci√≥n pertenece a esa categor√≠a y un 0 en caso contrario.\n",
    "\n",
    "**2. Ejemplo de One-Hot Encoding:**\n",
    "\n",
    "Supongamos que tienes un conjunto de datos con una variable categ√≥rica \"Color\" que puede tener tres categor√≠as: \"Rojo\", \"Verde\" y \"Azul\". El \"One-Hot Encoding\" crear√≠a tres columnas adicionales, una para cada categor√≠a, y asignar√≠a un 1 a la columna correspondiente a la categor√≠a y 0 a las otras columnas.\n",
    "\n",
    "Ejemplo de datos originales:\n",
    "```\n",
    "+----+-------+\n",
    "| ID | Color |\n",
    "+----+-------+\n",
    "| 1  | Rojo  |\n",
    "| 2  | Verde |\n",
    "| 3  | Azul  |\n",
    "| 4  | Rojo  |\n",
    "+----+-------+\n",
    "```\n",
    "\n",
    "Despu√©s de aplicar \"One-Hot Encoding\", los datos se ver√≠an as√≠:\n",
    "```\n",
    "+----+------+------+-------+\n",
    "| ID | Rojo | Verde | Azul  |\n",
    "+----+------+------+-------+\n",
    "| 1  | 1    | 0     | 0    |\n",
    "| 2  | 0    | 1     | 0    |\n",
    "| 3  | 0    | 0     | 1    |\n",
    "| 4  | 1    | 0     | 0    |\n",
    "+----+------+------+-------+\n",
    "```\n",
    "\n",
    "Cada columna representa una categor√≠a y tiene un valor binario que indica si la observaci√≥n pertenece o no a esa categor√≠a. Esto permite que los algoritmos de Aprendizaje Autom√°tico trabajen con variables categ√≥ricas de manera efectiva.\n",
    "\n",
    "**3. Ejemplo en C√≥digo:**\n",
    "\n",
    "Puedes utilizar la biblioteca scikit-learn para realizar \"One-Hot Encoding\" en Python. Aqu√≠ tienes un ejemplo de c√≥mo hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos originales:\n",
      "   Color\n",
      "0   Rojo\n",
      "1  Verde\n",
      "2   Azul\n",
      "3   Rojo\n",
      "\n",
      "Datos codificados con One-Hot Encoding:\n",
      "   Color_Azul  Color_Rojo  Color_Verde\n",
      "0         0.0         1.0          0.0\n",
      "1         0.0         0.0          1.0\n",
      "2         1.0         0.0          0.0\n",
      "3         0.0         1.0          0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import pandas as pd\n",
    "\n",
    "# Crear un DataFrame de ejemplo con la variable categ√≥rica \"Color\"\n",
    "data = pd.DataFrame({'Color': ['Rojo', 'Verde', 'Azul', 'Rojo']})\n",
    "\n",
    "# Crear un objeto OneHotEncoder con sparse_output=False\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "\n",
    "# Ajustar el encoder a los datos y transformarlos\n",
    "data_encoded = encoder.fit_transform(data[['Color']])\n",
    "\n",
    "# Obtener los nombres de las columnas codificadas\n",
    "column_names = encoder.get_feature_names_out(input_features=['Color'])\n",
    "\n",
    "# Crear un nuevo DataFrame con las columnas codificadas\n",
    "encoded_df = pd.DataFrame(data=data_encoded, columns=column_names)\n",
    "\n",
    "print(\"Datos originales:\")\n",
    "print(data)\n",
    "print(\"\\nDatos codificados con One-Hot Encoding:\")\n",
    "print(encoded_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este c√≥digo utiliza `OneHotEncoder` para codificar la variable categ√≥rica \"Color\" y crea un nuevo DataFrame con las columnas codificadas. Cada columna representa una categor√≠a √∫nica y tiene valores binarios 0 o 1, seg√∫n la presencia o ausencia de la categor√≠a en cada observaci√≥n.\n",
    "\n",
    "El \"One-Hot Encoding\" es una t√©cnica valiosa para trabajar con datos categ√≥ricos en Aprendizaje Autom√°tico, ya que permite que los modelos utilicen estas variables de manera efectiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **20. Transformador de columna en aprendizaje autom√°tico | C√≥mo utilizar ColumnTransformer en Sklearn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un transformador de columna es una herramienta importante en Aprendizaje Autom√°tico que permite aplicar transformaciones espec√≠ficas a diferentes columnas de un conjunto de datos. `ColumnTransformer` en scikit-learn es una clase que facilita la aplicaci√≥n de transformaciones a columnas espec√≠ficas de un conjunto de datos, lo que es √∫til cuando se trabaja con caracter√≠sticas heterog√©neas. Aqu√≠ tienes una explicaci√≥n detallada de c√≥mo utilizar `ColumnTransformer` con ejemplos en c√≥digo en Python.\n",
    "\n",
    "**1. ¬øQu√© es `ColumnTransformer`?**\n",
    "\n",
    "`ColumnTransformer` es una clase de scikit-learn que permite aplicar transformaciones a columnas espec√≠ficas de un conjunto de datos. Esto es √∫til cuando se trabaja con conjuntos de datos que contienen diferentes tipos de caracter√≠sticas, como num√©ricas, categ√≥ricas, texto, etc.\n",
    "\n",
    "**2. Ejemplo de Uso de `ColumnTransformer`:**\n",
    "\n",
    "Supongamos que tienes un conjunto de datos con tres columnas: una columna num√©rica, una columna categ√≥rica y una columna de texto. Deseas aplicar diferentes transformaciones a cada tipo de columna. A continuaci√≥n, se muestra un ejemplo de c√≥mo hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos transformados:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-1.34164079,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.70710678,  0.70710678,  0.        ,  0.        ],\n",
       "       [-0.4472136 ,  0.        ,  1.        ,  0.        ,  0.70710678,\n",
       "         0.70710678,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.4472136 ,  1.        ,  0.        ,  0.        ,  0.        ,\n",
       "         0.        ,  0.57735027,  0.57735027,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.57735027],\n",
       "       [ 1.34164079,  0.        ,  0.        ,  1.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.57735027,  0.57735027,\n",
       "         0.        ,  0.        ,  0.57735027,  0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Crear un DataFrame de ejemplo\n",
    "data = pd.DataFrame({\n",
    "    'Numerico': [10, 20, 30, 40],\n",
    "    'Categorico': ['A', 'B', 'A', 'C'],\n",
    "    'Texto': ['Hola mundo', 'Aprendizaje autom√°tico', 'Texto de ejemplo', 'Sklearn es genial']\n",
    "})\n",
    "\n",
    "# Definir las transformaciones para cada tipo de columna\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())  # Estandarizar los valores num√©ricos\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder())  # Aplicar One-Hot Encoding a las categor√≠as\n",
    "])\n",
    "\n",
    "text_transformer = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer())  # Aplicar TF-IDF a los datos de texto\n",
    "])\n",
    "\n",
    "# Crear un ColumnTransformer que aplique las transformaciones a las columnas correspondientes\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, ['Numerico']),  # Aplicar a la columna 'Numerico'\n",
    "        ('cat', categorical_transformer, ['Categorico']),  # Aplicar a la columna 'Categorico'\n",
    "        ('text', text_transformer, 'Texto')  # Aplicar a la columna 'Texto'\n",
    "    ],\n",
    "    remainder='passthrough'  # Mantener las columnas no transformadas\n",
    ")\n",
    "\n",
    "# Ajustar y transformar los datos utilizando el ColumnTransformer\n",
    "transformed_data = preprocessor.fit_transform(data)\n",
    "print(\"Datos transformados:\")\n",
    "transformed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, hemos definido transformaciones espec√≠ficas para columnas num√©ricas, categ√≥ricas y de texto. Luego, utilizamos `ColumnTransformer` para aplicar estas transformaciones a las columnas correspondientes en el conjunto de datos. Las columnas resultantes se combinan en un nuevo conjunto de datos transformado.\n",
    "\n",
    "`ColumnTransformer` es √∫til para gestionar conjuntos de datos con diferentes tipos de caracter√≠sticas y aplicar transformaciones espec√≠ficas a cada tipo de columna, lo que es fundamental en la ingenier√≠a de caracter√≠sticas en Aprendizaje Autom√°tico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atr√°s 1** | **Siguiente 3** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [üè†](../../README.md) | [‚è™](./1_Machine_Learning.ipynb)| [‚è©](./3_Machine_Learning.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
