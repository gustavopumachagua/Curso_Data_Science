{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 6** | **Siguiente 8** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../README.md) | [⏪](./6.Web_Scraping_de_APIs_iFrames_y_Scripts.ipynb)| [⏩](./8.Evitando_Problemas_Eticas.ipynb)|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **7. Autenticación y Captchas**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introducción a la Autenticación Online**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La autenticación en línea es un aspecto importante a considerar al realizar web scraping, especialmente cuando los sitios web requieren que los usuarios inicien sesión antes de acceder a ciertos datos o funcionalidades. En esta explicación detallada, te mostraré los conceptos básicos de la autenticación en línea y cómo abordarla en el contexto del web scraping, junto con ejemplos prácticos.\n",
    "\n",
    "1. **¿Qué es la autenticación en línea?**\n",
    "\n",
    "La autenticación en línea es un proceso mediante el cual un usuario se identifica y verifica para acceder a un sistema o servicio en línea. Por lo general, implica proporcionar credenciales, como un nombre de usuario y una contraseña, para demostrar la identidad del usuario y obtener acceso autorizado.\n",
    "\n",
    "2. **Métodos de autenticación en línea**\n",
    "\n",
    "Hay varios métodos de autenticación en línea utilizados por los sitios web. Algunos de los métodos comunes incluyen:\n",
    "\n",
    "* **Formulario de inicio de sesión:** El usuario proporciona un nombre de usuario y una contraseña a través de un formulario en la página de inicio de sesión del sitio web.\n",
    "* **Autenticación basada en tokens:** El sitio web emite un token de acceso al usuario después de una autenticación exitosa, y el usuario proporciona este token en cada solicitud subsiguiente para verificar su identidad.\n",
    "* **Autenticación basada en cookies:** Después del inicio de sesión exitoso, el sitio web crea y envía una cookie al navegador del usuario. El navegador luego envía automáticamente esta cookie en cada solicitud posterior para autenticar al usuario.\n",
    "* **Autenticación mediante API:** Algunos sitios web proporcionan una API con endpoints específicos para autenticación, donde los usuarios pueden enviar solicitudes y recibir tokens o cookies de autenticación.\n",
    "\n",
    "3. **Cómo abordar la autenticación en web scraping**\n",
    "\n",
    "Cuando se enfrenta a la autenticación en línea al realizar web scraping, existen varios enfoques que se pueden utilizar:\n",
    "\n",
    "* **Autenticación manual:** Si el sitio web utiliza un formulario de inicio de sesión estándar, puedes automatizar el proceso de inicio de sesión proporcionando las credenciales a través de un script de web scraping. Aquí hay un ejemplo utilizando la biblioteca `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "login_url = 'https://example.com/login'\n",
    "data = {\n",
    "    'username': 'myusername',\n",
    "    'password': 'mypassword'\n",
    "}\n",
    "\n",
    "session = requests.Session()\n",
    "session.post(login_url, data=data)\n",
    "\n",
    "# Continuar con las solicitudes posteriores utilizando la sesión autenticada\n",
    "response = session.get('https://example.com/protected_page')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Autenticación basada en tokens o cookies:** Si el sitio web utiliza tokens o cookies para autenticar al usuario, puedes extraer y utilizar esos tokens o cookies en tus solicitudes posteriores. Aquí hay un ejemplo utilizando la biblioteca `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "login_url = 'https://example.com/login'\n",
    "data = {\n",
    "    'username': 'myusername',\n",
    "    'password': 'mypassword'\n",
    "}\n",
    "\n",
    "session = requests.Session()\n",
    "session.post(login_url, data=data)\n",
    "\n",
    "# Obtener el token o cookie de autenticación\n",
    "auth_token = session.cookies['auth_token']\n",
    "\n",
    "# Continuar con las solicitudes posteriores utilizando el token o cookie de autenticación\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {auth_token}'\n",
    "}\n",
    "response = session.get('https://example.com/protected_page', headers=headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Autenticación mediante API:** Si el sitio web proporciona una API para autenticación, puedes utilizarla para obtener tokens de acceso o cookies de autenticación. Aquí hay un ejemplo utilizando la biblioteca `requests`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "api_url = 'https://example.com/api/auth'\n",
    "data = {\n",
    "    'username': 'myusername',\n",
    "    'password': 'mypassword'\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, json=data)\n",
    "auth_token = response.json()['auth_token']\n",
    "\n",
    "# Continuar con las solicitudes posteriores utilizando el token de autenticación\n",
    "headers = {\n",
    "    'Authorization': f'Bearer {auth_token}'\n",
    "}\n",
    "response = requests.get('https://example.com/protected_page', headers=headers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. **Consideraciones adicionales**\n",
    "\n",
    "Al trabajar con la autenticación en línea en web scraping, es importante tener en cuenta algunas consideraciones adicionales:\n",
    "\n",
    "* **Cumplir con los términos de servicio:** Asegúrate de revisar los términos de servicio del sitio web para comprender las limitaciones o restricciones específicas relacionadas con el web scraping y la autenticación en línea. Algunos sitios web pueden tener políticas estrictas sobre el acceso automatizado a sus servicios.\n",
    "\n",
    "* **Manejo de sesiones:** Utilizar sesiones en lugar de solicitudes independientes te permite mantener el estado de autenticación a lo largo de múltiples solicitudes. Esto asegura que las solicitudes posteriores estén autenticadas y puedas acceder a los datos protegidos.\n",
    "\n",
    "* **Actualizaciones de la autenticación:** Si el sitio web cambia su proceso de autenticación o introduce medidas de seguridad adicionales, es posible que debas actualizar tu script de web scraping para adaptarse a los nuevos requisitos.\n",
    "\n",
    "Recuerda que el web scraping debe realizarse de manera ética y respetando los términos de servicio de los sitios web. Asegúrate de obtener permiso cuando sea necesario y no abuses del acceso a los datos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Autenticación por Form Data de Login (Extracción de GITHUB)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La autenticación por formulario de inicio de sesión es uno de los métodos comunes utilizados por los sitios web para verificar la identidad de los usuarios. En esta explicación detallada, te mostraré cómo abordar la autenticación por formulario de inicio de sesión al realizar web scraping en GitHub, junto con ejemplos prácticos.\n",
    "\n",
    "1. **Identificar el formulario de inicio de sesión:**\n",
    "\n",
    "El primer paso es identificar el formulario de inicio de sesión en el sitio web. En GitHub, el formulario de inicio de sesión suele estar presente en la página de inicio en el elemento `<form>` con el atributo action que apunta a la URL de inicio de sesión.\n",
    "\n",
    "2. **Inspeccionar los campos del formulario:**\n",
    "\n",
    "Usando las herramientas de desarrollo del navegador, inspecciona los campos del formulario para obtener sus nombres y atributos. En el caso de GitHub, los campos comunes en el formulario de inicio de sesión son `login` (nombre de usuario o correo electrónico) y `password` (contraseña).\n",
    "\n",
    "3. **Enviar la solicitud POST con los datos de inicio de sesión:**\n",
    "\n",
    "Utilizando una biblioteca como `requests` en Python, puedes enviar una solicitud `POST` al servidor de GitHub con los datos de inicio de sesión. Aquí está el ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "login_url = 'https://github.com/login'\n",
    "data = {\n",
    "    'login': 'your_username',\n",
    "    'password': 'your_password'\n",
    "}\n",
    "\n",
    "session = requests.Session()\n",
    "response = session.post(login_url, data=data)\n",
    "\n",
    "# Verificar si el inicio de sesión fue exitoso\n",
    "if response.status_code == 200:\n",
    "    # Continuar con las solicitudes posteriores autenticadas\n",
    "    response = session.get('https://github.com/your_profile')\n",
    "    # Procesar la respuesta aquí"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se crea una sesión de `requests.Session()` para mantener el estado de autenticación en las solicitudes posteriores. La solicitud `POST` se realiza a la URL de inicio de sesión con los datos de inicio de sesión proporcionados en el diccionario data. Después de enviar la solicitud, puedes verificar si el inicio de sesión fue exitoso verificando el código de estado de la respuesta.\n",
    "\n",
    "4. **Continuar con las solicitudes autenticadas:**\n",
    "\n",
    "Después de iniciar sesión exitosamente, puedes realizar solicitudes posteriores utilizando la misma sesión autenticada. En el ejemplo anterior, se muestra una solicitud `GET` a la página de perfil después del inicio de sesión exitoso. Puedes ajustar las URL y los endpoints según tus necesidades para extraer los datos requeridos.\n",
    "\n",
    "Recuerda que debes respetar los términos de servicio de GitHub y obtener el permiso adecuado antes de realizar web scraping en su sitio. Además, ten en cuenta que los sitios web pueden cambiar su proceso de autenticación o introducir medidas de seguridad adicionales, por lo que es importante estar atento a posibles actualizaciones y ajustar tu código en consecuencia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Autenticación exclusivamente por API (Extracción de GITHUB)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunos casos, los sitios web ofrecen una autenticación exclusivamente a través de su API. Esto significa que en lugar de utilizar un formulario de inicio de sesión en el sitio web, debes enviar una solicitud autenticada directamente a la API del sitio para obtener un token de acceso que se utilizará en las solicitudes posteriores. A continuación, te mostraré cómo abordar la autenticación exclusivamente por API al realizar web scraping en GitHub, junto con ejemplos prácticos.\n",
    "\n",
    "1. **Obtener las credenciales de autenticación de la API:**\n",
    "\n",
    "Lo primero que debes hacer es obtener las credenciales de autenticación necesarias para realizar solicitudes a la API de GitHub. Esto generalmente implica generar un token de acceso en la configuración de tu cuenta de GitHub. Sigue los pasos específicos de la plataforma para generar un token de acceso con los permisos adecuados.\n",
    "\n",
    "2. **Enviar la solicitud de autenticación a la API:**\n",
    "\n",
    "Usando una biblioteca como `requests` en Python, puedes enviar una solicitud a la API de GitHub para autenticarte y obtener un token de acceso. Aquí tienes un ejemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "auth_url = 'https://api.github.com/authorizations'\n",
    "data = {\n",
    "    'scopes': ['repo'],\n",
    "    'note': 'Web scraping authorization'\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'Authorization': 'Basic your_base64_encoded_credentials'\n",
    "}\n",
    "\n",
    "response = requests.post(auth_url, json=data, headers=headers)\n",
    "\n",
    "# Verificar si la autenticación fue exitosa\n",
    "if response.status_code == 201:\n",
    "    token = response.json()['token']\n",
    "    # Continuar con las solicitudes posteriores autenticadas\n",
    "    headers_auth = {\n",
    "        'Authorization': f'token {token}'\n",
    "    }\n",
    "    response = requests.get('https://api.github.com/user', headers=headers_auth)\n",
    "    # Procesar la respuesta aquí"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se envía una solicitud `POST` a la URL de autenticación de la API de GitHub. Los datos JSON proporcionados incluyen los alcances (scopes) necesarios para las operaciones que deseas realizar y una nota para identificar la autenticación. Además, se incluye un encabezado de autenticación (`Authorization`) que contiene las credenciales codificadas en base64.\n",
    "\n",
    "Después de enviar la solicitud, puedes verificar si la autenticación fue exitosa verificando el código de estado de la respuesta. Si es así, puedes extraer el token de acceso de la respuesta JSON y utilizarlo en las solicitudes posteriores. En el ejemplo anterior, se muestra una solicitud GET a la API de GitHub para obtener información del usuario autenticado.\n",
    "\n",
    "Recuerda respetar los términos de servicio de GitHub y obtener el permiso adecuado antes de realizar web scraping en su sitio. Además, ten en cuenta que los sitios web pueden cambiar su proceso de autenticación o introducir medidas de seguridad adicionales, por lo que es importante estar atento a posibles actualizaciones y ajustar tu código en consecuencia."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Autenticación con Scrapy Spider (Extracción de GITHUB)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En Scrapy, puedes realizar autenticación en un Spider mediante el uso de middlewares personalizados. A continuación, te mostraré cómo implementar la autenticación en un Spider de Scrapy para extraer datos de GitHub. Aquí tienes un ejemplo práctico:\n",
    "\n",
    "1. **Crear un Middleware personalizado:**\n",
    "\n",
    "En primer lugar, debes crear un Middleware personalizado que se encargue de manejar la autenticación en cada solicitud realizada por el Spider. Aquí tienes un ejemplo de cómo podría verse el Middleware:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy import signals\n",
    "from scrapy.http import HtmlResponse\n",
    "from scrapy.exceptions import NotConfigured\n",
    "from base64 import b64encode\n",
    "\n",
    "class GithubAuthMiddleware:\n",
    "    def __init__(self, username, password):\n",
    "        self.username = username\n",
    "        self.password = password\n",
    "\n",
    "    @classmethod\n",
    "    def from_crawler(cls, crawler):\n",
    "        username = crawler.settings.get('GITHUB_USERNAME')\n",
    "        password = crawler.settings.get('GITHUB_PASSWORD')\n",
    "\n",
    "        if not username or not password:\n",
    "            raise NotConfigured(\"GitHub authentication not provided\")\n",
    "\n",
    "        return cls(username, password)\n",
    "\n",
    "    def process_request(self, request, spider):\n",
    "        encoded_credentials = b64encode(f\"{self.username}:{self.password}\".encode('utf-8')).decode('utf-8')\n",
    "        request.headers['Authorization'] = f\"Basic {encoded_credentials}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def process_response(request, response, spider):\n",
    "        if response.status == 401:\n",
    "            spider.logger.warning(\"Authentication failed\")\n",
    "            return HtmlResponse(url=request.url, status=401, request=request)\n",
    "\n",
    "        return response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, el Middleware personalizado se encarga de agregar el encabezado de autenticación (`Authorization`) a cada solicitud saliente. Las credenciales de autenticación se obtienen de las configuraciones del Spider.\n",
    "\n",
    "Además, el Middleware también maneja las respuestas de autenticación fallidas (código de estado 401) y devuelve una respuesta HTML vacía para indicar que la autenticación ha fallado.\n",
    "\n",
    "2. **Agregar el Middleware al Spider:**\n",
    "\n",
    "Una vez que hayas creado el Middleware personalizado, debes agregarlo al Spider para que se utilice durante el proceso de scraping. Para hacer esto, debes modificar el archivo `settings.py` del proyecto Scrapy. Añade la siguiente línea:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOWNLOADER_MIDDLEWARES = {\n",
    "    'myproject.middlewares.GithubAuthMiddleware': 543,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recuerda reemplazar `myproject.middlewares` con el nombre de tu propio proyecto y ruta al Middleware personalizado.\n",
    "\n",
    "Con esto, el Middleware se ejecutará en cada solicitud realizada por el Spider y se encargará de agregar la autenticación necesaria.\n",
    "\n",
    "3. **Utilizar el Middleware en el Spider:**\n",
    "\n",
    "Finalmente, en tu Spider, puedes acceder a los datos autenticados incluyendo `start_requests` y estableciendo la URL de inicio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy\n",
    "\n",
    "class GithubSpider(scrapy.Spider):\n",
    "    name = 'github'\n",
    "    start_urls = ['https://api.github.com/user']\n",
    "\n",
    "    def parse(self, response):\n",
    "        data = response.json()\n",
    "        # Procesar la respuesta aquí"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, el Spider se inicia con la URL `https://api.github.com/user`, que es una API de GitHub que requiere autenticación. La respuesta JSON se puede procesar en el método `parse()` del Spider.\n",
    "\n",
    "Recuerda proporcionar las credenciales de autenticación en las configuraciones del proyecto Scrapy para que el Middleware pueda utilizarlas.\n",
    "\n",
    "Con estos pasos, has implementado la autenticación en un Spider de Scrapy utilizando un Middleware personalizado. Esto te permitirá realizar web scraping autenticado en sitios web que requieren autenticación básica."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **¿Qué son los captchas?**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los captchas son mecanismos utilizados en sitios web para verificar que los usuarios sean humanos y no programas automatizados, como bots o spiders de web scraping. Estas pruebas suelen consistir en desafíos visuales o interactivos que requieren la intervención humana para ser resueltos.\n",
    "\n",
    "Los captchas se utilizan para prevenir actividades no deseadas, como el envío masivo de formularios, el acceso no autorizado a contenido protegido o el abuso de servicios en línea. Estos desafíos son diseñados para ser resueltos por seres humanos, pero suelen ser difíciles para los programas automatizados.\n",
    "\n",
    "Existen diferentes tipos de captchas utilizados en la web, entre los cuales se encuentran:\n",
    "\n",
    "1. **Captchas de texto:** Consisten en mostrar una imagen con una serie de caracteres distorsionados que deben ser ingresados en un campo de texto. El usuario debe leer y escribir los caracteres correctamente para superar la prueba. Un ejemplo de esto es el clásico captcha de \"escriba los caracteres que ve en la imagen\".\n",
    "\n",
    "2. **Captchas de selección:** Se presentan imágenes o conjuntos de imágenes y se le pide al usuario que seleccione aquellas que cumplan con ciertas características. Estas características pueden ser objetos específicos, como \"seleccione todas las imágenes que contengan un automóvil\".\n",
    "\n",
    "3. **Captchas de arrastrar y soltar:** Se muestra una imagen o conjunto de imágenes y se le pide al usuario que las arrastre y suelte en una posición específica o en un orden determinado. Esto requiere de interacción manual y es más difícil para los programas automatizados.\n",
    "\n",
    "4. **Captchas de cálculos matemáticos:** Se presentan problemas matemáticos sencillos que el usuario debe resolver antes de continuar. Estos pueden ser operaciones básicas de suma, resta, multiplicación o división.\n",
    "\n",
    "La presencia de captchas en un sitio web puede dificultar la extracción de datos a través de web scraping, ya que los bots automatizados suelen tener dificultades para resolver estos desafíos. Sin embargo, es importante destacar que los captchas no son infalibles y los métodos para superarlos han evolucionado con el tiempo.\n",
    "\n",
    "Algunas estrategias para lidiar con los captchas en el contexto del web scraping incluyen:\n",
    "\n",
    "1. **Utilizar servicios de reconocimiento óptico de caracteres (OCR):** Estos servicios pueden ayudar a leer y reconocer los caracteres distorsionados de un captcha de texto, permitiendo automatizar la resolución de estos desafíos.\n",
    "\n",
    "2. **Emplear servicios de terceros:** Existen servicios en línea que se especializan en resolver captchas, donde puedes enviar el captcha y recibir la respuesta decodificada. Estos servicios suelen tener un costo asociado.\n",
    "\n",
    "3. **Evitar el uso de captchas:** En algunos casos, es posible encontrar fuentes alternativas de datos que no utilicen captchas o que tengan mecanismos de autenticación más amigables para el web scraping, como APIs o acceso a datos públicos.\n",
    "\n",
    "Es importante destacar que eludir o romper los captchas puede estar en contra de los términos de servicio de un sitio web y puede ser ilegal en algunos casos. Es fundamental respetar las políticas de uso de los sitios web y asegurarse de tener permiso para extraer datos antes de realizar cualquier acción de web scraping."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Resolviendo captchas manualmente**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resolver captchas manualmente implica que una persona real se encarga de completar los desafíos visuales o interactivos que se presentan en un sitio web. Esta tarea generalmente se realiza de forma manual y requiere la intervención humana para superar la prueba.\n",
    "\n",
    "A diferencia de los enfoques automatizados que utilizan algoritmos o servicios de reconocimiento óptico de caracteres (OCR) para resolver captchas, resolverlos manualmente implica que un operador humano interactúa con el sitio web y proporciona las respuestas correctas.\n",
    "\n",
    "El proceso de resolución manual de captchas puede variar dependiendo del tipo de captcha y de cómo esté diseñado el desafío. Aquí se presenta un ejemplo general de cómo se podría abordar la resolución manual de un captcha:\n",
    "\n",
    "1. **Accede al sitio web y encuentra el captcha:** Ingresa a la página web que requiere el captcha y localiza la ubicación del captcha en el formulario o la página en la que se encuentra. El captcha puede ser una imagen o un desafío interactivo.\n",
    "\n",
    "2. **Observa y analiza el captcha:** Examina el captcha con detenimiento y analiza las instrucciones proporcionadas, si las hay. Observa los detalles y características clave del captcha, como los caracteres distorsionados, las imágenes que se presentan o las acciones que se deben realizar.\n",
    "\n",
    "3. **Resuelve el captcha:** Sigue las instrucciones y proporciona la respuesta correcta al desafío. Esto puede implicar leer y escribir los caracteres distorsionados, seleccionar las imágenes que cumplan con ciertas características o realizar una acción específica.\n",
    "\n",
    "4. **Confirma y envía la respuesta:** Verifica que hayas completado correctamente el captcha y confirma tu respuesta. En algunos casos, es posible que se requiera hacer clic en un botón o enviar el formulario para completar el proceso de autenticación.\n",
    "\n",
    "Es importante tener en cuenta que resolver captchas manualmente puede ser un proceso lento y tedioso, especialmente si se requiere resolver varios captchas en un corto período de tiempo. Además, algunos sitios web pueden implementar mecanismos de detección de actividad sospechosa, lo que podría resultar en bloqueos o restricciones para evitar el abuso.\n",
    "\n",
    "Por lo tanto, antes de optar por la resolución manual de captchas, es recomendable revisar los términos de servicio del sitio web y asegurarse de tener permiso para extraer los datos. También es importante considerar otras alternativas, como utilizar servicios de terceros para resolver captchas o explorar fuentes de datos que no requieran autenticación adicional."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Resolviendo captchas de manera automática**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La resolución automática de captchas es un enfoque utilizado en el web scraping para superar los desafíos visuales o interactivos que se presentan en un sitio web sin la intervención manual de un operador humano. Este método implica el uso de algoritmos y técnicas para reconocer y procesar las imágenes o desafíos captcha y proporcionar una respuesta válida.\n",
    "\n",
    "A continuación, se presenta una explicación detallada de cómo se puede abordar la resolución automática de captchas:\n",
    "\n",
    "1. **Identificación del tipo de captcha:** Antes de resolver un captcha de manera automática, es esencial identificar el tipo de captcha con el que se está trabajando. Algunos de los tipos comunes de captchas incluyen caracteres distorsionados, selección de imágenes, desafíos matemáticos, entre otros. Cada tipo puede requerir un enfoque diferente para su resolución.\n",
    "\n",
    "2. **Utilización de bibliotecas o servicios de terceros:** Existen varias bibliotecas y servicios de terceros que pueden ayudar en la resolución automática de captchas. Algunas de las bibliotecas populares incluyen pytesseract, OpenCV, PIL (Python Imaging Library), entre otras. Estas bibliotecas proporcionan funcionalidades para el procesamiento de imágenes, reconocimiento óptico de caracteres (OCR) y técnicas de aprendizaje automático para el reconocimiento de patrones en los captchas.\n",
    "\n",
    "3. **Preprocesamiento de imágenes:** En muchos casos, es necesario realizar un preprocesamiento de las imágenes captcha antes de aplicar algoritmos de reconocimiento. Esto puede incluir técnicas como el ajuste de brillo y contraste, reducción de ruido, recorte de imágenes, binarización, entre otros. El objetivo del preprocesamiento es mejorar la calidad y la legibilidad de las imágenes captcha para facilitar su reconocimiento.\n",
    "\n",
    "4. **Aplicación de algoritmos de reconocimiento:** Una vez que las imágenes captcha han sido preprocesadas, se pueden aplicar algoritmos de reconocimiento para extraer los caracteres o elementos relevantes. Esto puede involucrar técnicas de segmentación de caracteres, reconocimiento de formas, reconocimiento de texto, análisis de colores, entre otros. El algoritmo utilizado dependerá del tipo de captcha y de las características específicas del problema.\n",
    "\n",
    "5. **Validación y envío de respuestas:** Después de que los caracteres o elementos del captcha han sido reconocidos, se verifica la validez de la respuesta obtenida. Esto puede implicar comparar la respuesta con una lista predefinida de posibles soluciones o realizar comprobaciones adicionales en el sitio web para asegurarse de que la respuesta sea correcta. Una vez validada, la respuesta se puede enviar automáticamente al formulario o proceso que requiere el captcha.\n",
    "\n",
    "Es importante tener en cuenta que algunos sitios web implementan captchas más complejos y sofisticados para evitar la resolución automática. Estos captchas pueden incluir desafíos más avanzados, como imágenes con distorsiones adicionales, elementos en movimiento, desafíos de audio, entre otros. En tales casos, puede ser necesario utilizar técnicas más avanzadas, como el aprendizaje automático o la integración con servicios de resolución de captchas externos.\n",
    "\n",
    "Además, es fundamental recordar que el uso de técnicas de resolución automática de captchas debe realizarse de acuerdo con los términos de servicio y las políticas del sitio web objetivo. Algunos sitios web pueden prohibir o limitar el acceso a aquellos que intenten evadir sus mecanismos de seguridad.\n",
    "\n",
    "A continuación se presenta un ejemplo básico utilizando la biblioteca pytesseract en Python para el reconocimiento de texto en un captcha:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import pytesseract\n",
    "\n",
    "# Descargar y cargar la imagen captcha\n",
    "captcha_url = 'http://www.example.com/captcha.jpg'\n",
    "response = requests.get(captcha_url)\n",
    "captcha_image = Image.open(BytesIO(response.content))\n",
    "\n",
    "# Preprocesamiento de la imagen\n",
    "captcha_image = captcha_image.convert('L')  # Convertir a escala de grises\n",
    "captcha_image = captcha_image.point(lambda x: 0 if x < 128 else 255, '1')  # Binarización\n",
    "\n",
    "# Reconocimiento de texto utilizando pytesseract\n",
    "captcha_text = pytesseract.image_to_string(captcha_image)\n",
    "\n",
    "# Enviar la respuesta del captcha al formulario\n",
    "payload = {'captcha': captcha_text, 'username': 'my_username', 'password': 'my_password'}\n",
    "response = requests.post('http://www.example.com/login', data=payload)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se descarga una imagen captcha de una URL, se realiza un preprocesamiento básico convirtiéndola a escala de grises y binarizándola, y luego se utiliza pytesseract para extraer el texto del captcha. Finalmente, se envía la respuesta del captcha junto con los datos de inicio de sesión al formulario de inicio de sesión del sitio web.\n",
    "\n",
    "Es importante tener en cuenta que la efectividad de la resolución automática de captchas puede variar dependiendo de la complejidad del captcha, la calidad de las imágenes y la precisión del algoritmo de reconocimiento utilizado. Además, se recomienda revisar las políticas y términos de servicio del sitio web antes de utilizar técnicas de resolución automática de captchas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Inicio** | **atrás 6** | **Siguiente 8** |\n",
    "|----------- |-------------- |---------------|\n",
    "| [🏠](../../README.md) | [⏪](./6.Web_Scraping_de_APIs_iFrames_y_Scripts.ipynb)| [⏩](./8.Evitando_Problemas_Eticas.ipynb)|"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
