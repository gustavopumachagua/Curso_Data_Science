{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ajuste de Hiperparámetros de Modelos de Machine Learning**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Introducción**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ajuste de hiperparámetros en el contexto de modelos de Machine Learning se refiere al proceso de encontrar la combinación óptima de valores para los parámetros que no se aprenden directamente del conjunto de datos durante el entrenamiento del modelo.\n",
    "\n",
    "Los hiperparámetros son valores que se definen antes del entrenamiento del modelo y que afectan su capacidad para ajustarse al conjunto de datos. Algunos ejemplos comunes de hiperparámetros son la tasa de aprendizaje, el número de capas en una red neuronal, la cantidad de árboles en un bosque aleatorio, entre otros.\n",
    "\n",
    "El ajuste de hiperparámetros implica probar diferentes combinaciones de valores de los hiperparámetros y evaluar el desempeño del modelo en un conjunto de validación. El objetivo es encontrar la combinación óptima que maximice la precisión del modelo en el conjunto de datos de prueba.\n",
    "\n",
    "Este proceso puede ser muy laborioso y a menudo se utilizan técnicas como la búsqueda de cuadrícula, la búsqueda aleatoria y la optimización bayesiana para encontrar la combinación óptima de hiperparámetros. Una vez que se ha encontrado la combinación óptima, se puede utilizar para entrenar el modelo final que se utilizará en la producción."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Datos y técnica a utilizar**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí te presento algunos ejemplos de datos y técnicas que se pueden utilizar para el ajuste de hiperparámetros en modelos de Machine Learning:\n",
    "\n",
    "1. Datos: Conjunto de datos de reconocimiento de imágenes de dígitos escritos a mano (MNIST).\n",
    "\n",
    "Técnica: Búsqueda de cuadrícula para ajustar los hiperparámetros de un modelo de red neuronal convolucional, como el número de capas ocultas, el número de filtros en cada capa, el tamaño del kernel, etc.\n",
    "\n",
    "2. Datos: Conjunto de datos de precios de viviendas.\n",
    "\n",
    "Técnica: Búsqueda aleatoria para ajustar los hiperparámetros de un modelo de regresión, como el tamaño del conjunto de entrenamiento, el número de variables de entrada, el tipo de modelo (regresión lineal, regresión de bosque aleatorio, etc.), y otros hiperparámetros específicos del modelo.\n",
    "\n",
    "3. Datos: Conjunto de datos de detección de fraude de tarjetas de crédito.\n",
    "\n",
    "Técnica: Optimización bayesiana para ajustar los hiperparámetros de un modelo de clasificación, como el número de árboles en un bosque aleatorio, el número máximo de profundidad, la tasa de aprendizaje, la regularización y otros hiperparámetros específicos del modelo.\n",
    "\n",
    "Estos son solo algunos ejemplos de datos y técnicas que se pueden utilizar para el ajuste de hiperparámetros en modelos de Machine Learning. La elección de la técnica y los hiperparámetros específicos dependerá del problema y los datos que se estén utilizando."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3. Explicación de bosques aleatorios**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los bosques aleatorios son un tipo de modelo de Machine Learning que se utilizan para problemas de clasificación y regresión. Son una combinación de múltiples árboles de decisión, en los cuales cada árbol es entrenado con una muestra aleatoria de datos y una selección aleatoria de características.\n",
    "\n",
    "La idea principal detrás de los bosques aleatorios es que la combinación de múltiples modelos débiles y altamente correlacionados puede producir un modelo fuerte y robusto. Cada árbol en el bosque se entrena en una muestra aleatoria de los datos, lo que significa que cada árbol verá una parte diferente del conjunto de datos y será entrenado con una perspectiva diferente. Además, cada árbol se entrena con una selección aleatoria de características, lo que significa que cada árbol se enfoca en diferentes aspectos de los datos.\n",
    "\n",
    "A continuación se muestra un ejemplo de código en Python para implementar un modelo de bosque aleatorio utilizando el conjunto de datos de Iris:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=42)\n",
    "\n",
    "# crear un modelo de bosque aleatorio con 100 árboles\n",
    "rfc = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# ajustar el modelo a los datos de entrenamiento\n",
    "rfc.fit(X_train, y_train)\n",
    "\n",
    "# evaluar la precisión del modelo en los datos de prueba\n",
    "print('Precisión del modelo:', rfc.score(X_test, y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se utiliza la biblioteca Scikit-Learn para cargar el conjunto de datos de Iris y dividirlo en un conjunto de datos de entrenamiento y prueba. Luego se crea un modelo de bosque aleatorio con 100 árboles utilizando la clase ```RandomForestClassifier```. Se ajusta el modelo a los datos de entrenamiento y se evalúa la precisión del modelo en los datos de prueba. La precisión del modelo se imprime en la consola."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **4. Hiperparámetros de los bosques**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los hiperparámetros son valores que se establecen antes del entrenamiento de un modelo de Machine Learning y que influyen en su rendimiento. Para los bosques aleatorios, algunos ejemplos de hiperparámetros incluyen el número de árboles en el bosque, la profundidad máxima de los árboles, el número mínimo de muestras requeridas para dividir un nodo, la fracción de características que se seleccionan al azar para cada árbol, entre otros.\n",
    "\n",
    "A continuación, se muestra un ejemplo de código en Python que utiliza la biblioteca Scikit-Learn para entrenar un modelo de bosque aleatorio en el conjunto de datos de Iris, ajustando algunos de sus hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': 3, 'max_features': 'sqrt', 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Precisión del modelo: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=42)\n",
    "\n",
    "# crear un modelo de bosque aleatorio\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# definir una cuadrícula de hiperparámetros para buscar\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "              'max_depth': [3, 5, None],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'max_features': ['sqrt', 'log2']}\n",
    "\n",
    "# realizar la búsqueda de cuadrícula para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# imprimir los mejores hiperparámetros y la precisión del modelo en los datos de prueba\n",
    "print('Mejores hiperparámetros:', grid_search.best_params_)\n",
    "print('Precisión del modelo:', grid_search.score(X_test, y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se crea un modelo de bosque aleatorio sin establecer valores para algunos de sus hiperparámetros, para que puedan ser ajustados más tarde mediante la búsqueda de cuadrícula. Se define una cuadrícula de hiperparámetros utilizando la clase ```GridSearchCV``` de Scikit-Learn, que realiza una búsqueda exhaustiva de combinaciones de hiperparámetros para encontrar los valores que producen el mejor rendimiento. En este caso, se ajustan los hiperparámetros ```n_estimators```, ```max_depth```, ```min_samples_split``` y ```max_features```. Luego, se ajusta el modelo a los datos de entrenamiento utilizando la función ```fit``` de la clase ```GridSearchCV``` y se evalúa la precisión del modelo en los datos de prueba. Finalmente, se imprimen los mejores hiperparámetros encontrados y la precisión del modelo en los datos de prueba."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **5. Búsqueda en Rejilla (GridSearch)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda en rejilla, o GridSearch, es una técnica de ajuste de hiperparámetros que implica la evaluación exhaustiva de todas las combinaciones posibles de valores de hiperparámetros en un rango predefinido. A continuación, se presenta un ejemplo de código en Python que utiliza la biblioteca Scikit-Learn para realizar una búsqueda en rejilla en un modelo de regresión logística:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'C': 10, 'penalty': 'l1', 'solver': 'saga'}\n",
      "Precisión del modelo: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=42)\n",
    "\n",
    "# crear un modelo de regresión logística\n",
    "logreg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "\n",
    "# definir una cuadrícula de hiperparámetros para buscar\n",
    "param_grid = {'C': [0.1, 1, 10],\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'solver': ['liblinear', 'saga']}\n",
    "\n",
    "# realizar la búsqueda de cuadrícula para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(logreg, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# imprimir los mejores hiperparámetros y la precisión del modelo en los datos de prueba\n",
    "print('Mejores hiperparámetros:', grid_search.best_params_)\n",
    "print('Precisión del modelo:', grid_search.score(X_test, y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se define una cuadrícula de hiperparámetros utilizando la clase ```GridSearchCV``` de Scikit-Learn. La cuadrícula contiene diferentes valores para los hiperparámetros ```C```, ```penalty``` y ```solver``` del modelo de regresión logística. Luego, se realiza una búsqueda de cuadrícula para evaluar todas las posibles combinaciones de hiperparámetros y encontrar los que producen el mejor rendimiento en términos de precisión en los datos de entrenamiento. La función ```fit``` de la clase ```GridSearchCV``` ajusta el modelo a los datos de entrenamiento utilizando cada combinación de valores de hiperparámetros y evalúa el rendimiento utilizando una validación cruzada con 5 divisiones. Finalmente, se imprimen los mejores hiperparámetros encontrados y la precisión del modelo en los datos de prueba."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **6. Información de la Rejilla**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Información de la Rejilla (GridSearchCV) es una técnica de ajuste de hiperparámetros que utiliza una búsqueda exhaustiva sobre una grilla de valores posibles de hiperparámetros para encontrar la mejor combinación de hiperparámetros para un modelo de machine learning. En lugar de ajustar manualmente los hiperparámetros, GridSearchCV prueba todas las posibles combinaciones de hiperparámetros y devuelve la mejor combinación.\n",
    "\n",
    "Aquí hay un ejemplo de código que muestra cómo utilizar GridSearchCV con SVM para encontrar la mejor combinación de valores de hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Precisión del modelo: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "# crear un modelo SVM\n",
    "svm = SVC()\n",
    "\n",
    "# definir una cuadrícula de hiperparámetros para buscar\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "\n",
    "# realizar la búsqueda de cuadrícula para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# imprimir los mejores hiperparámetros y la precisión del modelo en los datos de prueba\n",
    "print('Mejores hiperparámetros:', grid_search.best_params_)\n",
    "print('Precisión del modelo:', grid_search.score(X_test, y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se utiliza ```GridSearchCV``` para buscar la mejor combinación de valores de hiperparámetros para el modelo SVM. La cuadrícula de hiperparámetros a probar se define en el diccionario ```param_grid```. ```GridSearchCV``` ajusta el modelo SVM a cada combinación posible de valores de hiperparámetros y evalúa su rendimiento utilizando la validación cruzada de 5 pliegues. Finalmente, imprime los mejores hiperparámetros encontrados y la precisión del modelo en los datos de prueba."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **7. Validación cruzada y Rejilla**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La Validación Cruzada (Cross Validation) es una técnica utilizada para evaluar el rendimiento de un modelo de Machine Learning. La idea principal es dividir el conjunto de datos en subconjuntos de entrenamiento y prueba, entrenar el modelo en el subconjunto de entrenamiento y evaluar su rendimiento en el subconjunto de prueba. Esta técnica es útil para evitar el sobreajuste y para obtener una mejor estimación del rendimiento del modelo.\n",
    "\n",
    "La Búsqueda en Rejilla (GridSearchCV) es una técnica de ajuste de hiperparámetros que utiliza una búsqueda exhaustiva sobre una grilla de valores posibles de hiperparámetros para encontrar la mejor combinación de hiperparámetros para un modelo de Machine Learning.\n",
    "\n",
    "Aquí hay un ejemplo de código que muestra cómo utilizar la Validación Cruzada y la Búsqueda en Rejilla con SVM para encontrar la mejor combinación de valores de hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Precisión del modelo en los datos de prueba: 0.9736842105263158\n",
      "Precisión media de la validación cruzada: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "# crear un modelo SVM\n",
    "svm = SVC()\n",
    "\n",
    "# definir una cuadrícula de hiperparámetros para buscar\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "\n",
    "# realizar la búsqueda de cuadrícula con validación cruzada para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# imprimir los mejores hiperparámetros y la precisión del modelo en los datos de prueba\n",
    "print('Mejores hiperparámetros:', grid_search.best_params_)\n",
    "print('Precisión del modelo en los datos de prueba:', grid_search.score(X_test, y_test))\n",
    "\n",
    "# realizar la validación cruzada para evaluar el rendimiento del modelo\n",
    "scores = cross_val_score(grid_search, iris.data, iris.target, cv=5)\n",
    "print('Precisión media de la validación cruzada:', scores.mean())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se utiliza la Validación Cruzada con Búsqueda en Rejilla para encontrar la mejor combinación de valores de hiperparámetros para el modelo SVM. La cuadrícula de hiperparámetros a probar se define en el diccionario ```param_grid```. GridSearchCV ajusta el modelo SVM a cada combinación posible de valores de hiperparámetros y evalúa su rendimiento utilizando la validación cruzada de 5 pliegues. Finalmente, imprime los mejores hiperparámetros encontrados y la precisión del modelo en los datos de prueba, así como la precisión media de la validación cruzada."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **8. Conjuntos de hiperparámetros explorados**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el contexto de la Búsqueda en Rejilla (GridSearchCV), los conjuntos de hiperparámetros explorados son todas las combinaciones de valores de hiperparámetros que se prueban para encontrar la mejor combinación que produce el mejor rendimiento del modelo. Estos conjuntos pueden ser bastante grandes y pueden ser un desafío para la optimización del modelo.\n",
    "\n",
    "Aquí hay un ejemplo de código que muestra cómo utilizar la Búsqueda en Rejilla con SVM para explorar conjuntos de hiperparámetros:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conjuntos de hiperparámetros explorados: [{'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}, {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}, {'C': 0.1, 'gamma': 'auto', 'kernel': 'linear'}, {'C': 0.1, 'gamma': 'auto', 'kernel': 'rbf'}, {'C': 1, 'gamma': 'scale', 'kernel': 'linear'}, {'C': 1, 'gamma': 'scale', 'kernel': 'rbf'}, {'C': 1, 'gamma': 'auto', 'kernel': 'linear'}, {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}, {'C': 10, 'gamma': 'scale', 'kernel': 'linear'}, {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}, {'C': 10, 'gamma': 'auto', 'kernel': 'linear'}, {'C': 10, 'gamma': 'auto', 'kernel': 'rbf'}]\n",
      "Rendimiento de cada conjunto de hiperparámetros: [0.95533597 0.82094862 0.95533597 0.94703557 0.97312253 0.96403162\n",
      " 0.97312253 0.96403162 0.97272727 0.97312253 0.97272727 0.97272727]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "# crear un modelo SVM\n",
    "svm = SVC()\n",
    "\n",
    "# definir una cuadrícula de hiperparámetros para buscar\n",
    "param_grid = {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf'], 'gamma': ['scale', 'auto']}\n",
    "\n",
    "# realizar la búsqueda de cuadrícula para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# imprimir los conjuntos de hiperparámetros explorados y su rendimiento\n",
    "print('Conjuntos de hiperparámetros explorados:', grid_search.cv_results_['params'])\n",
    "print('Rendimiento de cada conjunto de hiperparámetros:', grid_search.cv_results_['mean_test_score'])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se utiliza la Búsqueda en Rejilla con SVM para explorar conjuntos de hiperparámetros definidos en el diccionario ```param_grid```. GridSearchCV ajusta el modelo SVM a cada combinación posible de valores de hiperparámetros y evalúa su rendimiento utilizando la validación cruzada de 5 pliegues. Luego, imprime los conjuntos de hiperparámetros explorados y su rendimiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **9. Ranking de los mejores modelos**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El ranking de los mejores modelos es una lista ordenada de los modelos entrenados según su rendimiento. Esta lista puede ser útil para seleccionar el modelo final para su uso en la producción. Los modelos se ordenan según alguna métrica de rendimiento, como la precisión, la puntuación F1, el AUC, etc.\n",
    "\n",
    "Aquí hay un ejemplo de código que muestra cómo utilizar GridSearchCV para entrenar varios modelos y ordenarlos según su precisión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 30.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan 0.92924901        nan 0.96403162        nan 0.97272727]\n",
      "  warnings.warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Modelo: Logistic Regression, Precisión: 0.9736842105263158, Mejores Hiperparámetros: {'C': 10, 'penalty': 'l2'}\n",
      "2. Modelo: Decision Tree, Precisión: 0.9736842105263158, Mejores Hiperparámetros: {'max_depth': 3}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=0)\n",
    "\n",
    "# definir una lista de modelos para entrenar\n",
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression()),\n",
    "    ('Decision Tree', DecisionTreeClassifier())\n",
    "]\n",
    "\n",
    "# definir una cuadrícula de hiperparámetros para buscar\n",
    "param_grid = {\n",
    "    'Logistic Regression': {'C': [0.1, 1, 10], 'penalty': ['l1', 'l2']},\n",
    "    'Decision Tree': {'max_depth': [3, 5, 7]}\n",
    "}\n",
    "\n",
    "# entrenar los modelos utilizando la búsqueda de cuadrícula y la validación cruzada de 5 pliegues\n",
    "results = {}\n",
    "for name, model in models:\n",
    "    grid_search = GridSearchCV(model, param_grid[name], cv=5)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    results[name] = {'best_params': grid_search.best_params_, 'score': grid_search.score(X_test, y_test)}\n",
    "\n",
    "# ordenar los modelos según su precisión\n",
    "ranked_models = sorted(results.items(), key=lambda x: x[1]['score'], reverse=True)\n",
    "\n",
    "# imprimir el ranking de los modelos\n",
    "for i, (name, result) in enumerate(ranked_models):\n",
    "    print(f'{i+1}. Modelo: {name}, Precisión: {result[\"score\"]}, Mejores Hiperparámetros: {result[\"best_params\"]}')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se definen dos modelos diferentes para entrenar (regresión logística y árbol de decisión) y se define una cuadrícula de hiperparámetros diferente para cada modelo. GridSearchCV se utiliza para entrenar los modelos utilizando la búsqueda de cuadrícula y la validación cruzada de 5 pliegues. Luego, los modelos se ordenan según su precisión y se imprimen en orden de mejor a peor rendimiento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **10. Los mejores hiperparámetros**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores hiperparámetros son aquellos que producen el mejor rendimiento en el modelo de machine learning. En la búsqueda de hiperparámetros, se exploran diferentes combinaciones de hiperparámetros para encontrar los que producen el mejor resultado. El mejor conjunto de hiperparámetros se selecciona según una métrica de evaluación específica, como la precisión, el AUC, la F1-score, entre otros.\n",
    "\n",
    "Aquí hay un ejemplo de cómo obtener los mejores hiperparámetros utilizando la búsqueda en rejilla y la validación cruzada en Scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n",
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'max_depth': None, 'max_features': 'auto', 'n_estimators': 100}\n",
      "Precisión del modelo: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=42)\n",
    "\n",
    "# crear un modelo de bosque aleatorio\n",
    "rfc = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# definir una cuadrícula de hiperparámetros para buscar\n",
    "param_grid = {'n_estimators': [50, 100, 200],\n",
    "              'max_depth': [None, 5, 10],\n",
    "              'max_features': ['auto', 'sqrt', 'log2']}\n",
    "\n",
    "# realizar la búsqueda de cuadrícula para encontrar los mejores hiperparámetros\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# imprimir los mejores hiperparámetros y la precisión del modelo en los datos de prueba\n",
    "print('Mejores hiperparámetros:', grid_search.best_params_)\n",
    "print('Precisión del modelo:', grid_search.score(X_test, y_test))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, estamos buscando los mejores hiperparámetros para un modelo de bosque aleatorio. Hacemos uso de la búsqueda en rejilla para explorar diferentes combinaciones de hiperparámetros y usamos la validación cruzada con 5 pliegues para evaluar el rendimiento de cada combinación de hiperparámetros. Finalmente, imprimimos los mejores hiperparámetros encontrados y la precisión del modelo en los datos de prueba."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **11. Usando el mejor modelo**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez que hemos obtenido los mejores hiperparámetros y hemos ajustado nuestro modelo usando la validación cruzada, podemos utilizar el modelo resultante para hacer predicciones en nuevos datos. Aquí hay un ejemplo de cómo hacer esto usando un modelo de regresión logística ajustado a través de la validación cruzada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión del modelo en los datos de prueba: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "# cargar el conjunto de datos de iris\n",
    "iris = load_iris()\n",
    "\n",
    "# dividir el conjunto de datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, random_state=42)\n",
    "\n",
    "# definir una cuadrícula de hiperparámetros para buscar\n",
    "param_grid = {'C': [0.1, 1, 10],\n",
    "              'penalty': ['l1', 'l2'],\n",
    "              'solver': ['liblinear', 'saga']}\n",
    "\n",
    "# crear un modelo de regresión logística con los mejores hiperparámetros\n",
    "best_logreg = LogisticRegression(C=1, penalty='l1', solver='saga', random_state=42)\n",
    "\n",
    "# ajustar el modelo a los datos de entrenamiento\n",
    "best_logreg.fit(X_train, y_train)\n",
    "\n",
    "# hacer predicciones en los datos de prueba\n",
    "y_pred = best_logreg.predict(X_test)\n",
    "\n",
    "# evaluar la precisión del modelo en los datos de prueba\n",
    "accuracy = best_logreg.score(X_test, y_test)\n",
    "print('Precisión del modelo en los datos de prueba:', accuracy)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, después de ajustar el modelo con los mejores hiperparámetros encontrados mediante la validación cruzada, utilizamos el método ```predict``` para hacer predicciones en los datos de prueba. Luego, evaluamos la precisión del modelo en los datos de prueba utilizando el método ```score```."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **12. Búsqueda aleatoria (RandomizedSearch)**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La búsqueda aleatoria (RandomizedSearch) es una técnica de optimización de hiperparámetros que consiste en buscar los valores óptimos de los parámetros de un modelo de forma aleatoria en un rango de valores especificado. En lugar de probar todas las combinaciones posibles de parámetros, lo que puede ser computacionalmente costoso, se seleccionan valores aleatorios dentro de un rango predefinido para cada parámetro y se evalúa su desempeño en el modelo.\n",
    "\n",
    "Un ejemplo de cómo se puede implementar RandomizedSearch utilizando la biblioteca de aprendizaje automático Scikit-learn en Python es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'min_samples_leaf': 13, 'min_samples_split': 12, 'n_estimators': 16}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define el modelo\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define el espacio de búsqueda de los hiperparámetros\n",
    "param_dist = {'n_estimators': randint(10, 100),\n",
    "              'max_depth': randint(1, 10),\n",
    "              'min_samples_split': randint(2, 20),\n",
    "              'min_samples_leaf': randint(1, 20)}\n",
    "\n",
    "# Ejecuta la búsqueda aleatoria\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=10, cv=5, n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo utilizando los mejores parámetros encontrados\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Muestra los mejores parámetros encontrados\n",
    "print(random_search.best_params_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, se define un modelo RandomForestClassifier y se define un espacio de búsqueda de los hiperparámetros a través del diccionario param_dist. Los valores de los hiperparámetros se seleccionan de forma aleatoria dentro de los rangos especificados usando la función randint de scipy.stats.\n",
    "\n",
    "Se ejecuta la búsqueda aleatoria utilizando RandomizedSearchCV de Scikit-learn, que realiza una validación cruzada de 5 veces y prueba 10 combinaciones aleatorias de valores de hiperparámetros.\n",
    "\n",
    "Finalmente, se ajusta el modelo utilizando los mejores parámetros encontrados y se imprimen los valores de los mejores parámetros encontrados."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **13. Hiperparámetros explorados aleatoriamente**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los hiperparámetros explorados aleatoriamente se refieren a los valores de los hiperparámetros que son seleccionados de forma aleatoria dentro de un rango predefinido durante el proceso de búsqueda aleatoria. Estos hiperparámetros son los que se evalúan para determinar cuál combinación de valores da lugar al mejor desempeño del modelo.\n",
    "\n",
    "A continuación, se presenta un ejemplo de código que muestra cómo se pueden definir los hiperparámetros a ser explorados aleatoriamente en la búsqueda de un modelo RandomForestClassifier utilizando la biblioteca de aprendizaje automático Scikit-learn en Python:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/puma/anaconda3/lib/python3.9/site-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 3, 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 46}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Define el modelo\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Define el espacio de búsqueda de los hiperparámetros\n",
    "param_dist = {'n_estimators': randint(10, 100),\n",
    "              'max_depth': randint(1, 10),\n",
    "              'min_samples_split': randint(2, 20),\n",
    "              'min_samples_leaf': randint(1, 20)}\n",
    "\n",
    "# Ejecuta la búsqueda aleatoria\n",
    "random_search = RandomizedSearchCV(model, param_distributions=param_dist,\n",
    "                                   n_iter=10, cv=5, n_jobs=-1)\n",
    "\n",
    "# Ajusta el modelo utilizando los mejores parámetros encontrados\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Muestra los mejores parámetros encontrados\n",
    "print(random_search.best_params_)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este ejemplo, los hiperparámetros explorados aleatoriamente son:\n",
    "\n",
    "* n_estimators: número de árboles en el modelo RandomForestClassifier, seleccionado aleatoriamente entre 10 y 100.\n",
    "max_depth: profundidad máxima de los árboles en el modelo RandomForestClassifier, seleccionado aleatoriamente entre 1 y 10.\n",
    "* min_samples_split: número mínimo de muestras requeridas para dividir un nodo interno en el modelo RandomForestClassifier, seleccionado aleatoriamente entre 2 y 20.\n",
    "* min_samples_leaf: número mínimo de muestras requeridas para ser una hoja en el modelo RandomForestClassifier, seleccionado aleatoriamente entre 1 y 20.\n",
    "\n",
    "Estos hiperparámetros son definidos en el diccionario ```param_dist```, que es pasado como parámetro a la función RandomizedSearchCV. Durante la búsqueda aleatoria, se seleccionan aleatoriamente 10 combinaciones de valores de los hiperparámetros definidos en ```param_dist```, y se evalúa el desempeño del modelo para cada combinación. Al final, el mejor conjunto de valores de hiperparámetros se selecciona y se utiliza para ajustar el modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
